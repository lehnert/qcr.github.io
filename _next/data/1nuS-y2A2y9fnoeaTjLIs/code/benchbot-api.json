{"pageProps":{"codeData":"{\"content\":\"<p><strong>NOTE: this software needs to interface with a running instance of the BenchBot software stack. Unless you are running against a remote stack / robot, please install this software with the BenchBot software stack as described <a href=https://github.com/qcr/benchbot>here</a>.</strong></p>\\n<h1>BenchBot API</h1>\\n<p><video autoplay loop poster=\\\"/_next/static/gifs/566ece96917dbb84cd386109b8457390.jpg\\\"><source src=\\\"/_next/static/gifs/566ece96917dbb84cd386109b8457390.webm\\\" type=\\\"video/webm\\\"/></video></p>\\n<p>The BenchBot API provides a simple interface for controlling a robot or simulator through actions, and receiving data through observations. As shown above, the entire code required for running an agent in a realistic 3D simulator is only a handful of simple Python commands.</p>\\n<p><a href=\\\"https://gym.openai.com\\\">Open AI Gym</a> users will find the breakdown into actions, observations, and steps extremely familiar. BenchBot API allows researchers to develop and test novel algorithms with real robot systems and realistic 3D simulators, without the typical hassles arising when interfacing with complicated multi-component robot systems.</p>\\n<p>Running a robot through an entire environment, with your own custom agent, is as simple as one line of code with the BenchBot API:</p>\\n<pre class=\\\"language-python\\\"><code class=\\\"language-python\\\"><span class=\\\"token keyword\\\">from</span> benchbot_api <span class=\\\"token keyword\\\">import</span> BenchBot\\n<span class=\\\"token keyword\\\">from</span> my_agent <span class=\\\"token keyword\\\">import</span> MyAgent\\n\\nBenchBot<span class=\\\"token punctuation\\\">(</span>agent<span class=\\\"token operator\\\">=</span>MyAgent<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">.</span>run<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span>\\n</code></pre>\\n<p>The above assumes you have created your own agent by overloading the abstract <code class=\\\"language-none\\\">Agent</code> class provided with the API. Overloading the abstract class requires implementing 3 basic methods. Below is a basic example to spin on the spot:</p>\\n<pre class=\\\"language-python\\\"><code class=\\\"language-python\\\"><span class=\\\"token keyword\\\">from</span> benchbot_api <span class=\\\"token keyword\\\">import</span> Agent\\n<span class=\\\"token keyword\\\">import</span> json\\n\\n<span class=\\\"token keyword\\\">class</span> <span class=\\\"token class-name\\\">MyAgent</span><span class=\\\"token punctuation\\\">(</span>Agent<span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">:</span>\\n\\n    <span class=\\\"token keyword\\\">def</span> <span class=\\\"token function\\\">is_done</span><span class=\\\"token punctuation\\\">(</span>self<span class=\\\"token punctuation\\\">,</span> action_result<span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">:</span>\\n        <span class=\\\"token comment\\\"># Go forever</span>\\n        <span class=\\\"token keyword\\\">return</span> <span class=\\\"token boolean\\\">False</span>\\n\\n    <span class=\\\"token keyword\\\">def</span> <span class=\\\"token function\\\">pick_action</span><span class=\\\"token punctuation\\\">(</span>self<span class=\\\"token punctuation\\\">,</span> observations<span class=\\\"token punctuation\\\">,</span> action_list<span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">:</span>\\n        <span class=\\\"token comment\\\"># Rotates on the spot indefinitely, 5 degrees at a time</span>\\n        <span class=\\\"token comment\\\"># (assumes we are running in passive mode)</span>\\n        <span class=\\\"token keyword\\\">return</span> <span class=\\\"token string\\\">'move_angle'</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token punctuation\\\">{</span><span class=\\\"token string\\\">'angle'</span><span class=\\\"token punctuation\\\">:</span> <span class=\\\"token number\\\">5</span><span class=\\\"token punctuation\\\">}</span>\\n\\n    <span class=\\\"token keyword\\\">def</span> <span class=\\\"token function\\\">save_result</span><span class=\\\"token punctuation\\\">(</span>self<span class=\\\"token punctuation\\\">,</span> filename<span class=\\\"token punctuation\\\">,</span> empty_results<span class=\\\"token punctuation\\\">,</span> results_format_fns<span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">:</span>\\n        <span class=\\\"token comment\\\"># Save some blank results</span>\\n        <span class=\\\"token keyword\\\">with</span> <span class=\\\"token builtin\\\">open</span><span class=\\\"token punctuation\\\">(</span>filename<span class=\\\"token punctuation\\\">,</span> <span class=\\\"token string\\\">'w'</span><span class=\\\"token punctuation\\\">)</span> <span class=\\\"token keyword\\\">as</span> f<span class=\\\"token punctuation\\\">:</span>\\n            json<span class=\\\"token punctuation\\\">.</span>dump<span class=\\\"token punctuation\\\">(</span>empty_results<span class=\\\"token punctuation\\\">,</span> f<span class=\\\"token punctuation\\\">)</span>\\n</code></pre>\\n<p>If you prefer to do things manually, a more exhaustive suite of functions are also available as part of the BenchBot API. Instead of using the <code class=\\\"language-none\\\">BenchBot.run()</code> method, a large number of methods are available through the API. Below highlights a handful of the capabilities of BenchBot API:</p>\\n<pre class=\\\"language-python\\\"><code class=\\\"language-python\\\"><span class=\\\"token keyword\\\">from</span> benchbot_api <span class=\\\"token keyword\\\">import</span> BenchBot<span class=\\\"token punctuation\\\">,</span> RESULT_LOCATION\\n<span class=\\\"token keyword\\\">import</span> json\\n<span class=\\\"token keyword\\\">import</span> matplotlib<span class=\\\"token punctuation\\\">.</span>pyplot <span class=\\\"token keyword\\\">as</span> plt\\n\\n<span class=\\\"token comment\\\"># Create a BenchBot instance &amp; reset the simulator / robot to starting state</span>\\nb <span class=\\\"token operator\\\">=</span> BenchBot<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span>\\nobservations<span class=\\\"token punctuation\\\">,</span> action_result <span class=\\\"token operator\\\">=</span> b<span class=\\\"token punctuation\\\">.</span>reset<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span>\\n\\n<span class=\\\"token comment\\\"># Print details of selected task &amp; environment</span>\\n<span class=\\\"token keyword\\\">print</span><span class=\\\"token punctuation\\\">(</span>b<span class=\\\"token punctuation\\\">.</span>task_details<span class=\\\"token punctuation\\\">)</span>\\n<span class=\\\"token keyword\\\">print</span><span class=\\\"token punctuation\\\">(</span>b<span class=\\\"token punctuation\\\">.</span>environment_details<span class=\\\"token punctuation\\\">)</span>\\n\\n<span class=\\\"token comment\\\"># Visualise the current RGB image from the robot</span>\\nplt<span class=\\\"token punctuation\\\">.</span>imshow<span class=\\\"token punctuation\\\">(</span>observations<span class=\\\"token punctuation\\\">[</span><span class=\\\"token string\\\">'image_rgb'</span><span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span>\\n\\n<span class=\\\"token comment\\\"># Move to the next pose if we have a 'move_next' action available</span>\\n<span class=\\\"token keyword\\\">if</span> <span class=\\\"token string\\\">'move_next'</span> <span class=\\\"token keyword\\\">in</span> b<span class=\\\"token punctuation\\\">.</span>actions<span class=\\\"token punctuation\\\">:</span>\\n    observations<span class=\\\"token punctuation\\\">,</span> action_result <span class=\\\"token operator\\\">=</span> b<span class=\\\"token punctuation\\\">.</span>step<span class=\\\"token punctuation\\\">(</span><span class=\\\"token string\\\">'move_next'</span><span class=\\\"token punctuation\\\">)</span>\\n\\n<span class=\\\"token comment\\\"># Save some empty results</span>\\n<span class=\\\"token keyword\\\">with</span> <span class=\\\"token builtin\\\">open</span><span class=\\\"token punctuation\\\">(</span>RESULT_LOCATION<span class=\\\"token punctuation\\\">,</span> <span class=\\\"token string\\\">'w'</span><span class=\\\"token punctuation\\\">)</span> <span class=\\\"token keyword\\\">as</span> f<span class=\\\"token punctuation\\\">:</span>\\n    json<span class=\\\"token punctuation\\\">.</span>dump<span class=\\\"token punctuation\\\">(</span>b<span class=\\\"token punctuation\\\">.</span>empty_results<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">,</span> f<span class=\\\"token punctuation\\\">)</span>\\n</code></pre>\\n<p>For sample solutions that use the BenchBot API, see the examples add-ons available (e.g. <a href=https://github.com/benchbot-addons/examples_base><code class=\\\"language-none\\\">benchbot-addons/examples_base</code></a> and <a href=https://github.com/benchbot-addons/examples_ssu><code class=\\\"language-none\\\">benchbot-addons/examples_ssu</code></a>).</p>\\n<h2>Installing BenchBot API</h2>\\n<p>BenchBot API is a Python package, installable with pip. Run the following in the root directory of where this repository was cloned:</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">u@pc:~$ pip install .\\n</code></pre>\\n<h2>Using the API to communicate with a robot</h2>\\n<p>Communication with the robot comes through a series of &quot;channels&quot; which are defined by the robot's definition file (e.g. <a href=https://github.com/benchbot-addons/robots_isaac/blob/master/robots/carter.yaml>carter</a>). A task definition file (e.g. <a href=https://github.com/benchbot-addons/tasks_ssu/blob/master/tasks/sslam_pgt.yaml>semantic_slam:passive:ground_truth</a>) then declares which of these connections are provided to the API as either sensor observations or actions to be executed by a robot actuator.</p>\\n<p>The API talks to the <a href=https://github.com/qcr/benchbot_supervisor>BenchBot Supervisor</a>, which handles loading and managing the different kinds of back-end configuration files. This abstracts all of the underlying communication complexities away from the user, allowing the BenchBot API to remain a simple interface that focuses on getting observations and sending actions.</p>\\n<p>An action is sent to the robot by calling the <code class=\\\"language-none\\\">BenchBot.step()</code> method with a valid action (found by checking the <code class=\\\"language-none\\\">BenchBot.actions</code> property):</p>\\n<pre class=\\\"language-python\\\"><code class=\\\"language-python\\\"><span class=\\\"token keyword\\\">from</span> benchbot_api <span class=\\\"token keyword\\\">import</span> BenchBot\\n\\nb <span class=\\\"token operator\\\">=</span> BenchBot<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span>\\navailable_actions <span class=\\\"token operator\\\">=</span> b<span class=\\\"token punctuation\\\">.</span>actions\\nb<span class=\\\"token punctuation\\\">.</span>step<span class=\\\"token punctuation\\\">(</span>b<span class=\\\"token punctuation\\\">.</span>actions<span class=\\\"token punctuation\\\">[</span><span class=\\\"token number\\\">0</span><span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token punctuation\\\">{</span><span class=\\\"token string\\\">'action_arg:'</span><span class=\\\"token punctuation\\\">,</span> arg_value<span class=\\\"token punctuation\\\">}</span><span class=\\\"token punctuation\\\">)</span>  <span class=\\\"token comment\\\"># Perform the first available action</span>\\n</code></pre>\\n<p>The second parameter is a dictionary of named arguments for the selected action. For example, moving 5m forward with the <code class=\\\"language-none\\\">'move_distance'</code> action is represented by the dictionary <code class=\\\"language-none\\\">{'distance': 5}</code>.</p>\\n<p>Observations lists are received as return values from a <code class=\\\"language-none\\\">BenchBot.step()</code> call (<code class=\\\"language-none\\\">BenchBot.reset()</code> internally calls <code class=\\\"language-none\\\">BenchBot.step(None)</code>, which means don't perform an action):</p>\\n<pre class=\\\"language-python\\\"><code class=\\\"language-python\\\"><span class=\\\"token keyword\\\">from</span> benchbot_api <span class=\\\"token keyword\\\">import</span> BenchBot\\n\\nb <span class=\\\"token operator\\\">=</span> BenchBot<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span>\\nobservations<span class=\\\"token punctuation\\\">,</span> action_result <span class=\\\"token operator\\\">=</span> b<span class=\\\"token punctuation\\\">.</span>reset<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span>\\nobservations<span class=\\\"token punctuation\\\">,</span> action_result <span class=\\\"token operator\\\">=</span> b<span class=\\\"token punctuation\\\">.</span>step<span class=\\\"token punctuation\\\">(</span><span class=\\\"token string\\\">'move_distance'</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token punctuation\\\">{</span><span class=\\\"token string\\\">'distance'</span><span class=\\\"token punctuation\\\">:</span> <span class=\\\"token number\\\">5</span><span class=\\\"token punctuation\\\">}</span><span class=\\\"token punctuation\\\">)</span>\\n</code></pre>\\n<p>The returned <code class=\\\"language-none\\\">observations</code> variable holds a dictionary with key-value pairs corresponding to the name-data defined by each observation channel.</p>\\n<p>The <code class=\\\"language-none\\\">action_result</code> is an enumerated value denoting the result of the action (use <code class=\\\"language-none\\\">from benchbot_api import ActionResult</code> to access the <code class=\\\"language-none\\\">Enum</code> class). You should use this result to guide the progression of your algorithm either manually or in the <code class=\\\"language-none\\\">is_done()</code> method of your <code class=\\\"language-none\\\">Agent</code>. Possible values for the returned <code class=\\\"language-none\\\">action_result</code> are:</p>\\n<ul>\\n<li><code class=\\\"language-none\\\">ActionResult.SUCCESS</code>: the action was carried out successfully</li>\\n<li><code class=\\\"language-none\\\">ActionResult.FINISHED</code>: the action was carried out successfully, and the robot is now finished its traversal through the scene (only used in <code class=\\\"language-none\\\">passive</code> actuation mode)</li>\\n<li><code class=\\\"language-none\\\">ActionResult.COLLISION</code>: the action crashed the robot into an obstacle, and as a result it will not respond to any further actuation commands (at this point you should quit)</li>\\n</ul>\\n<h3>Standard Communication Channels</h3>\\n<p>Tasks and robot definition files declare actions and observations, and these files are include through <a href=https://github.com/qcr/benchbot_addons>BenchBot add-ons</a>. The add-on creator is free to add and declare channels as they please, but it is a better experience for all if channel definitions are as consistent as possible across the BenchBot ecosystem.</p>\\n<p>So if you're adding a robot that move between a set of poses, declare a channel called <code class=\\\"language-none\\\">'move_next</code> with no arguments. Likewise, a robot that receives image observations should use a channel named <code class=\\\"language-none\\\">'image_rgb'</code> with the same format as described below. Feel free to implement the channels however you please for your robot, but consistent interfaces should always be preferred.</p>\\n<p>If you encounter a task using non-standard channel configurations, the API has all the functionality you need as a user to handle them (<code class=\\\"language-none\\\">actions</code>, <code class=\\\"language-none\\\">config</code>, &amp; <code class=\\\"language-none\\\">observations</code> properties). On the other hand, maybe the non-standard channel should be a new standard. New standard communication channels are always welcome; please open a pull request with the details!</p>\\n<h4>Standard action channels:</h4>\\n<table>\\n<thead>\\n<tr>\\n<th>Name</th>\\n<th style=\\\"text-align:center\\\">Required Arguments</th>\\n<th>Description</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td><code class=\\\"language-none\\\">'move_next'</code></td>\\n<td style=\\\"text-align:center\\\"><code class=\\\"language-none\\\">None</code></td>\\n<td>Moves the robot to the next pose in its list of pre-defined poses (only available in environments that declare a <code class=\\\"language-none\\\">'trajectory_poses'</code> field).</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'move_distance'</code></td>\\n<td style=\\\"text-align:center\\\"><pre class=\\\"language-none\\\">{'distance': float}</pre></td>\\n<td>Moves the robot <code class=\\\"language-none\\\">'distance'</code> metres directly ahead.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'move_angle'</code></td>\\n<td style=\\\"text-align:center\\\"><pre class=\\\"language-none\\\">{'angle': float}</pre></td>\\n<td>Rotate the angle on the spot by <code class=\\\"language-none\\\">'angle'</code> degrees.</td>\\n</tr>\\n</tbody>\\n</table>\\n<h4>Standard observation channels:</h4>\\n<table>\\n<thead>\\n<tr>\\n<th>Name</th>\\n<th style=\\\"text-align:left\\\">Data format</th>\\n<th>Description</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td><code class=\\\"language-none\\\">'image_depth'</code></td>\\n<td style=\\\"text-align:left\\\"><pre class=\\\"language-none\\\">numpy.ndarray(shape=(H,W),<br> dtype='float32')</pre></td>\\n<td>Depth image from the default image sensor with depths in meters.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'image_depth_info'</code></td>\\n<td style=\\\"text-align:left\\\"><pre class=\\\"language-none\\\">{<br> 'frame_id': string<br> 'height': int<br> 'width': int<br> 'matrix_instrinsics':<br> numpy.ndarray(shape=(3,3),<br> dtype='float64')<br>'matrix_projection':<br> numpy.ndarray(shape=(3,4)<br> dtype='float64')<br>}</pre></td>\\n<td>Sensor information for the depth image. <code class=\\\"language-none\\\">'matrix_instrinsics'</code> is of the format:<br><pre class=\\\"language-none\\\">[fx 0 cx]<br>[0 fy cy]<br>[0 0 1]</pre> for a camera with focal lengths <code class=\\\"language-none\\\">(fx,fy)</code>, &amp; principal point <code class=\\\"language-none\\\">(cx,cy)</code>. Likewise, <code class=\\\"language-none\\\">'matrix_projection'</code> is:<br><pre class=\\\"language-none\\\">[fx 0 cx Tx]<br>[0 fy cy Ty]<br>[0 0 1 0]</pre>where <code class=\\\"language-none\\\">(Tx,Ty)</code> is the translation between stereo sensors. See <a href=\\\"http://docs.ros.org/melodic/api/sensor_msgs/html/msg/CameraInfo.html\\\">here</a> for further information on fields.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'image_rgb'</code></td>\\n<td style=\\\"text-align:left\\\"><pre class=\\\"language-none\\\">numpy.ndarray(shape=(H,W,3),<br> dtype='uint8')</pre></td>\\n<td>RGB image from the default image sensor with colour values mapped to the 3 channels, in the 0-255 range.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'image_rgb_info'</code></td>\\n<td style=\\\"text-align:left\\\"><pre class=\\\"language-none\\\">{<br> 'frame_id': string<br> 'height': int<br> 'width': int<br> 'matrix_instrinsics':<br> numpy.ndarray(shape=(3,3),<br> dtype='float64')<br>'matrix_projection':<br> numpy.ndarray(shape=(3,4)<br> dtype='float64')<br>}</pre></td>\\n<td>Sensor information for the RGB image. <code class=\\\"language-none\\\">'matrix_instrinsics'</code> is of the format:<br><pre class=\\\"language-none\\\">[fx 0 cx]<br>[0 fy cy]<br>[0 0 1]</pre> for a camera with focal lengths <code class=\\\"language-none\\\">(fx,fy)</code>, &amp; principal point <code class=\\\"language-none\\\">(cx,cy)</code>. Likewise, <code class=\\\"language-none\\\">'matrix_projection'</code> is:<br><pre class=\\\"language-none\\\">[fx 0 cx Tx]<br>[0 fy cy Ty]<br>[0 0 1 0]</pre>where <code class=\\\"language-none\\\">(Tx,Ty)</code> is the translation between stereo sensors. See <a href=\\\"http://docs.ros.org/melodic/api/sensor_msgs/html/msg/CameraInfo.html\\\">here</a> for further information on fields.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'laser'</code></td>\\n<td style=\\\"text-align:left\\\"><pre class=\\\"language-none\\\">{<br> 'range_max': float64,<br> 'range_min': float64,<br> 'scans':<br> numpy.ndarray(shape=(N,2),<br> dtype='float64')<br>}</pre></td>\\n<td>Set of scan values from a laser sensor, between <code class=\\\"language-none\\\">'range_min'</code> &amp; <code class=\\\"language-none\\\">'range_max'</code> (in meters). The <code class=\\\"language-none\\\">'scans'</code> array consists of <code class=\\\"language-none\\\">N</code> scans of format <code class=\\\"language-none\\\">[scan_angle, scan_value]</code>. For example, <code class=\\\"language-none\\\">scans[100,0]</code> would get the angle of the 100th scan &amp; <code class=\\\"language-none\\\">scans[100,1]</code> would get the distance value.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'poses'</code></td>\\n<td style=\\\"text-align:left\\\"><pre class=\\\"language-none\\\">{<br> ...<br> 'frame_name': {<br> 'parent_frame': string<br> 'rotation_rpy':<br> numpy.ndarray(shape=(3,),<br> dtype='float64')<br> 'rotation_xyzw':<br> numpy.ndarray(shape=(4,),<br> dtype='float64')<br> 'translation_xyz':<br> numpy.ndarray(shape=(3,),<br> dtype='float64')<br> }<br> ...<br>}</pre></td>\\n<td>Dictionary of relative poses for the current system state. The pose of each system component is available at key <code class=\\\"language-none\\\">'frame_name'</code>. Each pose has a <code class=\\\"language-none\\\">'parent_frame'</code> which the pose is relative to (all poses are typically with respect to global <code class=\\\"language-none\\\">'map'</code> frame), &amp; the pose values. <code class=\\\"language-none\\\">'rotation_rpy'</code> is <code class=\\\"language-none\\\">[roll,pitch,yaw]</code>, <code class=\\\"language-none\\\">'rotation_xyzw'</code> is the equivalent quaternion <code class=\\\"language-none\\\">[x,y,z,w]</code>, &amp; <code class=\\\"language-none\\\">'translation_xyz'</code> is the Cartesion <code class=\\\"language-none\\\">[x,y,z]</code> coordinates.</td>\\n</tr>\\n</tbody>\\n</table>\\n<h2>Using the API to communicate with the BenchBot system</h2>\\n<p>A running BenchBot system manages many other elements besides simply getting data to and from a real / simulated robot. BenchBot encapsulates not just the robot, but also the environment it is operating in (whether that be simulator or real) and task that is currently being attempted.</p>\\n<p>The API handles communication for all parts of the BenchBot system, including controlling the currently running environment and obtaining configuration information. Below are details for some of the more useful features of the API (all features are also documented in the <a href=https:/github.com/qcr/benchbot_api/blob/master/benchbot_api/benchbot.py><code class=\\\"language-none\\\">benchbot.py</code></a> source code).</p>\\n<h3>Gathering configuration information</h3>\\n<table>\\n<thead>\\n<tr>\\n<th>API method or property</th>\\n<th>Description</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td><code class=\\\"language-none\\\">config</code></td>\\n<td>Returns a <code class=\\\"language-none\\\">dict</code> exhaustively describing the current BenchBot configuration. Most of the information returned will not be useful for general BenchBot use.</td>\\n</tr>\\n</tbody>\\n</table>\\n<h3>Interacting with the environment</h3>\\n<table>\\n<thead>\\n<tr>\\n<th>API method or property</th>\\n<th>Description</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td><code class=\\\"language-none\\\">reset()</code></td>\\n<td>Resets the current environment scene. For the simulator, this means restarting the running simulator instance with the robot back at its initial position. The method returns initial <code class=\\\"language-none\\\">observations</code>, &amp; the <code class=\\\"language-none\\\">action_result</code> (should always be <code class=\\\"language-none\\\">BenchBot.ActionResult.SUCCESS</code>).</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">next_scene()</code></td>\\n<td>Starts the next scene in the current environment (only relevant for tasks with multiple scenes). Note there is no going back once you have moved to the next scene. Returns the same as <code class=\\\"language-none\\\">reset()</code>.</td>\\n</tr>\\n</tbody>\\n</table>\\n<h3>Interacting with an agent</h3>\\n<table>\\n<thead>\\n<tr>\\n<th>API method or property</th>\\n<th>Description</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td><code class=\\\"language-none\\\">actions</code></td>\\n<td>Returns the list of actions currently available to the agent. This will update as actions are performed in the environment (for example if the agent has collided with an obstacle this list will be empty).</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">observations</code></td>\\n<td>Returns the lists of observations available to the agent.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">step(action, **action_args)</code></td>\\n<td>Performs the requested action with the provided named action arguments. See <a href=https:/github.com/qcr/benchbot_api/#using-the-api-to-communicate-with-a-robot>Using the API to communicate with a robot</a> above for further details.</td>\\n</tr>\\n</tbody>\\n</table>\\n<h3>Creating results</h3>\\n<table>\\n<thead>\\n<tr>\\n<th>API method or property</th>\\n<th>Description</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td><code class=\\\"language-none\\\">empty_results()</code></td>\\n<td>Generates a <code class=\\\"language-none\\\">dict</code> of with required result metadata &amp; empty results. Metadata (<code class=\\\"language-none\\\">'task_details'</code> &amp; <code class=\\\"language-none\\\">'environment_details'</code>) is pre-filled. To create results, all a user needs to do is fill in the empty <code class=\\\"language-none\\\">'results'</code> field using format's results functions. These functions are available through the <code class=\\\"language-none\\\">'results_functions()</code> method.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">results_functions()</code></td>\\n<td>Returns a <code class=\\\"language-none\\\">dict</code> of functions defined by the task's <code class=\\\"language-none\\\">'results_format'</code>. Example use for calling a <code class=\\\"language-none\\\">create()</code> function is <code class=\\\"language-none\\\">results_functions()['create']()</code>.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">RESULT_LOCATION</code> (outside of <code class=\\\"language-none\\\">BenchBot</code> class)</td>\\n<td>A static string denoting where results should be saved (<code class=\\\"language-none\\\">/tmp/results</code>). Using this locations ensures tools in the <a href=https://github.com/qcr/benchbot>BenchBot software stack</a> work as expected.</td>\\n</tr>\\n</tbody>\\n</table>\\n\",\"name\":\"BenchBot Python API\",\"type\":\"code\",\"url\":\"https://github.com/qcr/benchbot_api\",\"image_position\":\"center 100%\",\"src\":\"/content/benchbot/benchbot-api.md\",\"id\":\"benchbot-api\",\"image\":\"/_next/static/gifs/566ece96917dbb84cd386109b8457390.jpg\",\"_image\":\"/_next/static/gifs/566ece96917dbb84cd386109b8457390.webm\"}"},"__N_SSG":true}