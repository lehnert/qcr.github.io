<!DOCTYPE html><html><head><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-H0HTWHNLPD"></script><script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
            gtag('config', 'G-H0HTWHNLPD', {
              page_path: window.location.pathname,
            });
          </script><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>QUT Centre for Robotics Open Source</title><meta name="next-head-count" content="3"/><link rel="preload" href="/_next/static/css/ec58676f2add16c92212.css" as="style"/><link rel="stylesheet" href="/_next/static/css/ec58676f2add16c92212.css" data-n-g=""/><link rel="preload" href="/_next/static/css/720c54c06a66d0bc1902.css" as="style"/><link rel="stylesheet" href="/_next/static/css/720c54c06a66d0bc1902.css" data-n-p=""/><noscript data-n-css=""></noscript><link rel="preload" href="/_next/static/chunks/main-c439d75cfca1ce6a0f7f.js" as="script"/><link rel="preload" href="/_next/static/chunks/webpack-50bee04d1dc61f8adf5b.js" as="script"/><link rel="preload" href="/_next/static/chunks/framework.a6402fb70cc88f6f61b0.js" as="script"/><link rel="preload" href="/_next/static/chunks/commons.455c36b53add9c9c2736.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/_app-d07085bfa8b88c39a473.js" as="script"/><link rel="preload" href="/_next/static/chunks/3d04e185781834a6bdd2cdc78a14cbdede4fee55.e5e850c413858c1cae6e.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/%5Blist%5D-3190a030279983f5e879.js" as="script"/></head><body><div id="__next"><div class="site" style="--mdc-theme-on-primary:rgba(255, 255, 255, 1);--mdc-theme-primary:#00407a"><header class="top_bar_bar__3T8Pf mdc-top-app-bar"><div class="top_bar_row__2Br8o mdc-top-app-bar__row"><section class="top_bar_logo-section__-bkhv mdc-top-app-bar__section mdc-top-app-bar__section--align-start"><img class="top_bar_logo__27Lwl" alt="QCR Logo (light)" src="/_next/static/images/qcr_logo_light-3a0967f7c1a32ca7de4713af85481529.png"/></section><section class="top_bar_pages__3emYr mdc-top-app-bar__section mdc-top-app-bar__section--align-end"><button class="top_bar_selected-tab__2hCGV mdc-button"><div class="mdc-button__ripple"></div><span class="mdc-button__label">Collections</span></button><button class="mdc-button"><div class="mdc-button__ripple"></div><span class="mdc-button__label">Code</span></button><button class="mdc-button"><div class="mdc-button__ripple"></div><span class="mdc-button__label">Datasets</span></button></section></div></header><div class="layout_space__3mcnW"></div><div class="layout_main__1OEEk layout_list__2KQH3"><div class="list_cards__1NSVY"><div class="mdc-elevation--z4 mdc-elevation-transition card_card__3y3tW mdc-card"><div class="card_clickable___QgLM mdc-card__primary-action"><img src="/_next/static/gifs/0f460afe63fb093a8b44efcd5c652cf8.jpg" class="card_media__1I_sY" style="object-position:100% center"/><div class="card_footer__2lBtj"><span class="card_extra__1-p0a card_size__nmyRd mdc-typography--body2">Collection</span><span class="mdc-typography--body1">BenchBot</span></div></div></div><div class="mdc-elevation--z4 mdc-elevation-transition card_card__3y3tW mdc-card"><div class="card_clickable___QgLM mdc-card__primary-action"><img src="/_next/static/images/abstract_map_in_action-261a2f7eea1f79411b48203e72995f14.png" class="card_media__1I_sY" style="object-position:center"/><div class="card_footer__2lBtj"><span class="card_extra__1-p0a card_size__nmyRd mdc-typography--body2">Collection</span><span class="mdc-typography--body1">Human Cues for Robot Navigation</span></div></div></div><div class="mdc-elevation--z4 mdc-elevation-transition card_card__3y3tW mdc-card"><div class="card_clickable___QgLM mdc-card__primary-action"><img src="/_next/static/images/RobToolBox_RoundLogoB-9563d226662903b6e404b809e72e3235.png" class="card_media__1I_sY" style="object-position:center;object-fit:contain"/><div class="card_footer__2lBtj"><span class="card_extra__1-p0a card_size__nmyRd mdc-typography--body2">Collection</span><span class="mdc-typography--body1">Python Robotics</span></div></div></div></div></div><div class="bottom_bar_bar__B7RGm"><div class="site-bottom-bar bottom_bar_content__2DVtD"><div></div><div></div><div><span class="mdc-typography--body2">CRICOS No. 00213J</span></div></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"listData":"[{\"content\":\"\u003cp\u003eThe BenchBot software stack is a collection of software packages that allow end users to control robots in real or simulated environments with a simple python API. It leverages the simple \u0026quot;observe, act, repeat\u0026quot; approach to robot problems prevalent in reinforcement learning communities (OpenAI Gym users will find the BenchBot API interface very similar).\u003c/p\u003e\\n\",\"name\":\"BenchBot\",\"type\":\"collection\",\"url\":\"http://benchbot.org\",\"id\":\"benchbot\",\"code\":[{\"content\":\"\u003cp align=center\u003e\u003cstrong\u003e~ Our \u003ca href=\\\"https://evalai.cloudcv.org/web/challenges/challenge-page/807/overview\\\"\u003eRobotic Vision Scene Understanding (RVSU) Challenge is live on EvalAI\u003c/a\u003e ~\u003cbr\u003e(prizes include $2,500USD provided by \u003ca href=\\\"https://www.roboticvision.org/\\\"\u003eACRV\u003c/a\u003e \u0026 GPUs provided by sponsors \u003ca href=\\\"https://www.nvidia.com/en-us/research/robotics/\\\"\u003eNVIDIA\u003c/a\u003e)\u003c/strong\u003e\u003c/p\u003e\\n\u003cp align=center\u003e\u003cstrong\u003e~ Our \u003ca href=\\\"https://github.com/qcr/benchbot/wiki/Tutorial:-Performing-Semantic-SLAM-with-Votenet\\\"\u003eBenchBot tutorial\u003c/a\u003e is the best place to get started developing with BenchBot ~\u003c/strong\u003e\u003c/p\u003e\\n\u003ch1\u003eBenchBot Software Stack\u003c/h1\u003e\\n\u003cp\u003e\u003cvideo autoplay loop poster=\\\"/_next/static/gifs/0f460afe63fb093a8b44efcd5c652cf8.jpg\\\"\u003e\u003csource src=\\\"/_next/static/gifs/0f460afe63fb093a8b44efcd5c652cf8.webm\\\" type=\\\"video/webm\\\"/\u003e\u003c/video\u003e\u003c/p\u003e\\n\u003cp\u003eThe BenchBot software stack is a collection of software packages that allow end users to control robots in real or simulated environments with a simple python API. It leverages the simple \u0026quot;observe, act, repeat\u0026quot; approach to robot problems prevalent in reinforcement learning communities (\u003ca href=\\\"https://gym.openai.com/\\\"\u003eOpenAI Gym\u003c/a\u003e users will find the BenchBot API interface very similar).\u003c/p\u003e\\n\u003cp\u003eBenchBot was created as a tool to assist in the research challenges faced by the semantic scene understanding community; challenges including understanding a scene in simulation, transferring algorithms to real world systems, and meaningfully evaluating algorithm performance. We've since realised, these challenges don't just exist for semantic scene understanding, they're prevalent in a wide range of robotic problems.\u003c/p\u003e\\n\u003cp\u003eThis led us to create version 2 of BenchBot with a focus on allowing users to define their own functionality for BenchBot through \u003ca href=https://github.com/qcr/benchbot_addons\u003eadd-ons\u003c/a\u003e. Want to integrate your own environments? Plug-in new robot platforms? Define new tasks? Share examples with others? Add evaluation measures? This all now possible with add-ons, and you don't have to do anything more than add some YAML and Python files defining your new content!\u003c/p\u003e\\n\u003cp\u003eThe \u0026quot;bench\u0026quot; in \u0026quot;BenchBot\u0026quot; refers to benchmarking, with our goal to provide a system that greatly simplifies the benchmarking of novel algorithms in both realistic 3D simulation and on real robot platforms. If there is something else you would like to use BenchBot for (like integrating different simulators), please let us know. We're very interested in BenchBot being the glue between your novel robotics research and whatever your robot platform may be.\u003c/p\u003e\\n\u003cp\u003eThis repository contains the software stack needed to develop solutions for BenchBot tasks on your local machine. It installs and configures a significant amount of software for you, wraps software in stable Docker images (~50GB), and provides simple interaction with the stack through 4 basic scripts: \u003ccode class=\\\"language-none\\\"\u003ebenchbot_install\u003c/code\u003e, \u003ccode class=\\\"language-none\\\"\u003ebenchbot_run\u003c/code\u003e, \u003ccode class=\\\"language-none\\\"\u003ebenchbot_submit\u003c/code\u003e, and \u003ccode class=\\\"language-none\\\"\u003ebenchbot_eval\u003c/code\u003e.\u003c/p\u003e\\n\u003ch2\u003eSystem recommendations and requirements\u003c/h2\u003e\\n\u003cp\u003eThe BenchBot software stack is designed to run seamlessly on a wide number of system configurations (currently limited to Ubuntu 18.04+). System hardware requirements are relatively high due to the software run for 3D simulation (Unreal Engine, Nvidia Isaac, Vulkan, etc.):\u003c/p\u003e\\n\u003cul\u003e\\n\u003cli\u003eNvidia Graphics card (GeForce GTX 1080 minimum, Titan XP+ / GeForce RTX 2070+ recommended)\u003c/li\u003e\\n\u003cli\u003eCPU with multiple cores (Intel i7-6800K minimum)\u003c/li\u003e\\n\u003cli\u003e32GB+ RAM\u003c/li\u003e\\n\u003cli\u003e64GB+ spare storage (an SSD storage device is \u003cstrong\u003estrongly\u003c/strong\u003e recommended)\u003c/li\u003e\\n\u003c/ul\u003e\\n\u003cp\u003eHaving a system that meets the above hardware requirements is all that is required to begin installing the BenchBot software stack. The install script analyses your system configuration and offers to install any missing software components interactively. The list of 3rd party software components involved includes:\u003c/p\u003e\\n\u003cul\u003e\\n\u003cli\u003eNvidia Driver (4.18+ required, 4.50+ recommended)\u003c/li\u003e\\n\u003cli\u003eCUDA with GPU support (10.0+ required, 10.1+ recommended)\u003c/li\u003e\\n\u003cli\u003eDocker Engine - Community Edition (19.03+ required, 19.03.2+ recommended)\u003c/li\u003e\\n\u003cli\u003eNvidia Container Toolkit (1.0+ required, 1.0.5+ recommended)\u003c/li\u003e\\n\u003cli\u003eISAAC 2019.2 SDK (requires an Nvidia developer login)\u003c/li\u003e\\n\u003c/ul\u003e\\n\u003ch2\u003eManaging your installation\u003c/h2\u003e\\n\u003cp\u003eInstallation is simple:\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003eu@pc:~$ git clone https://github.com/qcr/benchbot \u0026amp;\u0026amp; cd benchbot\\nu@pc:~$ ./install\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eAny missing software components, or configuration issues with your system, should be detected by the install script and resolved interactively. The installation asks if you want to add BenchBot helper scripts to your \u003ccode class=\\\"language-none\\\"\u003ePATH\u003c/code\u003e. Choosing yes will make the following commands available from any directory: \u003ccode class=\\\"language-none\\\"\u003ebenchbot_install\u003c/code\u003e (same as \u003ccode class=\\\"language-none\\\"\u003e./install\u003c/code\u003e above), \u003ccode class=\\\"language-none\\\"\u003ebenchbot_run\u003c/code\u003e, \u003ccode class=\\\"language-none\\\"\u003ebenchbot_submit\u003c/code\u003e, \u003ccode class=\\\"language-none\\\"\u003ebenchbot_eval\u003c/code\u003e, and \u003ccode class=\\\"language-none\\\"\u003ebenchbot_batch\u003c/code\u003e.\u003c/p\u003e\\n\u003cp\u003eBenchBot installs a default set of add-ons (currently \u003ccode class=\\\"language-none\\\"\u003e'benchbot-addons/ssu'\u003c/code\u003e), but this can be changed based on how you want to use BenchBot. For example, the following will also install the \u003ccode class=\\\"language-none\\\"\u003e'benchbot-addons/sqa'\u003c/code\u003e add-ons:\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003eu@pc:~$ benchbot_install --addons benchbot-addons/ssu,benchbot-addons/sqa\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eSee the \u003ca href=https://github.com/qcr/benchbot_addons\u003eBenchBot Add-ons Manager's documentation\u003c/a\u003e for more information on using add-ons.\u003c/p\u003e\\n\u003cp\u003eThe BenchBot software stack will frequently check for updates and can update itself automatically. To update simply run the install script again (add the \u003ccode class=\\\"language-none\\\"\u003e--force-clean\u003c/code\u003e flag if you would like to install from scratch):\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003eu@pc:~$ benchbot_install\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eIf you decide to uninstall the BenchBot software stack, run:\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003eu@pc:~$ benchbot_install --uninstall\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eThere are a number of other options to customise your BenchBot installation, which are all described by running:\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003eu@pc:~$ benchbot_install --help\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003ch2\u003eGetting started\u003c/h2\u003e\\n\u003cp\u003eGetting a solution up and running with BenchBot is as simple as 1,2,3. Here's how to use BenchBot with content from the \u003ca href=https://github.com/benchbot-addons/ssu\u003esemantic scene understanding add-on\u003c/a\u003e:\u003c/p\u003e\\n\u003col\u003e\\n\u003cli\u003e\\n\u003cp\u003eRun a simulator with the BenchBot software stack by selecting an available robot, environment, and task definition:\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003eu@pc:~$ benchbot_run --robot carter --env miniroom:1 --task semantic_slam:active:ground_truth\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eA number of useful flags exist to help you explore what content is available in your installation (see \u003ccode class=\\\"language-none\\\"\u003e--help\u003c/code\u003e for full details). For example, you can list what tasks are available via \u003ccode class=\\\"language-none\\\"\u003e--list-tasks\u003c/code\u003e and view the task specification via \u003ccode class=\\\"language-none\\\"\u003e--show-task TASK_NAME\u003c/code\u003e.\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\\n\u003cp\u003eCreate a solution to a BenchBot task, and run it against the software stack. To run a solution you must select a mode. For example, if you've created a solution in \u003ccode class=\\\"language-none\\\"\u003emy_solution.py\u003c/code\u003e that you would like to run natively:\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003eu@pc:~$ benchbot_submit --native python my_solution.py\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eSee \u003ccode class=\\\"language-none\\\"\u003e--help\u003c/code\u003e for other options. You also have access to all of the examples available in your installation. For instance, you can run the \u003ccode class=\\\"language-none\\\"\u003ehello_active\u003c/code\u003e example in containerised mode via:\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003eu@pc:~$ benchbot_submit --containerised --example hello_active\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eSee \u003ccode class=\\\"language-none\\\"\u003e--list-examples\u003c/code\u003e and \u003ccode class=\\\"language-none\\\"\u003e--show-example EXAMPLE_NAME\u003c/code\u003e for full details on what's available out of the box.\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\\n\u003cp\u003eEvaluate the performance of your system using a supported evaluation method (see \u003ccode class=\\\"language-none\\\"\u003e--list-methods\u003c/code\u003e). To use the \u003ccode class=\\\"language-none\\\"\u003eomq\u003c/code\u003e evaluation method on \u003ccode class=\\\"language-none\\\"\u003emy_results.json\u003c/code\u003e:\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003eu@pc:~$ benchbot_eval --method omq my_results.json\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eYou can also simply run evaluation automatically after your submission completes:\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003eu@pc:~$ benchbot_submit --evaluate-results omq --native --example hello_eval_semantic_slam\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003c/li\u003e\\n\u003c/ol\u003e\\n\u003cp\u003eThe \u003ca href=https://github.com/qcr/benchbot/wiki/Tutorial:-Performing-Semantic-SLAM-with-Votenet\u003eBenchBot Tutorial\u003c/a\u003e is a great place to start working with BenchBot; the tutorial takes you from a blank system to a working Semantic SLAM solution, with many educational steps along the way. Also remember the examples in your installation (\u003ca href=https://github.com/benchbot-addons/examples_base\u003e\u003ccode class=\\\"language-none\\\"\u003ebenchbot-addons/examples_base\u003c/code\u003e\u003c/a\u003e is a good starting point) which show how to get up and running with the BenchBot software stack.\u003c/p\u003e\\n\u003ch2\u003ePower tools for autonomous algorithm evaluation\u003c/h2\u003e\\n\u003cp\u003eOnce you are confident your algorithm is a solution to the chosen task, the BenchBot software stack's power tools allow you to comprehensively explore your algorithm's performance. You can autonomously run your algorithm over multiple environments, and evaluate it holistically to produce a single summary statistic of your algorithm's performance. Here are some examples again with content from the \u003ca href=https://github.com/benchbot-addons/ssu\u003esemantic scene understanding add-on\u003c/a\u003e:\u003c/p\u003e\\n\u003cul\u003e\\n\u003cli\u003e\\n\u003cp\u003eUse \u003ccode class=\\\"language-none\\\"\u003ebenchbot_batch\u003c/code\u003e to run your algorithm in a number of environments and produce a set of results. The script has a number of toggles available to customise the process (see \u003ccode class=\\\"language-none\\\"\u003e--help\u003c/code\u003e for full details). To autonomously run your \u003ccode class=\\\"language-none\\\"\u003esemantic_slam:active:ground_truth\u003c/code\u003e algorithm over 3 environments:\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003eu@pc:~$ benchbot_batch --robot carter --task semantic_slam:active:ground_truth --envs miniroom:1,miniroom:3,house:5 --native python my_solution.py\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eOr you can use one of the pre-defined environment batches installed via add-ons (e.g. \u003ca href=https://github.com/benchbot-addons/batches_isaac\u003e\u003ccode class=\\\"language-none\\\"\u003ebenchbot-addons/batches_isaac\u003c/code\u003e\u003c/a\u003e):\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003eu@pc:~$ benchbot_batch --robot carter --task semantic_slam:active:ground_truth --envs-batch develop_1 --native python my_solution.py\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eAdditionally, you can create a results ZIP and request an overall evaluation score at the end of the batch:\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003eu@pc:~$ benchbot_batch --robot carter --task semantic_slam:active:ground_truth --envs miniroom:1,miniroom:3,house:5 --zip --score-results omq --native python my_solution.py\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eLastly, both native and containerised submissions are supported exactly as in \u003ccode class=\\\"language-none\\\"\u003ebenchbot_submit\u003c/code\u003e:\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003eu@pc:~$ benchbot_batch --robot carter --task semantic_slam:active:ground_truth --envs miniroom:1,miniroom:3,house:5 --containerised my_solution_folder/\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\\n\u003cp\u003eYou can also directly call the holistic evaluation performed above by \u003ccode class=\\\"language-none\\\"\u003ebenchbot_batch\u003c/code\u003e through the \u003ccode class=\\\"language-none\\\"\u003ebenchbot_eval\u003c/code\u003e script. The script supports single result files, multiple results files, or a ZIP of multiple results files. See \u003ccode class=\\\"language-none\\\"\u003ebenchbot_eval --help\u003c/code\u003e for full details. Below are examples calling \u003ccode class=\\\"language-none\\\"\u003ebenchbot_eval\u003c/code\u003e with a series of results and a ZIP of results respectively:\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003eu@pc:~$ benchbot_eval --method omq -o my_jsons_scores result_1.json result_2.json result_3.json\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003eu@pc:~$ benchbot_eval --method omq -o my_zip_scores results.zip\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003c/li\u003e\\n\u003c/ul\u003e\\n\u003ch2\u003eUsing BenchBot in your research\u003c/h2\u003e\\n\u003cp\u003eBenchBot was made to enable and assist the development of high quality, repeatable research results. We welcome any and all use of the BenchBot software stack in your research.\u003c/p\u003e\\n\u003cp\u003eTo use our system, we just ask that you cite our paper on the BenchBot system. This will help us follow uses of BenchBot in the research community, and understand how we can improve the system to help support future research results. Citation details are as follows:\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003e@misc{talbot2020benchbot,\\n    title={BenchBot: Evaluating Robotics Research in Photorealistic 3D Simulation and on Real Robots},\\n    author={Ben Talbot and David Hall and Haoyang Zhang and Suman Raj Bista and Rohan Smith and Feras Dayoub and Niko Sünderhauf},\\n    year={2020},\\n    eprint={2008.00635},\\n    archivePrefix={arXiv},\\n    primaryClass={cs.RO}\\n}\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003ch2\u003eComponents of the BenchBot software stack\u003c/h2\u003e\\n\u003cp\u003eThe BenchBot software stack is split into a number of standalone components, each with their own GitHub repository and documentation. This repository glues them all together for you into a working system. The components of the stack are:\u003c/p\u003e\\n\u003cul\u003e\\n\u003cli\u003e\u003cstrong\u003e\u003ca href=https://github.com/qcr/benchbot_api\u003ebenchbot_api\u003c/a\u003e:\u003c/strong\u003e user-facing Python interface to the BenchBot system, allowing the user to control simulated or real robots in simulated or real world environments through simple commands\u003c/li\u003e\\n\u003cli\u003e\u003cstrong\u003e\u003ca href=https://github.com/qcr/benchbot_addons\u003ebenchbot_addons\u003c/a\u003e:\u003c/strong\u003e a Python manager for add-ons to a BenchBot system, with full documentation on how to create and add your own add-ons\u003c/li\u003e\\n\u003cli\u003e\u003cstrong\u003e\u003ca href=https://github.com/qcr/benchbot_supervisor\u003ebenchbot_supervisor\u003c/a\u003e:\u003c/strong\u003e a HTTP server facilitating communication between user-facing interfaces and the underlying robot controller\u003c/li\u003e\\n\u003cli\u003e\u003cstrong\u003e\u003ca href=https://github.com/qcr/benchbot_robot_controller\u003ebenchbot_robot_controller\u003c/a\u003e:\u003c/strong\u003e a wrapping script which controls the low-level ROS functionality of a simulator or real robot, handles automated subprocess management, and exposes interaction via a HTTP server\u003c/li\u003e\\n\u003cli\u003e\u003cstrong\u003e\u003ca href=https://github.com/qcr/benchbot_simulator\u003ebenchbot_simulator\u003c/a\u003e:\u003c/strong\u003e a realistic 3D simulator employing Nvidia's Isaac framework, in combination with Unreal Engine environments\u003c/li\u003e\\n\u003cli\u003e\u003cstrong\u003e\u003ca href=https://github.com/qcr/benchbot_eval\u003ebenchbot_eval\u003c/a\u003e:\u003c/strong\u003e Python library for evaluating the performance in a task, based on the results produced by a submission\u003c/li\u003e\\n\u003c/ul\u003e\\n\u003ch2\u003eFurther information\u003c/h2\u003e\\n\u003cul\u003e\\n\u003cli\u003e\u003cstrong\u003e\u003ca href=https://github.com/qcr/benchbot/wiki/FAQs\u003eFAQs\u003c/a\u003e:\u003c/strong\u003e Wiki page where answers to frequently asked questions and resolutions to common issues will be provided\u003c/li\u003e\\n\u003cli\u003e\u003cstrong\u003e\u003ca href=https://github.com/qcr/benchbot/wiki/Tutorial:-Performing-Semantic-SLAM-with-Votenet\u003eSemantic SLAM Tutorial\u003c/a\u003e:\u003c/strong\u003e a tutorial stepping through creating a semantic SLAM system in BenchBot that utilises the 3D object detector \u003ca href=https://github.com/facebookresearch/votenet\u003eVoteNet\u003c/a\u003e\u003c/li\u003e\\n\u003c/ul\u003e\\n\u003ch2\u003eSupporters\u003c/h2\u003e\\n\u003cp\u003eDevelopment of the BenchBot software stack was directly supported by:\u003c/p\u003e\\n\u003cp\u003e\u003ca href=\\\"https://www.roboticvision.org/\\\"\u003e\u003cimg src=\\\"/_next/static/images/acrv_logo_small-e816f01e0557cf5cee1e9eb709d9a5e5.png\\\" alt=\\\"Australian Centre for Robotic Vision\\\"\u003e\u003c/a\u003e        \u003ca href=\\\"https://research.qut.edu.au/qcr/\\\"\u003e\u003cimg src=\\\"data:image/png;base64,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\\\" alt=\\\"QUT Centre for Robotics\\\"\u003e\u003c/a\u003e\u003c/p\u003e\\n\",\"name\":\"BenchBot Software Stack\",\"type\":\"code\",\"url\":\"https://github.com/qcr/benchbot\",\"image_position\":\"100% center\",\"src\":\"/content/benchbot/benchbot.md\",\"id\":\"benchbot\",\"image\":\"/_next/static/gifs/0f460afe63fb093a8b44efcd5c652cf8.jpg\",\"_image\":\"/_next/static/gifs/0f460afe63fb093a8b44efcd5c652cf8.webm\"},{\"content\":\"\u003cp\u003e\u003cstrong\u003eNOTE: this software needs to interface with a running instance of the BenchBot software stack. Unless you are running against a remote stack / robot, please install this software with the BenchBot software stack as described \u003ca href=https://github.com/qcr/benchbot\u003ehere\u003c/a\u003e.\u003c/strong\u003e\u003c/p\u003e\\n\u003ch1\u003eBenchBot API\u003c/h1\u003e\\n\u003cp\u003e\u003cvideo autoplay loop poster=\\\"/_next/static/gifs/566ece96917dbb84cd386109b8457390.jpg\\\"\u003e\u003csource src=\\\"/_next/static/gifs/566ece96917dbb84cd386109b8457390.webm\\\" type=\\\"video/webm\\\"/\u003e\u003c/video\u003e\u003c/p\u003e\\n\u003cp\u003eThe BenchBot API provides a simple interface for controlling a robot or simulator through actions, and receiving data through observations. As shown above, the entire code required for running an agent in a realistic 3D simulator is only a handful of simple Python commands.\u003c/p\u003e\\n\u003cp\u003e\u003ca href=\\\"https://gym.openai.com\\\"\u003eOpen AI Gym\u003c/a\u003e users will find the breakdown into actions, observations, and steps extremely familiar. BenchBot API allows researchers to develop and test novel algorithms with real robot systems and realistic 3D simulators, without the typical hassles arising when interfacing with complicated multi-component robot systems.\u003c/p\u003e\\n\u003cp\u003eRunning a robot through an entire environment, with your own custom agent, is as simple as one line of code with the BenchBot API:\u003c/p\u003e\\n\u003cpre class=\\\"language-python\\\"\u003e\u003ccode class=\\\"language-python\\\"\u003e\u003cspan class=\\\"token keyword\\\"\u003efrom\u003c/span\u003e benchbot_api \u003cspan class=\\\"token keyword\\\"\u003eimport\u003c/span\u003e BenchBot\\n\u003cspan class=\\\"token keyword\\\"\u003efrom\u003c/span\u003e my_agent \u003cspan class=\\\"token keyword\\\"\u003eimport\u003c/span\u003e MyAgent\\n\\nBenchBot\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003eagent\u003cspan class=\\\"token operator\\\"\u003e=\u003c/span\u003eMyAgent\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003erun\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eThe above assumes you have created your own agent by overloading the abstract \u003ccode class=\\\"language-none\\\"\u003eAgent\u003c/code\u003e class provided with the API. Overloading the abstract class requires implementing 3 basic methods. Below is a basic example to spin on the spot:\u003c/p\u003e\\n\u003cpre class=\\\"language-python\\\"\u003e\u003ccode class=\\\"language-python\\\"\u003e\u003cspan class=\\\"token keyword\\\"\u003efrom\u003c/span\u003e benchbot_api \u003cspan class=\\\"token keyword\\\"\u003eimport\u003c/span\u003e Agent\\n\u003cspan class=\\\"token keyword\\\"\u003eimport\u003c/span\u003e json\\n\\n\u003cspan class=\\\"token keyword\\\"\u003eclass\u003c/span\u003e \u003cspan class=\\\"token class-name\\\"\u003eMyAgent\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003eAgent\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e:\u003c/span\u003e\\n\\n    \u003cspan class=\\\"token keyword\\\"\u003edef\u003c/span\u003e \u003cspan class=\\\"token function\\\"\u003eis_done\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003eself\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e action_result\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e:\u003c/span\u003e\\n        \u003cspan class=\\\"token comment\\\"\u003e# Go forever\u003c/span\u003e\\n        \u003cspan class=\\\"token keyword\\\"\u003ereturn\u003c/span\u003e \u003cspan class=\\\"token boolean\\\"\u003eFalse\u003c/span\u003e\\n\\n    \u003cspan class=\\\"token keyword\\\"\u003edef\u003c/span\u003e \u003cspan class=\\\"token function\\\"\u003epick_action\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003eself\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e observations\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e action_list\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e:\u003c/span\u003e\\n        \u003cspan class=\\\"token comment\\\"\u003e# Rotates on the spot indefinitely, 5 degrees at a time\u003c/span\u003e\\n        \u003cspan class=\\\"token comment\\\"\u003e# (assumes we are running in passive mode)\u003c/span\u003e\\n        \u003cspan class=\\\"token keyword\\\"\u003ereturn\u003c/span\u003e \u003cspan class=\\\"token string\\\"\u003e'move_angle'\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e \u003cspan class=\\\"token punctuation\\\"\u003e{\u003c/span\u003e\u003cspan class=\\\"token string\\\"\u003e'angle'\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e:\u003c/span\u003e \u003cspan class=\\\"token number\\\"\u003e5\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e}\u003c/span\u003e\\n\\n    \u003cspan class=\\\"token keyword\\\"\u003edef\u003c/span\u003e \u003cspan class=\\\"token function\\\"\u003esave_result\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003eself\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e filename\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e empty_results\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e results_format_fns\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e:\u003c/span\u003e\\n        \u003cspan class=\\\"token comment\\\"\u003e# Save some blank results\u003c/span\u003e\\n        \u003cspan class=\\\"token keyword\\\"\u003ewith\u003c/span\u003e \u003cspan class=\\\"token builtin\\\"\u003eopen\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003efilename\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e \u003cspan class=\\\"token string\\\"\u003e'w'\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e \u003cspan class=\\\"token keyword\\\"\u003eas\u003c/span\u003e f\u003cspan class=\\\"token punctuation\\\"\u003e:\u003c/span\u003e\\n            json\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003edump\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003eempty_results\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e f\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eIf you prefer to do things manually, a more exhaustive suite of functions are also available as part of the BenchBot API. Instead of using the \u003ccode class=\\\"language-none\\\"\u003eBenchBot.run()\u003c/code\u003e method, a large number of methods are available through the API. Below highlights a handful of the capabilities of BenchBot API:\u003c/p\u003e\\n\u003cpre class=\\\"language-python\\\"\u003e\u003ccode class=\\\"language-python\\\"\u003e\u003cspan class=\\\"token keyword\\\"\u003efrom\u003c/span\u003e benchbot_api \u003cspan class=\\\"token keyword\\\"\u003eimport\u003c/span\u003e BenchBot\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e RESULT_LOCATION\\n\u003cspan class=\\\"token keyword\\\"\u003eimport\u003c/span\u003e json\\n\u003cspan class=\\\"token keyword\\\"\u003eimport\u003c/span\u003e matplotlib\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003epyplot \u003cspan class=\\\"token keyword\\\"\u003eas\u003c/span\u003e plt\\n\\n\u003cspan class=\\\"token comment\\\"\u003e# Create a BenchBot instance \u0026amp; reset the simulator / robot to starting state\u003c/span\u003e\\nb \u003cspan class=\\\"token operator\\\"\u003e=\u003c/span\u003e BenchBot\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\nobservations\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e action_result \u003cspan class=\\\"token operator\\\"\u003e=\u003c/span\u003e b\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003ereset\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n\\n\u003cspan class=\\\"token comment\\\"\u003e# Print details of selected task \u0026amp; environment\u003c/span\u003e\\n\u003cspan class=\\\"token keyword\\\"\u003eprint\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003eb\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003etask_details\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n\u003cspan class=\\\"token keyword\\\"\u003eprint\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003eb\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eenvironment_details\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n\\n\u003cspan class=\\\"token comment\\\"\u003e# Visualise the current RGB image from the robot\u003c/span\u003e\\nplt\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eimshow\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003eobservations\u003cspan class=\\\"token punctuation\\\"\u003e[\u003c/span\u003e\u003cspan class=\\\"token string\\\"\u003e'image_rgb'\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e]\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n\\n\u003cspan class=\\\"token comment\\\"\u003e# Move to the next pose if we have a 'move_next' action available\u003c/span\u003e\\n\u003cspan class=\\\"token keyword\\\"\u003eif\u003c/span\u003e \u003cspan class=\\\"token string\\\"\u003e'move_next'\u003c/span\u003e \u003cspan class=\\\"token keyword\\\"\u003ein\u003c/span\u003e b\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eactions\u003cspan class=\\\"token punctuation\\\"\u003e:\u003c/span\u003e\\n    observations\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e action_result \u003cspan class=\\\"token operator\\\"\u003e=\u003c/span\u003e b\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003estep\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token string\\\"\u003e'move_next'\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n\\n\u003cspan class=\\\"token comment\\\"\u003e# Save some empty results\u003c/span\u003e\\n\u003cspan class=\\\"token keyword\\\"\u003ewith\u003c/span\u003e \u003cspan class=\\\"token builtin\\\"\u003eopen\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003eRESULT_LOCATION\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e \u003cspan class=\\\"token string\\\"\u003e'w'\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e \u003cspan class=\\\"token keyword\\\"\u003eas\u003c/span\u003e f\u003cspan class=\\\"token punctuation\\\"\u003e:\u003c/span\u003e\\n    json\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003edump\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003eb\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eempty_results\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e f\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eFor sample solutions that use the BenchBot API, see the examples add-ons available (e.g. \u003ca href=https://github.com/benchbot-addons/examples_base\u003e\u003ccode class=\\\"language-none\\\"\u003ebenchbot-addons/examples_base\u003c/code\u003e\u003c/a\u003e and \u003ca href=https://github.com/benchbot-addons/examples_ssu\u003e\u003ccode class=\\\"language-none\\\"\u003ebenchbot-addons/examples_ssu\u003c/code\u003e\u003c/a\u003e).\u003c/p\u003e\\n\u003ch2\u003eInstalling BenchBot API\u003c/h2\u003e\\n\u003cp\u003eBenchBot API is a Python package, installable with pip. Run the following in the root directory of where this repository was cloned:\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003eu@pc:~$ pip install .\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003ch2\u003eUsing the API to communicate with a robot\u003c/h2\u003e\\n\u003cp\u003eCommunication with the robot comes through a series of \u0026quot;channels\u0026quot; which are defined by the robot's definition file (e.g. \u003ca href=https://github.com/benchbot-addons/robots_isaac/blob/master/robots/carter.yaml\u003ecarter\u003c/a\u003e). A task definition file (e.g. \u003ca href=https://github.com/benchbot-addons/tasks_ssu/blob/master/tasks/sslam_pgt.yaml\u003esemantic_slam:passive:ground_truth\u003c/a\u003e) then declares which of these connections are provided to the API as either sensor observations or actions to be executed by a robot actuator.\u003c/p\u003e\\n\u003cp\u003eThe API talks to the \u003ca href=https://github.com/qcr/benchbot_supervisor\u003eBenchBot Supervisor\u003c/a\u003e, which handles loading and managing the different kinds of back-end configuration files. This abstracts all of the underlying communication complexities away from the user, allowing the BenchBot API to remain a simple interface that focuses on getting observations and sending actions.\u003c/p\u003e\\n\u003cp\u003eAn action is sent to the robot by calling the \u003ccode class=\\\"language-none\\\"\u003eBenchBot.step()\u003c/code\u003e method with a valid action (found by checking the \u003ccode class=\\\"language-none\\\"\u003eBenchBot.actions\u003c/code\u003e property):\u003c/p\u003e\\n\u003cpre class=\\\"language-python\\\"\u003e\u003ccode class=\\\"language-python\\\"\u003e\u003cspan class=\\\"token keyword\\\"\u003efrom\u003c/span\u003e benchbot_api \u003cspan class=\\\"token keyword\\\"\u003eimport\u003c/span\u003e BenchBot\\n\\nb \u003cspan class=\\\"token operator\\\"\u003e=\u003c/span\u003e BenchBot\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\navailable_actions \u003cspan class=\\\"token operator\\\"\u003e=\u003c/span\u003e b\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eactions\\nb\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003estep\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003eb\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eactions\u003cspan class=\\\"token punctuation\\\"\u003e[\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e]\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e \u003cspan class=\\\"token punctuation\\\"\u003e{\u003c/span\u003e\u003cspan class=\\\"token string\\\"\u003e'action_arg:'\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e arg_value\u003cspan class=\\\"token punctuation\\\"\u003e}\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e  \u003cspan class=\\\"token comment\\\"\u003e# Perform the first available action\u003c/span\u003e\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eThe second parameter is a dictionary of named arguments for the selected action. For example, moving 5m forward with the \u003ccode class=\\\"language-none\\\"\u003e'move_distance'\u003c/code\u003e action is represented by the dictionary \u003ccode class=\\\"language-none\\\"\u003e{'distance': 5}\u003c/code\u003e.\u003c/p\u003e\\n\u003cp\u003eObservations lists are received as return values from a \u003ccode class=\\\"language-none\\\"\u003eBenchBot.step()\u003c/code\u003e call (\u003ccode class=\\\"language-none\\\"\u003eBenchBot.reset()\u003c/code\u003e internally calls \u003ccode class=\\\"language-none\\\"\u003eBenchBot.step(None)\u003c/code\u003e, which means don't perform an action):\u003c/p\u003e\\n\u003cpre class=\\\"language-python\\\"\u003e\u003ccode class=\\\"language-python\\\"\u003e\u003cspan class=\\\"token keyword\\\"\u003efrom\u003c/span\u003e benchbot_api \u003cspan class=\\\"token keyword\\\"\u003eimport\u003c/span\u003e BenchBot\\n\\nb \u003cspan class=\\\"token operator\\\"\u003e=\u003c/span\u003e BenchBot\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\nobservations\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e action_result \u003cspan class=\\\"token operator\\\"\u003e=\u003c/span\u003e b\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003ereset\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\nobservations\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e action_result \u003cspan class=\\\"token operator\\\"\u003e=\u003c/span\u003e b\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003estep\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token string\\\"\u003e'move_distance'\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e \u003cspan class=\\\"token punctuation\\\"\u003e{\u003c/span\u003e\u003cspan class=\\\"token string\\\"\u003e'distance'\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e:\u003c/span\u003e \u003cspan class=\\\"token number\\\"\u003e5\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e}\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eThe returned \u003ccode class=\\\"language-none\\\"\u003eobservations\u003c/code\u003e variable holds a dictionary with key-value pairs corresponding to the name-data defined by each observation channel.\u003c/p\u003e\\n\u003cp\u003eThe \u003ccode class=\\\"language-none\\\"\u003eaction_result\u003c/code\u003e is an enumerated value denoting the result of the action (use \u003ccode class=\\\"language-none\\\"\u003efrom benchbot_api import ActionResult\u003c/code\u003e to access the \u003ccode class=\\\"language-none\\\"\u003eEnum\u003c/code\u003e class). You should use this result to guide the progression of your algorithm either manually or in the \u003ccode class=\\\"language-none\\\"\u003eis_done()\u003c/code\u003e method of your \u003ccode class=\\\"language-none\\\"\u003eAgent\u003c/code\u003e. Possible values for the returned \u003ccode class=\\\"language-none\\\"\u003eaction_result\u003c/code\u003e are:\u003c/p\u003e\\n\u003cul\u003e\\n\u003cli\u003e\u003ccode class=\\\"language-none\\\"\u003eActionResult.SUCCESS\u003c/code\u003e: the action was carried out successfully\u003c/li\u003e\\n\u003cli\u003e\u003ccode class=\\\"language-none\\\"\u003eActionResult.FINISHED\u003c/code\u003e: the action was carried out successfully, and the robot is now finished its traversal through the scene (only used in \u003ccode class=\\\"language-none\\\"\u003epassive\u003c/code\u003e actuation mode)\u003c/li\u003e\\n\u003cli\u003e\u003ccode class=\\\"language-none\\\"\u003eActionResult.COLLISION\u003c/code\u003e: the action crashed the robot into an obstacle, and as a result it will not respond to any further actuation commands (at this point you should quit)\u003c/li\u003e\\n\u003c/ul\u003e\\n\u003ch3\u003eStandard Communication Channels\u003c/h3\u003e\\n\u003cp\u003eTasks and robot definition files declare actions and observations, and these files are include through \u003ca href=https://github.com/qcr/benchbot_addons\u003eBenchBot add-ons\u003c/a\u003e. The add-on creator is free to add and declare channels as they please, but it is a better experience for all if channel definitions are as consistent as possible across the BenchBot ecosystem.\u003c/p\u003e\\n\u003cp\u003eSo if you're adding a robot that move between a set of poses, declare a channel called \u003ccode class=\\\"language-none\\\"\u003e'move_next\u003c/code\u003e with no arguments. Likewise, a robot that receives image observations should use a channel named \u003ccode class=\\\"language-none\\\"\u003e'image_rgb'\u003c/code\u003e with the same format as described below. Feel free to implement the channels however you please for your robot, but consistent interfaces should always be preferred.\u003c/p\u003e\\n\u003cp\u003eIf you encounter a task using non-standard channel configurations, the API has all the functionality you need as a user to handle them (\u003ccode class=\\\"language-none\\\"\u003eactions\u003c/code\u003e, \u003ccode class=\\\"language-none\\\"\u003econfig\u003c/code\u003e, \u0026amp; \u003ccode class=\\\"language-none\\\"\u003eobservations\u003c/code\u003e properties). On the other hand, maybe the non-standard channel should be a new standard. New standard communication channels are always welcome; please open a pull request with the details!\u003c/p\u003e\\n\u003ch4\u003eStandard action channels:\u003c/h4\u003e\\n\u003ctable\u003e\\n\u003cthead\u003e\\n\u003ctr\u003e\\n\u003cth\u003eName\u003c/th\u003e\\n\u003cth style=\\\"text-align:center\\\"\u003eRequired Arguments\u003c/th\u003e\\n\u003cth\u003eDescription\u003c/th\u003e\\n\u003c/tr\u003e\\n\u003c/thead\u003e\\n\u003ctbody\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'move_next'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd style=\\\"text-align:center\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003eNone\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eMoves the robot to the next pose in its list of pre-defined poses (only available in environments that declare a \u003ccode class=\\\"language-none\\\"\u003e'trajectory_poses'\u003c/code\u003e field).\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'move_distance'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd style=\\\"text-align:center\\\"\u003e\u003cpre class=\\\"language-none\\\"\u003e{'distance': float}\u003c/pre\u003e\u003c/td\u003e\\n\u003ctd\u003eMoves the robot \u003ccode class=\\\"language-none\\\"\u003e'distance'\u003c/code\u003e metres directly ahead.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'move_angle'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd style=\\\"text-align:center\\\"\u003e\u003cpre class=\\\"language-none\\\"\u003e{'angle': float}\u003c/pre\u003e\u003c/td\u003e\\n\u003ctd\u003eRotate the angle on the spot by \u003ccode class=\\\"language-none\\\"\u003e'angle'\u003c/code\u003e degrees.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003c/tbody\u003e\\n\u003c/table\u003e\\n\u003ch4\u003eStandard observation channels:\u003c/h4\u003e\\n\u003ctable\u003e\\n\u003cthead\u003e\\n\u003ctr\u003e\\n\u003cth\u003eName\u003c/th\u003e\\n\u003cth style=\\\"text-align:left\\\"\u003eData format\u003c/th\u003e\\n\u003cth\u003eDescription\u003c/th\u003e\\n\u003c/tr\u003e\\n\u003c/thead\u003e\\n\u003ctbody\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'image_depth'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd style=\\\"text-align:left\\\"\u003e\u003cpre class=\\\"language-none\\\"\u003enumpy.ndarray(shape=(H,W),\u003cbr\u003e dtype='float32')\u003c/pre\u003e\u003c/td\u003e\\n\u003ctd\u003eDepth image from the default image sensor with depths in meters.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'image_depth_info'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd style=\\\"text-align:left\\\"\u003e\u003cpre class=\\\"language-none\\\"\u003e{\u003cbr\u003e 'frame_id': string\u003cbr\u003e 'height': int\u003cbr\u003e 'width': int\u003cbr\u003e 'matrix_instrinsics':\u003cbr\u003e numpy.ndarray(shape=(3,3),\u003cbr\u003e dtype='float64')\u003cbr\u003e'matrix_projection':\u003cbr\u003e numpy.ndarray(shape=(3,4)\u003cbr\u003e dtype='float64')\u003cbr\u003e}\u003c/pre\u003e\u003c/td\u003e\\n\u003ctd\u003eSensor information for the depth image. \u003ccode class=\\\"language-none\\\"\u003e'matrix_instrinsics'\u003c/code\u003e is of the format:\u003cbr\u003e\u003cpre class=\\\"language-none\\\"\u003e[fx 0 cx]\u003cbr\u003e[0 fy cy]\u003cbr\u003e[0 0 1]\u003c/pre\u003e for a camera with focal lengths \u003ccode class=\\\"language-none\\\"\u003e(fx,fy)\u003c/code\u003e, \u0026amp; principal point \u003ccode class=\\\"language-none\\\"\u003e(cx,cy)\u003c/code\u003e. Likewise, \u003ccode class=\\\"language-none\\\"\u003e'matrix_projection'\u003c/code\u003e is:\u003cbr\u003e\u003cpre class=\\\"language-none\\\"\u003e[fx 0 cx Tx]\u003cbr\u003e[0 fy cy Ty]\u003cbr\u003e[0 0 1 0]\u003c/pre\u003ewhere \u003ccode class=\\\"language-none\\\"\u003e(Tx,Ty)\u003c/code\u003e is the translation between stereo sensors. See \u003ca href=\\\"http://docs.ros.org/melodic/api/sensor_msgs/html/msg/CameraInfo.html\\\"\u003ehere\u003c/a\u003e for further information on fields.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'image_rgb'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd style=\\\"text-align:left\\\"\u003e\u003cpre class=\\\"language-none\\\"\u003enumpy.ndarray(shape=(H,W,3),\u003cbr\u003e dtype='uint8')\u003c/pre\u003e\u003c/td\u003e\\n\u003ctd\u003eRGB image from the default image sensor with colour values mapped to the 3 channels, in the 0-255 range.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'image_rgb_info'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd style=\\\"text-align:left\\\"\u003e\u003cpre class=\\\"language-none\\\"\u003e{\u003cbr\u003e 'frame_id': string\u003cbr\u003e 'height': int\u003cbr\u003e 'width': int\u003cbr\u003e 'matrix_instrinsics':\u003cbr\u003e numpy.ndarray(shape=(3,3),\u003cbr\u003e dtype='float64')\u003cbr\u003e'matrix_projection':\u003cbr\u003e numpy.ndarray(shape=(3,4)\u003cbr\u003e dtype='float64')\u003cbr\u003e}\u003c/pre\u003e\u003c/td\u003e\\n\u003ctd\u003eSensor information for the RGB image. \u003ccode class=\\\"language-none\\\"\u003e'matrix_instrinsics'\u003c/code\u003e is of the format:\u003cbr\u003e\u003cpre class=\\\"language-none\\\"\u003e[fx 0 cx]\u003cbr\u003e[0 fy cy]\u003cbr\u003e[0 0 1]\u003c/pre\u003e for a camera with focal lengths \u003ccode class=\\\"language-none\\\"\u003e(fx,fy)\u003c/code\u003e, \u0026amp; principal point \u003ccode class=\\\"language-none\\\"\u003e(cx,cy)\u003c/code\u003e. Likewise, \u003ccode class=\\\"language-none\\\"\u003e'matrix_projection'\u003c/code\u003e is:\u003cbr\u003e\u003cpre class=\\\"language-none\\\"\u003e[fx 0 cx Tx]\u003cbr\u003e[0 fy cy Ty]\u003cbr\u003e[0 0 1 0]\u003c/pre\u003ewhere \u003ccode class=\\\"language-none\\\"\u003e(Tx,Ty)\u003c/code\u003e is the translation between stereo sensors. See \u003ca href=\\\"http://docs.ros.org/melodic/api/sensor_msgs/html/msg/CameraInfo.html\\\"\u003ehere\u003c/a\u003e for further information on fields.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'laser'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd style=\\\"text-align:left\\\"\u003e\u003cpre class=\\\"language-none\\\"\u003e{\u003cbr\u003e 'range_max': float64,\u003cbr\u003e 'range_min': float64,\u003cbr\u003e 'scans':\u003cbr\u003e numpy.ndarray(shape=(N,2),\u003cbr\u003e dtype='float64')\u003cbr\u003e}\u003c/pre\u003e\u003c/td\u003e\\n\u003ctd\u003eSet of scan values from a laser sensor, between \u003ccode class=\\\"language-none\\\"\u003e'range_min'\u003c/code\u003e \u0026amp; \u003ccode class=\\\"language-none\\\"\u003e'range_max'\u003c/code\u003e (in meters). The \u003ccode class=\\\"language-none\\\"\u003e'scans'\u003c/code\u003e array consists of \u003ccode class=\\\"language-none\\\"\u003eN\u003c/code\u003e scans of format \u003ccode class=\\\"language-none\\\"\u003e[scan_angle, scan_value]\u003c/code\u003e. For example, \u003ccode class=\\\"language-none\\\"\u003escans[100,0]\u003c/code\u003e would get the angle of the 100th scan \u0026amp; \u003ccode class=\\\"language-none\\\"\u003escans[100,1]\u003c/code\u003e would get the distance value.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'poses'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd style=\\\"text-align:left\\\"\u003e\u003cpre class=\\\"language-none\\\"\u003e{\u003cbr\u003e ...\u003cbr\u003e 'frame_name': {\u003cbr\u003e 'parent_frame': string\u003cbr\u003e 'rotation_rpy':\u003cbr\u003e numpy.ndarray(shape=(3,),\u003cbr\u003e dtype='float64')\u003cbr\u003e 'rotation_xyzw':\u003cbr\u003e numpy.ndarray(shape=(4,),\u003cbr\u003e dtype='float64')\u003cbr\u003e 'translation_xyz':\u003cbr\u003e numpy.ndarray(shape=(3,),\u003cbr\u003e dtype='float64')\u003cbr\u003e }\u003cbr\u003e ...\u003cbr\u003e}\u003c/pre\u003e\u003c/td\u003e\\n\u003ctd\u003eDictionary of relative poses for the current system state. The pose of each system component is available at key \u003ccode class=\\\"language-none\\\"\u003e'frame_name'\u003c/code\u003e. Each pose has a \u003ccode class=\\\"language-none\\\"\u003e'parent_frame'\u003c/code\u003e which the pose is relative to (all poses are typically with respect to global \u003ccode class=\\\"language-none\\\"\u003e'map'\u003c/code\u003e frame), \u0026amp; the pose values. \u003ccode class=\\\"language-none\\\"\u003e'rotation_rpy'\u003c/code\u003e is \u003ccode class=\\\"language-none\\\"\u003e[roll,pitch,yaw]\u003c/code\u003e, \u003ccode class=\\\"language-none\\\"\u003e'rotation_xyzw'\u003c/code\u003e is the equivalent quaternion \u003ccode class=\\\"language-none\\\"\u003e[x,y,z,w]\u003c/code\u003e, \u0026amp; \u003ccode class=\\\"language-none\\\"\u003e'translation_xyz'\u003c/code\u003e is the Cartesion \u003ccode class=\\\"language-none\\\"\u003e[x,y,z]\u003c/code\u003e coordinates.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003c/tbody\u003e\\n\u003c/table\u003e\\n\u003ch2\u003eUsing the API to communicate with the BenchBot system\u003c/h2\u003e\\n\u003cp\u003eA running BenchBot system manages many other elements besides simply getting data to and from a real / simulated robot. BenchBot encapsulates not just the robot, but also the environment it is operating in (whether that be simulator or real) and task that is currently being attempted.\u003c/p\u003e\\n\u003cp\u003eThe API handles communication for all parts of the BenchBot system, including controlling the currently running environment and obtaining configuration information. Below are details for some of the more useful features of the API (all features are also documented in the \u003ca href=https:/github.com/qcr/benchbot_api/blob/master/benchbot_api/benchbot.py\u003e\u003ccode class=\\\"language-none\\\"\u003ebenchbot.py\u003c/code\u003e\u003c/a\u003e source code).\u003c/p\u003e\\n\u003ch3\u003eGathering configuration information\u003c/h3\u003e\\n\u003ctable\u003e\\n\u003cthead\u003e\\n\u003ctr\u003e\\n\u003cth\u003eAPI method or property\u003c/th\u003e\\n\u003cth\u003eDescription\u003c/th\u003e\\n\u003c/tr\u003e\\n\u003c/thead\u003e\\n\u003ctbody\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003econfig\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eReturns a \u003ccode class=\\\"language-none\\\"\u003edict\u003c/code\u003e exhaustively describing the current BenchBot configuration. Most of the information returned will not be useful for general BenchBot use.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003c/tbody\u003e\\n\u003c/table\u003e\\n\u003ch3\u003eInteracting with the environment\u003c/h3\u003e\\n\u003ctable\u003e\\n\u003cthead\u003e\\n\u003ctr\u003e\\n\u003cth\u003eAPI method or property\u003c/th\u003e\\n\u003cth\u003eDescription\u003c/th\u003e\\n\u003c/tr\u003e\\n\u003c/thead\u003e\\n\u003ctbody\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003ereset()\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eResets the current environment scene. For the simulator, this means restarting the running simulator instance with the robot back at its initial position. The method returns initial \u003ccode class=\\\"language-none\\\"\u003eobservations\u003c/code\u003e, \u0026amp; the \u003ccode class=\\\"language-none\\\"\u003eaction_result\u003c/code\u003e (should always be \u003ccode class=\\\"language-none\\\"\u003eBenchBot.ActionResult.SUCCESS\u003c/code\u003e).\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003enext_scene()\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eStarts the next scene in the current environment (only relevant for tasks with multiple scenes). Note there is no going back once you have moved to the next scene. Returns the same as \u003ccode class=\\\"language-none\\\"\u003ereset()\u003c/code\u003e.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003c/tbody\u003e\\n\u003c/table\u003e\\n\u003ch3\u003eInteracting with an agent\u003c/h3\u003e\\n\u003ctable\u003e\\n\u003cthead\u003e\\n\u003ctr\u003e\\n\u003cth\u003eAPI method or property\u003c/th\u003e\\n\u003cth\u003eDescription\u003c/th\u003e\\n\u003c/tr\u003e\\n\u003c/thead\u003e\\n\u003ctbody\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003eactions\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eReturns the list of actions currently available to the agent. This will update as actions are performed in the environment (for example if the agent has collided with an obstacle this list will be empty).\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003eobservations\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eReturns the lists of observations available to the agent.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003estep(action, **action_args)\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003ePerforms the requested action with the provided named action arguments. See \u003ca href=https:/github.com/qcr/benchbot_api/#using-the-api-to-communicate-with-a-robot\u003eUsing the API to communicate with a robot\u003c/a\u003e above for further details.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003c/tbody\u003e\\n\u003c/table\u003e\\n\u003ch3\u003eCreating results\u003c/h3\u003e\\n\u003ctable\u003e\\n\u003cthead\u003e\\n\u003ctr\u003e\\n\u003cth\u003eAPI method or property\u003c/th\u003e\\n\u003cth\u003eDescription\u003c/th\u003e\\n\u003c/tr\u003e\\n\u003c/thead\u003e\\n\u003ctbody\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003eempty_results()\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eGenerates a \u003ccode class=\\\"language-none\\\"\u003edict\u003c/code\u003e of with required result metadata \u0026amp; empty results. Metadata (\u003ccode class=\\\"language-none\\\"\u003e'task_details'\u003c/code\u003e \u0026amp; \u003ccode class=\\\"language-none\\\"\u003e'environment_details'\u003c/code\u003e) is pre-filled. To create results, all a user needs to do is fill in the empty \u003ccode class=\\\"language-none\\\"\u003e'results'\u003c/code\u003e field using format's results functions. These functions are available through the \u003ccode class=\\\"language-none\\\"\u003e'results_functions()\u003c/code\u003e method.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003eresults_functions()\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eReturns a \u003ccode class=\\\"language-none\\\"\u003edict\u003c/code\u003e of functions defined by the task's \u003ccode class=\\\"language-none\\\"\u003e'results_format'\u003c/code\u003e. Example use for calling a \u003ccode class=\\\"language-none\\\"\u003ecreate()\u003c/code\u003e function is \u003ccode class=\\\"language-none\\\"\u003eresults_functions()['create']()\u003c/code\u003e.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003eRESULT_LOCATION\u003c/code\u003e (outside of \u003ccode class=\\\"language-none\\\"\u003eBenchBot\u003c/code\u003e class)\u003c/td\u003e\\n\u003ctd\u003eA static string denoting where results should be saved (\u003ccode class=\\\"language-none\\\"\u003e/tmp/results\u003c/code\u003e). Using this locations ensures tools in the \u003ca href=https://github.com/qcr/benchbot\u003eBenchBot software stack\u003c/a\u003e work as expected.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003c/tbody\u003e\\n\u003c/table\u003e\\n\",\"name\":\"BenchBot Python API\",\"type\":\"code\",\"url\":\"https://github.com/qcr/benchbot_api\",\"image_position\":\"center 100%\",\"src\":\"/content/benchbot/benchbot-api.md\",\"id\":\"benchbot-api\",\"image\":\"/_next/static/gifs/566ece96917dbb84cd386109b8457390.jpg\",\"_image\":\"/_next/static/gifs/566ece96917dbb84cd386109b8457390.webm\"},{\"content\":\"\u003cp\u003e\u003cstrong\u003eNOTE: this software is part of the BenchBot software stack, and not intended to be run in isolation (although it can be installed independently through pip if desired). For a working BenchBot system, please install the BenchBot software stack by following the instructions \u003ca href=https://github.com/qcr/benchbot\u003ehere\u003c/a\u003e.\u003c/strong\u003e\u003c/p\u003e\\n\u003ch1\u003eBenchBot Add-ons Manager\u003c/h1\u003e\\n\u003cp\u003e\u003cvideo autoplay loop poster=\\\"/_next/static/gifs/8ef442bbcf06f5d9f4a4bd553bd28212.jpg\\\"\u003e\u003csource src=\\\"/_next/static/gifs/8ef442bbcf06f5d9f4a4bd553bd28212.webm\\\" type=\\\"video/webm\\\"/\u003e\u003c/video\u003e\u003c/p\u003e\\n\u003cp\u003eThe BenchBot Add-ons Manager allows you to use BenchBot with a wide array of additional content, and customise your installation to suite your needs. Semantic Scene Understanding not your thing? Install the Semantic Question Answering add-ons instead. Want to create your own content? Write some basic YAML files to make your own add-ons. Need to re-use existing content? Simply include a dependency on that add-on. Add-ons are all about making BenchBot whatever you need it to be—build a BenchBot for your research problems, exactly as you need it.\u003c/p\u003e\\n\u003cp\u003eAdd-ons come in a variety of types. Anything that you may need to customise for your own experiments or research, should be customisable through an add-on. If not, let us know, and we'll add more add-on enabled functionality to BenchBot!\u003c/p\u003e\\n\u003cp\u003eThe list of currently supported types of add-ons are:\u003c/p\u003e\\n\u003cul\u003e\\n\u003cli\u003e\u003cstrong\u003ebatches\u003c/strong\u003e: a list of environments used for repeatable evaluation scores with the \u003ccode class=\\\"language-none\\\"\u003ebenchbot_batch\u003c/code\u003e script.\u003c/li\u003e\\n\u003cli\u003e\u003cstrong\u003eenvironments\u003c/strong\u003e: simulated or real world environments that a task can be performed in, with a robot. Only \u003ca href=\\\"https://developer.nvidia.com/Isaac-sim\\\"\u003eIsaac Sim\u003c/a\u003e simulation is currently supported, but there is capacity to support other simulators. Please get in contact if you'd like to see another simulator in BenchBot!\u003c/li\u003e\\n\u003cli\u003e\u003cstrong\u003eevaluation_methods\u003c/strong\u003e: a method for evaluating a set of formatted results, against a corresponding ground truth, and producing scores describing how well a result performed a given task.\u003c/li\u003e\\n\u003cli\u003e\u003cstrong\u003eformats\u003c/strong\u003e: formalisation of a format for results or ground truth data, including helper functions.\u003c/li\u003e\\n\u003cli\u003e\u003cstrong\u003eground_truths\u003c/strong\u003e: ground truth data in a declared format, about a specific environment. Environments can have many different types of ground truths depending on what different tasks require.\u003c/li\u003e\\n\u003cli\u003e\u003cstrong\u003erobots\u003c/strong\u003e: a robot definition declaring the communication channels available to the BenchBot ecosystem. Both simulated and real world robots are supported, they just need to run ROS.\u003c/li\u003e\\n\u003cli\u003e\u003cstrong\u003etasks\u003c/strong\u003e: a task is a definition of something we want a robot to do, including what observations and actions it has available, and how results should be reported.\u003c/li\u003e\\n\u003c/ul\u003e\\n\u003cp\u003eSee the sections below for details of how to interact with installed add-ons, how to create your own add-ons, and formalisation of what's required in an add-on.\u003c/p\u003e\\n\u003ch2\u003eInstalling and using the add-ons manager\u003c/h2\u003e\\n\u003cp\u003eIn general, you won't use the add-ons manager directly. Instead you interact with the \u003ca href=https://github.com/qcr/benchbot\u003eBenchBot software stack\u003c/a\u003e, which uses the add-ons manager to manage and access add-ons.\u003c/p\u003e\\n\u003cp\u003eThe manager is a Python package if you do find you want to use it directly, and installable with pip. Run the following in the root directory where the repository was cloned:\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003eu@pc:~$ pip install .\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eThe manager can then be imported and used to manage installation, loading, accessing, processing, and updating of add-ons. Some samples of supported functionality are shown below:\u003c/p\u003e\\n\u003cpre class=\\\"language-python\\\"\u003e\u003ccode class=\\\"language-python\\\"\u003e\u003cspan class=\\\"token keyword\\\"\u003efrom\u003c/span\u003e benchbot_addons \u003cspan class=\\\"token keyword\\\"\u003eimport\u003c/span\u003e manager \u003cspan class=\\\"token keyword\\\"\u003eas\u003c/span\u003e bam\\n\\n\u003cspan class=\\\"token comment\\\"\u003e# Check if example with 'name' = 'hello_scd' exists\u003c/span\u003e\\nbam\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eexists\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token string\\\"\u003e'examples'\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e \u003cspan class=\\\"token punctuation\\\"\u003e[\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token string\\\"\u003e'name'\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e \u003cspan class=\\\"token string\\\"\u003e'hello_scd'\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e]\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n\\n\u003cspan class=\\\"token comment\\\"\u003e# Find all installed environments\u003c/span\u003e\\nbam\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003efind_all\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token string\\\"\u003e'environments'\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n\\n\u003cspan class=\\\"token comment\\\"\u003e# Get a list of the names for all installed tasks\u003c/span\u003e\\nbam\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eget_field\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token string\\\"\u003e'tasks'\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e \u003cspan class=\\\"token string\\\"\u003e'name'\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n\\n\u003cspan class=\\\"token comment\\\"\u003e# Get a list of (name, variant) pairs for all installed environments\u003c/span\u003e\\nbam\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eget_fields\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token string\\\"\u003e'environments'\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e \u003cspan class=\\\"token punctuation\\\"\u003e[\u003c/span\u003e\u003cspan class=\\\"token string\\\"\u003e'name'\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e \u003cspan class=\\\"token string\\\"\u003e'variant'\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e]\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n\\n\u003cspan class=\\\"token comment\\\"\u003e# Find a robot with 'name' = 'carter'\u003c/span\u003e\\nbam\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eget_match\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token string\\\"\u003e'robots'\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e \u003cspan class=\\\"token punctuation\\\"\u003e[\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token string\\\"\u003e'name'\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e \u003cspan class=\\\"token string\\\"\u003e'carter'\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e]\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n\\n\u003cspan class=\\\"token comment\\\"\u003e# Get the 'results_format' value for the task called 'scd:passive:ground_truth'\u003c/span\u003e\\nbam\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eget_value_by_name\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token string\\\"\u003e'tasks'\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e \u003cspan class=\\\"token string\\\"\u003e'scd:passive:ground_truth'\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e \u003cspan class=\\\"token string\\\"\u003e'results_format'\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n\\n\u003cspan class=\\\"token comment\\\"\u003e# Load YAML data for all installed ground truths\u003c/span\u003e\\nbam\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eload_yaml_list\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003ebam\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003efind_all\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token string\\\"\u003e'ground_truths'\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e extension\u003cspan class=\\\"token operator\\\"\u003e=\u003c/span\u003e\u003cspan class=\\\"token string\\\"\u003e'json'\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n\\n\u003cspan class=\\\"token comment\\\"\u003e# Install a list of comma-separated add-ons\u003c/span\u003e\\nbam\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003einstall_addons\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token string\\\"\u003e'benchbot-addons/ssu,benchbot-addons/sqa'\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n\\n\u003cspan class=\\\"token comment\\\"\u003e# Install a specific add-on (\u0026amp; it's dependencies)\u003c/span\u003e\\nbam\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003einstall_addon\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token string\\\"\u003e'tasks_ssu'\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n\\n\u003cspan class=\\\"token comment\\\"\u003e# Print the list of currently installed add-ons, \u0026amp; officially available add-ons\u003c/span\u003e\\nbam\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eprint_state\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n\\n\u003cspan class=\\\"token comment\\\"\u003e# Uninstall all add-ons\u003c/span\u003e\\nbam\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eremove_addons\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n\\n\u003cspan class=\\\"token comment\\\"\u003e# Uninstall a string separated list of add-ons\u003c/span\u003e\\nbam\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eremove_addon\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token string\\\"\u003e'benchbot-addons/ssu,benchbot-addons/sqa'\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003ch2\u003eHow to add your own add-ons\u003c/h2\u003e\\n\u003cp\u003eThere are two different types of add-ons: 'official' add-ons and third-party add-ons.\u003c/p\u003e\\n\u003cp\u003e'Official' are add-ons that we've verified, and are stored in our \u003ca href=https://github.com/benchbot-addons\u003ebenchbot-addons\u003c/a\u003e GitHub organisation. You can get a full list of official add-ons through the \u003ccode class=\\\"language-none\\\"\u003emanager.official_addons()\u003c/code\u003e helper function, or \u003ccode class=\\\"language-none\\\"\u003ebenchbot_install --list-addons\u003c/code\u003e script in the \u003ca href=https://github.com/qcr/benchbot\u003eBenchBot software stack\u003c/a\u003e.\u003c/p\u003e\\n\u003cp\u003eThird-party add-ons only differ in that we haven't looked at them, and they can be hosted anywhere on GitHub you please.\u003c/p\u003e\\n\u003cp\u003eCreating all add-ons is exactly the same process, the only difference is whether the repository is inside or outside of the \u003ca href=https://github.com/benchbot-addons\u003ebenchbot-addons\u003c/a\u003e GitHub organisation:\u003c/p\u003e\\n\u003col\u003e\\n\u003cli\u003eCreate a new GitHub repository\u003c/li\u003e\\n\u003cli\u003eAdd folders corresponding to the type of content your add-ons provide (i.e. an environments add-on has an \u003ccode class=\\\"language-none\\\"\u003eenvironments\u003c/code\u003e directory at the root).\u003c/li\u003e\\n\u003cli\u003eAdd YAML / JSON files for your content, and make sure they match the corresponding format specification from the section below\u003c/li\u003e\\n\u003cli\u003eAdd in any extra content your add-on may require: Python files, simulator binaries, images, etc. (if your add-on gets too big for a Git repository, you can zip the content up, host it somewhere, and use the \u003ccode class=\\\"language-none\\\"\u003e.remote\u003c/code\u003e metadata file described in the next section)\u003c/li\u003e\\n\u003cli\u003eDecide if your add-on is dependent on any others, and declare any dependencies in a \u003ccode class=\\\"language-none\\\"\u003e.dependencies\u003c/code\u003e file\u003c/li\u003e\\n\u003cli\u003ePush everything up to git on your default branch\u003c/li\u003e\\n\u003c/ol\u003e\\n\u003cp\u003e\u003cem\u003e\u003cstrong\u003eNote:\u003c/strong\u003e it's a good idea to only include one type of add-on per repository as it makes your add-on package more usable for others. It's not a hard rule though, so feel free to add multiple folders to your add-on if you require.\u003c/em\u003e\u003c/p\u003e\\n\u003cp\u003eFeel free to have a look at any of the \u003ca href=https://github.com/benchbot-addons\u003eofficial add-ons\u003c/a\u003e for help and examples of how to work with add-ons.\u003c/p\u003e\\n\u003ch2\u003eAdd-ons format specification\u003c/h2\u003e\\n\u003cp\u003eHere are the technical details of what's expected in add-on content. The BenchBot system will assume these specifications are adhered to, and errors can be expected if you try to use add-ons that don't match the specifications.\u003c/p\u003e\\n\u003cp\u003eAn add-on package has the following structure (technically none of the files are required, they just determine what functionality your add-on includes):\u003c/p\u003e\\n\u003ctable\u003e\\n\u003cthead\u003e\\n\u003ctr\u003e\\n\u003cth\u003eFilename\u003c/th\u003e\\n\u003cth\u003eDescription\u003c/th\u003e\\n\u003c/tr\u003e\\n\u003c/thead\u003e\\n\u003ctbody\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e.dependencies\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eA list of add-on packages that must be installed with this package. Packages are specified by their GitHub identifier (i.e. \u003ccode class=\\\"language-none\\\"\u003egithub_username/repository_name\u003c/code\u003e), with one per line\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e.dependencies-python\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eA list of Python dependencies for your add-on. Syntax for file is exactly the same as \u003ca href=\\\"https://pip.pypa.io/en/stable/user_guide/#requirements-files\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003erequirements.txt\u003c/code\u003e\u003c/a\u003e files.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e.remote\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eSpecifies content that should be installed from a remote URL, rather than residing in this repository. A remote resource is specified as a URL and target directory separated by a space. One resource is specified per line. The add-ons manager will fetch the URL specified, and extract the contents to the target directory (e.g. \u003ccode class=\\\"language-none\\\"\u003ehttp://myhost/my_content.zip environments\u003c/code\u003e)\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e\u0026lt;directory\u0026gt;/\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eEach named directory corresponds to an add-on type described below. The directory will be ignored if its name doesn't exactly match any of those below.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003c/tbody\u003e\\n\u003c/table\u003e\\n\u003ch3\u003eBatch add-ons\u003c/h3\u003e\\n\u003cp\u003eA YAML file, that must exist in a folder called \u003ccode class=\\\"language-none\\\"\u003ebatches\u003c/code\u003e in the root of the add-on package (e.g. \u003ccode class=\\\"language-none\\\"\u003ebatches/my_batch.yaml\u003c/code\u003e).\u003c/p\u003e\\n\u003cp\u003eThe following keys are supported for batch add-ons:\u003c/p\u003e\\n\u003ctable\u003e\\n\u003cthead\u003e\\n\u003ctr\u003e\\n\u003cth\u003eKey\u003c/th\u003e\\n\u003cth\u003eRequired\u003c/th\u003e\\n\u003cth\u003eDescription\u003c/th\u003e\\n\u003c/tr\u003e\\n\u003c/thead\u003e\\n\u003ctbody\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'name'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eYes\u003c/td\u003e\\n\u003ctd\u003eA string used to refer to this batch (must be unique!).\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'environments'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eYes\u003c/td\u003e\\n\u003ctd\u003eA list of environment strings of the format \u003ccode class=\\\"language-none\\\"\u003e'name':'variant'\u003c/code\u003e (e.g. \u003ccode class=\\\"language-none\\\"\u003e'miniroom:1'\u003c/code\u003e).\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003c/tbody\u003e\\n\u003c/table\u003e\\n\u003ch3\u003eEnvironment add-ons\u003c/h3\u003e\\n\u003cp\u003eA YAML file, that must exist in a folder called \u003ccode class=\\\"language-none\\\"\u003eenvironments\u003c/code\u003e in the root of the add-on package (e.g. \u003ccode class=\\\"language-none\\\"\u003eenvironments/my_environment.yaml\u003c/code\u003e).\u003c/p\u003e\\n\u003cp\u003eThe following keys are supported for environment add-ons:\u003c/p\u003e\\n\u003ctable\u003e\\n\u003cthead\u003e\\n\u003ctr\u003e\\n\u003cth\u003eKey\u003c/th\u003e\\n\u003cth\u003eRequired\u003c/th\u003e\\n\u003cth\u003eDescription\u003c/th\u003e\\n\u003c/tr\u003e\\n\u003c/thead\u003e\\n\u003ctbody\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'name'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eYes\u003c/td\u003e\\n\u003ctd\u003eA string used to refer to this environment's name (the \u003ccode class=\\\"language-none\\\"\u003e('name', 'variant')\u003c/code\u003e pair must be unique!).\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'variant'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eYes\u003c/td\u003e\\n\u003ctd\u003eA string used to refer to this environment's variant (the \u003ccode class=\\\"language-none\\\"\u003e('name', 'variant')\u003c/code\u003e pair must be unique!).\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'type'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eYes\u003c/td\u003e\\n\u003ctd\u003eA string describing the type of this environment (\u003ccode class=\\\"language-none\\\"\u003e'sim_unreal'\u003c/code\u003e \u0026amp; \u003ccode class=\\\"language-none\\\"\u003e'real'\u003c/code\u003e are the only values currently used).\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'map_path'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eYes\u003c/td\u003e\\n\u003ctd\u003eA path to the map for this environment, which will be used by either the simulator or real world system to load the environment.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'start_pose'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eYes\u003c/td\u003e\\n\u003ctd\u003eThe start pose of the robot that will be provided to users through the \u003ca href=https://github.com/qcr/benchbot_api\u003eBenchBot API\u003c/a\u003e. The pose is specified as a list of 7 numbers: quarternion_x, quarternion_y, quarternion_z, quarternion_w, position_x, position_y, position_z. This must be accurate!\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'trajectory_poses'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eNo\u003c/td\u003e\\n\u003ctd\u003eA list of poses for the robot to traverse through in order. Each pose is a list of 7 numbers: quarternion_x, quarternion_y, quarternion_z, quarternion_w, position_x, position_y, position_z. This environment won't be usable for tasks that use the \u003ccode class=\\\"language-none\\\"\u003e'move_next'\u003c/code\u003e action if this parameter isn't provided.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'robots'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eNo\u003c/td\u003e\\n\u003ctd\u003eA list of supported names for robot that are supported in this environment. If this list isn't included, all robots with the same \u003ccode class=\\\"language-none\\\"\u003e'type'\u003c/code\u003e as this environment will be able to run.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'object_labels'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eNo\u003c/td\u003e\\n\u003ctd\u003eA list of labels for the objects that exist in the scene. Can be used with simulated sensors like segmentation sensors.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003c/tbody\u003e\\n\u003c/table\u003e\\n\u003ch3\u003eEvaluation method add-ons\u003c/h3\u003e\\n\u003cp\u003eA YAML file, that must exist in a folder called \u003ccode class=\\\"language-none\\\"\u003eevaluation_methods\u003c/code\u003e in the root of the add-on package (e.g. \u003ccode class=\\\"language-none\\\"\u003eevaluation_methods/my_evaluation_method.yaml\u003c/code\u003e).\u003c/p\u003e\\n\u003cp\u003eThe following keys are supported for evaluation method add-ons:\u003c/p\u003e\\n\u003ctable\u003e\\n\u003cthead\u003e\\n\u003ctr\u003e\\n\u003cth\u003eKey\u003c/th\u003e\\n\u003cth\u003eRequired\u003c/th\u003e\\n\u003cth\u003eDescription\u003c/th\u003e\\n\u003c/tr\u003e\\n\u003c/thead\u003e\\n\u003ctbody\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'name'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eYes\u003c/td\u003e\\n\u003ctd\u003eA string used to refer to this evaluation method (must be unique!)\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'valid_result_formats'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eYes\u003c/td\u003e\\n\u003ctd\u003eList of strings denoting results formats supported by the evaluation method. Ideally these format definitions should also be installed.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'valid_ground_truth_formats'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eYes\u003c/td\u003e\\n\u003ctd\u003eList of strings denoting ground truth formats supported by the evaluation method. Ideally these format definitions should also be installed.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'functions'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eYes\u003c/td\u003e\\n\u003ctd\u003eDictionary of named functions provided by the evaluation method. The named methods are key value pairs where the key is the function name, and the value is a string describing how the function can be imported with Python. For example, \u003ccode class=\\\"language-none\\\"\u003eevaluate: \u0026quot;omq.evaluate_method\u0026quot;\u003c/code\u003e declares a function called \u003ccode class=\\\"language-none\\\"\u003e'evaluate'\u003c/code\u003e that is imported via \u003ccode class=\\\"language-none\\\"\u003efrom omq import evaluate_method\u003c/code\u003e. Likewise \u003ccode class=\\\"language-none\\\"\u003e\u0026quot;omq.submodule.combine_method\u0026quot;\u003c/code\u003e translates to \u003ccode class=\\\"language-none\\\"\u003efrom omq.submodule import combine_method\u003c/code\u003e. See below for the list of functions expected for evaluation methods.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'description'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eNo\u003c/td\u003e\\n\u003ctd\u003eA string describing what the evaluation method is and how it works. Should be included if you want users to understand where your method can be used.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003c/tbody\u003e\\n\u003c/table\u003e\\n\u003cp\u003eEvaluation methods expect the following named functions:\u003c/p\u003e\\n\u003ctable\u003e\\n\u003cthead\u003e\\n\u003ctr\u003e\\n\u003cth\u003eName\u003c/th\u003e\\n\u003cth\u003eSignature\u003c/th\u003e\\n\u003cth\u003eUsage\u003c/th\u003e\\n\u003c/tr\u003e\\n\u003c/thead\u003e\\n\u003ctbody\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'evaluate'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003efn(dict: results, list: ground_truths) -\u0026gt; dict\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eEvaluates the performance using a \u003ccode class=\\\"language-none\\\"\u003eresults\u003c/code\u003e dictionary, and returns a dictionary of containing the scores. It also takes a list of dictionaries containing each ground truth that will be used in evaluation.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'combine'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003efn(list: scores) -\u0026gt; dict\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eTakes a list of \u003ccode class=\\\"language-none\\\"\u003escores\u003c/code\u003e dictionaries, and returns an aggregate score. If this method isn't declared, \u003ca href=https://github.com/qcr/benchbot_eval\u003e\u003ccode class=\\\"language-none\\\"\u003ebenchbot_eval\u003c/code\u003e\u003c/a\u003e won't return a summary score.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003c/tbody\u003e\\n\u003c/table\u003e\\n\u003ch3\u003eFormat definition add-ons\u003c/h3\u003e\\n\u003cp\u003eA YAML file, that must exist in a folder called \u003ccode class=\\\"language-none\\\"\u003eformats\u003c/code\u003e in the root of the add-on package (e.g. \u003ccode class=\\\"language-none\\\"\u003eformats/my_format.yaml\u003c/code\u003e).\u003c/p\u003e\\n\u003cp\u003eThe following keys are supported for format add-ons:\u003c/p\u003e\\n\u003ctable\u003e\\n\u003cthead\u003e\\n\u003ctr\u003e\\n\u003cth\u003eKey\u003c/th\u003e\\n\u003cth\u003eRequired\u003c/th\u003e\\n\u003cth\u003eDescription\u003c/th\u003e\\n\u003c/tr\u003e\\n\u003c/thead\u003e\\n\u003ctbody\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'name'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eYes\u003c/td\u003e\\n\u003ctd\u003eA string used to refer to this format (must be unique!)\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'functions'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eYes\u003c/td\u003e\\n\u003ctd\u003eDictionary of named functions for use with this format. The named methods are key-value pairs where the key is the function name, and the value is a string describing how the function can be imported with Python. For example, \u003ccode class=\\\"language-none\\\"\u003ecreate: \u0026quot;object_map.create_empty\u0026quot;\u003c/code\u003e declares a function called \u003ccode class=\\\"language-none\\\"\u003e'create'\u003c/code\u003e that is imported via \u003ccode class=\\\"language-none\\\"\u003efrom object_map import create_empty\u003c/code\u003e. Likewise \u003ccode class=\\\"language-none\\\"\u003e\u0026quot;object_map.submodule.validate\u0026quot;\u003c/code\u003e translates to \u003ccode class=\\\"language-none\\\"\u003efrom object_map.submodule import validate\u003c/code\u003e. See below for the list of functions expected for format definitions.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'description'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eNo\u003c/td\u003e\\n\u003ctd\u003eA string describing what the format is and how it works. Should be included if you want users to understand what your format is supposed to capture.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003c/tbody\u003e\\n\u003c/table\u003e\\n\u003cp\u003eFormat definitions expect the following named functions:\u003c/p\u003e\\n\u003ctable\u003e\\n\u003cthead\u003e\\n\u003ctr\u003e\\n\u003cth\u003eName\u003c/th\u003e\\n\u003cth\u003eSignature\u003c/th\u003e\\n\u003cth\u003eUsage\u003c/th\u003e\\n\u003c/tr\u003e\\n\u003c/thead\u003e\\n\u003ctbody\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'create'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003efn() -\u0026gt; dict\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eFunction that returns an empty instance of this format. As much as possible should be filled in to make it easy for users to create valid instances (especially when a format is used for results).\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'validate'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003efn(dict: instance) -\u0026gt; None\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eTakes a proposed \u003ccode class=\\\"language-none\\\"\u003einstance\u003c/code\u003e of this format and validates whether it meets the requirements. Will typically use a series of assert statements to confirm fields are valid.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003c/tbody\u003e\\n\u003c/table\u003e\\n\u003ch3\u003eGround truth add-ons\u003c/h3\u003e\\n\u003cp\u003eA JSON file, that must exist in a folder called \u003ccode class=\\\"language-none\\\"\u003eground_truths\u003c/code\u003e in the root of the add-on package (e.g. \u003ccode class=\\\"language-none\\\"\u003eground_truths/my_ground_truth.json\u003c/code\u003e).\u003c/p\u003e\\n\u003cp\u003eThe following keys are supported for ground truth add-ons:\u003c/p\u003e\\n\u003ctable\u003e\\n\u003cthead\u003e\\n\u003ctr\u003e\\n\u003cth\u003eKey\u003c/th\u003e\\n\u003cth\u003eRequired\u003c/th\u003e\\n\u003cth\u003eDescription\u003c/th\u003e\\n\u003c/tr\u003e\\n\u003c/thead\u003e\\n\u003ctbody\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'environment'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eYes\u003c/td\u003e\\n\u003ctd\u003eA dictionary containing the definition data for the ground truth's reference environment. The data in this field should be a direct copy of an environment add-on.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'format'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eYes\u003c/td\u003e\\n\u003ctd\u003eA dictionary containing the definition data for the ground truth's format. The data in this field should be a direct copy of a format definition add-on.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'ground_truth'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eYes\u003c/td\u003e\\n\u003ctd\u003eA valid instance of the format described by the \u003ccode class=\\\"language-none\\\"\u003e'format'\u003c/code\u003e field. This is where your actual ground truth data should be stored.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003c/tbody\u003e\\n\u003c/table\u003e\\n\u003cp\u003eA lot of these keys should be copied from other valid definitions. Please see the \u003ccode class=\\\"language-none\\\"\u003eGroundTruthCreator\u003c/code\u003e helper class in \u003ca href=https://github.com/qcr/benchbot_eval\u003eBenchBot Evaluation\u003c/a\u003e for assistance in creating valid ground truths.\u003c/p\u003e\\n\u003ch3\u003eRobot add-ons\u003c/h3\u003e\\n\u003cp\u003eA YAML file, that must exist in a folder called \u003ccode class=\\\"language-none\\\"\u003erobots\u003c/code\u003e in the root of the add-on package (e.g. \u003ccode class=\\\"language-none\\\"\u003erobots/my_robot.yaml\u003c/code\u003e).\u003c/p\u003e\\n\u003cp\u003eThe following keys are supported for robot add-ons:\u003c/p\u003e\\n\u003ctable\u003e\\n\u003cthead\u003e\\n\u003ctr\u003e\\n\u003cth\u003eKey\u003c/th\u003e\\n\u003cth\u003eRequired\u003c/th\u003e\\n\u003cth\u003eDescription\u003c/th\u003e\\n\u003c/tr\u003e\\n\u003c/thead\u003e\\n\u003ctbody\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'name'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eYes\u003c/td\u003e\\n\u003ctd\u003eA string used to refer to this robot (must be unique!).\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'type'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eYes\u003c/td\u003e\\n\u003ctd\u003eA string describing the type of this robot (\u003ccode class=\\\"language-none\\\"\u003e'sim_unreal'\u003c/code\u003e \u0026amp; \u003ccode class=\\\"language-none\\\"\u003e'real'\u003c/code\u003e are the only values currently used).\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'address'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eYes\u003c/td\u003e\\n\u003ctd\u003eA string for the address where a running \u003ca href=https://github.com/qcr/benchbot_robot_controller\u003eBenchBot Robot Controller\u003c/a\u003e can be accessed (e.g. \u003ccode class=\\\"language-none\\\"\u003e'localhost:10000'\u003c/code\u003e)\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'global_frame'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eYes\u003c/td\u003e\\n\u003ctd\u003eThe name of the global TF frame. All poses reported by the \u003ca href=https://github.com/qcr/benchbot_api\u003eBenchBot API\u003c/a\u003e will be with respect to this frame.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'robot_frame'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eYes\u003c/td\u003e\\n\u003ctd\u003eThe name of the robot's TF frame.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'poses'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eYes\u003c/td\u003e\\n\u003ctd\u003eA list of named poses that this robot provides. This list of poses will be available in observations provided by the \u003ca href=https://github.com/qcr/benchbot_api\u003eBenchBot API\u003c/a\u003e.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'start_cmds'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eYes\u003c/td\u003e\\n\u003ctd\u003eA list of commands describing how to start the robot (this will often include the simulator). The commands will be run in parallel, and executed via \u003ccode class=\\\"language-none\\\"\u003ebash -c '\u0026lt;your_command_string\u0026gt;'\u003c/code\u003e\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'connections'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eYes\u003c/td\u003e\\n\u003ctd\u003eA dictionary of connections that your robot makes available to the BenchBot ecosystem. The name of the key-value pair is important, and should follow the recommendations provided on standard channels in the \u003ca href=https://github.com/qcr/benchbot_api\u003eBenchBot API documentation\u003c/a\u003e. A description of connection definitions is provided below.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003c/tbody\u003e\\n\u003c/table\u003e\\n\u003cp\u003eConnections are the lifeblood of interaction between BenchBot and robot platforms. They are defined by named entries, with the following fields:\u003c/p\u003e\\n\u003ctable\u003e\\n\u003cthead\u003e\\n\u003ctr\u003e\\n\u003cth\u003eKey\u003c/th\u003e\\n\u003cth\u003eRequired\u003c/th\u003e\\n\u003cth\u003eDescription\u003c/th\u003e\\n\u003c/tr\u003e\\n\u003c/thead\u003e\\n\u003ctbody\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'connection'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eYes\u003c/td\u003e\\n\u003ctd\u003eConnection type string, used by the \u003ca href=https://github.com/qcr/benchbot_robot_controller\u003eBenchBot Robot Controller\u003c/a\u003e. Supported values are \u003ccode class=\\\"language-none\\\"\u003e'api_to_ros'\u003c/code\u003e (used for actions), \u003ccode class=\\\"language-none\\\"\u003e'ros_to_api'\u003c/code\u003e (used for observations), and \u003ccode class=\\\"language-none\\\"\u003e'roscache_to_api'\u003c/code\u003e (special value used for caching observation values).\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'ros_topic'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eYes\u003c/td\u003e\\n\u003ctd\u003eTopic name for the ROS side of the connection.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'ros_type'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eYes\u003c/td\u003e\\n\u003ctd\u003eTopic type for the ROS side of the connection.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'callback_api'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eNo\u003c/td\u003e\\n\u003ctd\u003eA callback that is run on the HTTP encoded data received / sent on the API end of the connection. It takes in data, and returns transformed data based on the callback's action. Callbacks are specified by a string denoting how the callback can be accessed (e.g. \u003ccode class=\\\"language-none\\\"\u003e'api_callbacks.convert_to_rgb\u003c/code\u003e = \u003ccode class=\\\"language-none\\\"\u003efrom api_callbacks import convert_to_rgb\u003c/code\u003e). No data transformation occurs if no callback is provided.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'callback_ros'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eNo\u003c/td\u003e\\n\u003ctd\u003eA callback that is run on the ROS data received / sent on the robot controller end of the connection. It takes in data and a reference to the robot controller. \u003ccode class=\\\"language-none\\\"\u003e'api_to_ros'\u003c/code\u003e connections use this data to act on the robot, whereas \u003ccode class=\\\"language-none\\\"\u003e'ros_to_api'\u003c/code\u003e connections turn this data into a dictionary that can be serialised into HTTP traffic. Callbacks are specified by a string denoting how the callback can be accessed (e.g. \u003ccode class=\\\"language-none\\\"\u003e'api_callbacks.convert_to_rgb\u003c/code\u003e = \u003ccode class=\\\"language-none\\\"\u003efrom api_callbacks import convert_to_rgb\u003c/code\u003e). No action occurs at the ROS level if no callback is provided.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003c/tbody\u003e\\n\u003c/table\u003e\\n\u003ch3\u003eTask add-ons\u003c/h3\u003e\\n\u003cp\u003eA YAML file, that must exist in a folder called \u003ccode class=\\\"language-none\\\"\u003etasks\u003c/code\u003e in the root of the add-on package (e.g. \u003ccode class=\\\"language-none\\\"\u003etasks/my_task.yaml\u003c/code\u003e).\u003c/p\u003e\\n\u003cp\u003eThe following keys are supported for task add-ons:\u003c/p\u003e\\n\u003ctable\u003e\\n\u003cthead\u003e\\n\u003ctr\u003e\\n\u003cth\u003eKey\u003c/th\u003e\\n\u003cth\u003eRequired\u003c/th\u003e\\n\u003cth\u003eDescription\u003c/th\u003e\\n\u003c/tr\u003e\\n\u003c/thead\u003e\\n\u003ctbody\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'name'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eYes\u003c/td\u003e\\n\u003ctd\u003eA string used to refer to this task (must be unique!).\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'actions'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eYes\u003c/td\u003e\\n\u003ctd\u003eA list of named connections to be provided as actions through the \u003ca href=https://github.com/qcr/benchbot_api\u003eBenchBot API\u003c/a\u003e. Running this task will fail if the robot doesn't provide these named connections.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'observations'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eYes\u003c/td\u003e\\n\u003ctd\u003eA list of named connections to be provided as observations through the \u003ca href=https://github.com/qcr/benchbot_api\u003eBenchBot API\u003c/a\u003e. Running this task will fail if the robot doesn't provide these named connections.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'results_format'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eYes\u003c/td\u003e\\n\u003ctd\u003eA string naming the format for results. The format must be installed, as \u003ca href=https://github.com/qcr/benchbot_api\u003eBenchBot API\u003c/a\u003e will use the format's functions to provide the user with empty results.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'description'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eNo\u003c/td\u003e\\n\u003ctd\u003eA string describing what the task is, and how it works. Should be included if you want users to understand what challenges your task is trying to capture.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'type'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eNo\u003c/td\u003e\\n\u003ctd\u003eA string describing what robot / environment types are valid for this task. For example, a task that provides a magic image segmentation sensor would only be made available for \u003ccode class=\\\"language-none\\\"\u003e'sim_unreal'\u003c/code\u003e type robots / environments.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e'scene_count'\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eNo\u003c/td\u003e\\n\u003ctd\u003eInteger representing the number of scenes (i.e. environment variations required for a task). If omitted, a default value of 1 will be used for the task.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003c/tbody\u003e\\n\u003c/table\u003e\\n\",\"name\":\"BenchBot Add-ons Manager\",\"type\":\"code\",\"url\":\"https://github.com/qcr/benchbot_addons\",\"src\":\"/content/benchbot/benchbot-addons.md\",\"id\":\"benchbot-addons\",\"image_position\":\"center\",\"image\":\"/_next/static/gifs/8ef442bbcf06f5d9f4a4bd553bd28212.jpg\",\"_image\":\"/_next/static/gifs/8ef442bbcf06f5d9f4a4bd553bd28212.webm\"},{\"content\":\"\u003cp\u003e\u003cstrong\u003eNOTE: this software is part of the BenchBot software stack, and not intended to be run in isolation (although it can be installed independently through pip and run on results files if desired). For a working BenchBot system, please install the BenchBot software stack by following the instructions \u003ca href=https://github.com/qcr/benchbot\u003ehere\u003c/a\u003e.\u003c/strong\u003e\u003c/p\u003e\\n\u003ch1\u003eBenchBot Evaluation\u003c/h1\u003e\\n\u003cp\u003eBenchBot Evaluation is a library of functions used to call evaluation methods. These methods are installed through the \u003ca href=https://github.com/qcr/benchbot-addons\u003eBenchBot Add-ons Manager\u003c/a\u003e, and evaluate the performance of a BenchBot system against the metric. The easiest way to use this module is through the helper scripts provided with the \u003ca href=https://github.com/qcr/benchbot\u003eBenchBot software stack\u003c/a\u003e.\u003c/p\u003e\\n\u003ch2\u003eInstalling and performing evaluation with BenchBot Evaluation\u003c/h2\u003e\\n\u003cp\u003eBenchBot Evaluation is a Python package, installable with pip. Run the following in the root directory of where this repository was cloned:\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003eu@pc:~$ pip install .\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eAlthough evaluation is best run from within the BenchBot software stack, it can be run in isolation if desired. The following code snippet shows how to perform evaluation with the \u003ccode class=\\\"language-none\\\"\u003e'omq'\u003c/code\u003e method from Python:\u003c/p\u003e\\n\u003cpre class=\\\"language-python\\\"\u003e\u003ccode class=\\\"language-python\\\"\u003e\u003cspan class=\\\"token keyword\\\"\u003efrom\u003c/span\u003e benchbot_eval\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eevaluator \u003cspan class=\\\"token keyword\\\"\u003eimport\u003c/span\u003e Evaluator\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e Validator\\n\\nValidator\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003eresults_file\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003evalidate_results_data\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\nEvaluator\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token string\\\"\u003e'omq'\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e scores_file\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eevaluate\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eThis prints the final scores to the screen and saves them to a file using the following inputs:\u003c/p\u003e\\n\u003cul\u003e\\n\u003cli\u003e\u003ccode class=\\\"language-none\\\"\u003eresults_file\u003c/code\u003e: points to the JSON file with the output from your experiment\u003c/li\u003e\\n\u003cli\u003e\u003ccode class=\\\"language-none\\\"\u003eground_truth_folder\u003c/code\u003e: the directory containing the relevant environment ground truth JSON files\u003c/li\u003e\\n\u003cli\u003e\u003ccode class=\\\"language-none\\\"\u003esave_file\u003c/code\u003e: is where final scores are to be saved\u003c/li\u003e\\n\u003c/ul\u003e\\n\u003ch2\u003eHow add-ons interact with BenchBot Evaluation\u003c/h2\u003e\\n\u003cp\u003eTwo types of add-ons are used in the BenchBot Evaluation process: format definitions, and evaluation methods. An evaluation method's YAML file defines what results formats and ground truth formats the method supports. This means:\u003c/p\u003e\\n\u003cul\u003e\\n\u003cli\u003ethis package requires installation of the \u003ca href=https://github.com/qcr/benchbot_addons\u003eBenchBot Add-ons Manager\u003c/a\u003e for interacting with installed add-ons\u003c/li\u003e\\n\u003cli\u003ethe \u003ccode class=\\\"language-none\\\"\u003eresults_file\u003c/code\u003e must be a valid instance of a supported format\u003c/li\u003e\\n\u003cli\u003ethere must be a valid ground truth available in a supported format, for the same environment as the results\u003c/li\u003e\\n\u003cli\u003evalidity is determined by the format-specific validation function described in the format's YAML file\u003c/li\u003e\\n\u003c/ul\u003e\\n\u003cp\u003ePlease see the \u003ca href=https://github.com/qcr/benchbot_addons\u003eBenchBot Add-ons Manager's documentation\u003c/a\u003e for further details on the different types of add-ons.\u003c/p\u003e\\n\u003ch2\u003eCreating valid results and ground truth files\u003c/h2\u003e\\n\u003cp\u003eThe \u003ca href=https://github.com/qcr/benchbot\u003eBenchBot software stack\u003c/a\u003e includes tools to assist in creating results and ground truth files:\u003c/p\u003e\\n\u003cul\u003e\\n\u003cli\u003e\\n\u003cp\u003e\u003cstrong\u003eresults:\u003c/strong\u003e are best created using the \u003ccode class=\\\"language-none\\\"\u003eempty_results()\u003c/code\u003e and \u003ccode class=\\\"language-none\\\"\u003eresults_functions()\u003c/code\u003e helper functions in the \u003ca href=https://github.com/qcr/benchbot_api\u003eBenchBot API\u003c/a\u003e, which automatically populate metadata for your current task and environment.\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\\n\u003cp\u003e\u003cstrong\u003eground truths:\u003c/strong\u003e this package includes a \u003ccode class=\\\"language-none\\\"\u003eGroundTruthCreator\u003c/code\u003e class to aid in creating ground truths of a specific format, for a specific environment. Example use includes:\u003c/p\u003e\\n\u003cpre class=\\\"language-python\\\"\u003e\u003ccode class=\\\"language-python\\\"\u003e\u003cspan class=\\\"token keyword\\\"\u003efrom\u003c/span\u003e benchbot_eval\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eground_truth_creator \u003cspan class=\\\"token keyword\\\"\u003eimport\u003c/span\u003e GroundTruthCreator\\n\\ngtc \u003cspan class=\\\"token operator\\\"\u003e=\u003c/span\u003e GroundTruthCreator\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token string\\\"\u003e'object_map_ground_truth'\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e \u003cspan class=\\\"token string\\\"\u003e'miniroom:1'\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\ngt \u003cspan class=\\\"token operator\\\"\u003e=\u003c/span\u003e gtc\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003ecreate_empty\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e;\u003c/span\u003e\\n\u003cspan class=\\\"token keyword\\\"\u003eprint\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003egtc\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003efunctions\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e  \u003cspan class=\\\"token comment\\\"\u003e# ['create', 'create_object']\u003c/span\u003e\\ngt\u003cspan class=\\\"token punctuation\\\"\u003e[\u003c/span\u003e\u003cspan class=\\\"token string\\\"\u003e'ground_truth'\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e]\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e[\u003c/span\u003e\u003cspan class=\\\"token string\\\"\u003e'objects'\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e]\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e[\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e]\u003c/span\u003e \u003cspan class=\\\"token operator\\\"\u003e=\u003c/span\u003e gtc\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003efunctions\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token string\\\"\u003e'create_object'\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003c/li\u003e\\n\u003c/ul\u003e\\n\",\"name\":\"BenchBot Evaluation Tools\",\"type\":\"code\",\"url\":\"https://github.com/qcr/benchbot_eval\",\"src\":\"/content/benchbot/benchbot-eval.md\",\"id\":\"benchbot-eval\",\"image_position\":\"center\",\"image\":\"/_next/static/images/qcr_logo_light_filled-b2f2ba81b0ef111afdf9fa7264fb4adf.png\"},{\"content\":\"\u003cp\u003e\u003cstrong\u003eNOTE: this software is part of the BenchBot software stack, and not intended to be run in isolation. For a working BenchBot system, please install the BenchBot software stack by following the instructions \u003ca href=https://github.com/qcr/benchbot\u003ehere\u003c/a\u003e.\u003c/strong\u003e\u003c/p\u003e\\n\u003ch1\u003eBenchBot Supervisor\u003c/h1\u003e\\n\u003cp align=\\\"center\\\"\u003e\u003cimg alt=\\\"benchbot_supervisor\\\" src=\\\"/_next/static/images/benchbot_supervisor-308d8e63428bf85c3824123d688af972.jpg\\\" width=\\\"60%\\\"/\u003e\u003c/p\u003e\\n\u003cp\u003eThe BenchBot Supervisor is a HTTP server facilitating communication between user-facing interfaces like the \u003ca href=https://github.com/qcr/benchbot_api\u003eBenchBot API\u003c/a\u003e, and the low-level robot components like \u003ca href=https://github.com/qcr/benchbot_simulator\u003eBenchBot Simulator\u003c/a\u003e or real robots. Communication is typically routed through a \u003ca href=https://github.com/qcr/benchbot_robot_controller\u003eBenchBot Robot Controller\u003c/a\u003e, which provides automated process management for low-level components and wraps all ROS communications.\u003c/p\u003e\\n\u003ch2\u003eInstalling and running the BenchBot Supervisor\u003c/h2\u003e\\n\u003cp\u003eBenchBot Supervisor is a Python package containing a \u003ccode class=\\\"language-none\\\"\u003eSupervisor\u003c/code\u003e class that wraps a HTTP server for both upstream and downstream communication. Install by running the following in the root directory of where this repository was cloned:\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003eu@pc:~$ pip install .\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eOnce installed, the Python class can be used as follows:\u003c/p\u003e\\n\u003cpre class=\\\"language-python\\\"\u003e\u003ccode class=\\\"language-python\\\"\u003e\u003cspan class=\\\"token keyword\\\"\u003efrom\u003c/span\u003e benchbot_supervisor \u003cspan class=\\\"token keyword\\\"\u003eimport\u003c/span\u003e Supervisor\\n\\ns \u003cspan class=\\\"token operator\\\"\u003e=\u003c/span\u003e Supervisor\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eargs\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\ns\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003erun\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eThe following parameters are typically required for a useful instantiation of the supervisor:\u003c/p\u003e\\n\u003cul\u003e\\n\u003cli\u003e\u003cstrong\u003eaddons_path\u003c/strong\u003e: path to installed \u003ca href=https://github.com/qcr/benchbot_addons\u003eBenchBot add-ons\u003c/a\u003e (is the same as the directory where \u003ccode class=\\\"language-none\\\"\u003emanager.py\u003c/code\u003e can be found)\u003c/li\u003e\\n\u003cli\u003e\u003cstrong\u003etask_name\u003c/strong\u003e: string matching the \u003ccode class=\\\"language-none\\\"\u003e'name'\u003c/code\u003e field of an installed task\u003c/li\u003e\\n\u003cli\u003e\u003cstrong\u003erobot_name\u003c/strong\u003e: string matching the \u003ccode class=\\\"language-none\\\"\u003e'name'\u003c/code\u003e field of an installed robot\u003c/li\u003e\\n\u003cli\u003e\u003cstrong\u003eenvironment_names\u003c/strong\u003e: list of strings, each matching the \u003ccode class=\\\"language-none\\\"\u003e'name':'variant'\u003c/code\u003e field combination of an installed environment (the \u003ccode class=\\\"language-none\\\"\u003e'name'\u003c/code\u003e must be the same for all environments in the list)\u003c/li\u003e\\n\u003cli\u003e\u003cstrong\u003eport\u003c/strong\u003e: select a different port than the default (10000)\u003c/li\u003e\\n\u003c/ul\u003e\\n\u003cp\u003eThe module can also be executed directly, which makes the passing of arguments from the command line simple (see \u003ccode class=\\\"language-none\\\"\u003epython -m benchbot_supervisor --help\u003c/code\u003e for argument details):\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003eu@pc:~$ python -m benchbot_supervisor ...args...\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eAs an example, the below command runs the supervisor for a scene change detection task, where active control is employed with ground truth localisation on a simulated Carter robot, and environments miniroom:1 and miniroom:5 are used:\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003eu@pc:~$ python -m benchbot_supervisor \\\\\\n    --task-name scd:active:ground_truth \\\\\\n    --robot-name carter \\\\\\n    --environment-names miniroom:1,miniroom:5\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003ch2\u003eEmploying task, robot, and environment configurations\u003c/h2\u003e\\n\u003cp\u003eThe BenchBot Supervisor requires configuration details for the selected tasks, robots, and environments. It uses these details to manage each of the system components, like API interaction and control of the simulator / real robot. Configuration details are provided by YAML files, which are referenced via their \u003ccode class=\\\"language-none\\\"\u003e'name'\u003c/code\u003e field as shown above.\u003c/p\u003e\\n\u003cp\u003eThe \u003ca href=https://github.com/qcr/benchbot_addons\u003eBenchBot Add-ons Manager\u003c/a\u003e manages the installation of, and access to, these files. See the documentation there for further details on configuration files. All you need to do to use add-ons with the supervisor is provide the location via the \u003ccode class=\\\"language-none\\\"\u003e'addons_path'\u003c/code\u003e argument.\u003c/p\u003e\\n\u003ch2\u003eInteracting with the BenchBot Supervisor\u003c/h2\u003e\\n\u003cp\u003eThe supervisor includes a RESTful HTTP API for all interaction with a user-facing API. The RESTful API includes the following commands:\u003c/p\u003e\\n\u003ctable\u003e\\n\u003cthead\u003e\\n\u003ctr\u003e\\n\u003cth\u003eRequest Route\u003c/th\u003e\\n\u003cth\u003eResponse Format\u003c/th\u003e\\n\u003cth\u003eDescription\u003c/th\u003e\\n\u003c/tr\u003e\\n\u003c/thead\u003e\\n\u003ctbody\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e/\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003e\u003cpre class=\\\"language-none\\\"\u003eHello, I am the BenchBot supervisor\u003c/pre\u003e\u003c/td\u003e\\n\u003ctd\u003eArbitrary response to confirm connection.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e/config/\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003e\u003cpre class=\\\"language-none\\\"\u003e{\u003cbr\u003e ...\u003cbr\u003e 'param_name': param_value,\u003cbr\u003e ...\u003cbr\u003e}\u003c/pre\u003e\u003c/td\u003e\\n\u003ctd\u003eDictionary containing containing parameter values for all of supervisor configuration settings. Keys correspond to parameter name, \u0026amp; values to parameter value.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e/config/\u0026lt;config\u0026gt;\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003econfig_value\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eDirectly retrieve the value of a supervisor configuration parameter with name \u003ccode class=\\\"language-none\\\"\u003e'config'\u003c/code\u003e. Returns \u003ccode class=\\\"language-none\\\"\u003eparam_value\u003c/code\u003e of \u003ccode class=\\\"language-none\\\"\u003e'config'\u003c/code\u003e.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e/connections/\u0026lt;connection\u0026gt;\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003edict\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eReturns the response of the connection (e.g. an \u003ccode class=\\\"language-none\\\"\u003eimage_rgb\u003c/code\u003e connection would return the image) as a \u003ccode class=\\\"language-none\\\"\u003edict\u003c/code\u003e. Format \u0026amp; style of the \u003ccode class=\\\"language-none\\\"\u003edict\u003c/code\u003e is defined by the methods described above in \u0026quot;Defining environment, robot, \u0026amp; task configurations\u0026quot;.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e/results_functions/\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003elist\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eReturns a list of the results function names that can be remotely executed via the route below.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e/results_functions/\u0026lt;function\u0026gt;\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003edict\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003eCalls results function with name \u003ccode class=\\\"language-none\\\"\u003e'function'\u003c/code\u003e, and returns the result of the function call in the response's JSON body.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e/robot/\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003e\u003cpre class=\\\"language-none\\\"\u003eHello, I am the BenchBot robot controller\u003c/pre\u003e\u003c/td\u003e\\n\u003ctd\u003eArbitrary response confirming a robot controller is available.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003e/robot/\u0026lt;command\u0026gt;\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003edict\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003ePasses the command \u003ccode class=\\\"language-none\\\"\u003ecommand\u003c/code\u003e down to a running robot controller manager. See \u003ca href=https://github.com/qcr/benchbot_robot_controller\u003eBenchBot Robot Controller\u003c/a\u003e for documentation of supported commands \u0026amp; expected responses.\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003c/tbody\u003e\\n\u003c/table\u003e\\n\",\"name\":\"BenchBot Backend Supervisor\",\"type\":\"code\",\"url\":\"https://github.com/qcr/benchbot_supervisor\",\"image_position\":\"center 0%\",\"src\":\"/content/benchbot/benchbot-supervisor.md\",\"id\":\"benchbot-supervisor\",\"image\":\"/_next/static/images/benchbot_supervisor-308d8e63428bf85c3824123d688af972.jpg\"},{\"content\":\"\u003cp\u003e\u003cstrong\u003eNOTE: this software is part of the BenchBot software stack, and not intended to be run in isolation. For a working BenchBot system, please install the BenchBot software stack by following the instructions \u003ca href=https://github.com/qcr/benchbot\u003ehere\u003c/a\u003e.\u003c/strong\u003e\u003c/p\u003e\\n\u003ch1\u003eBenchBot Simulator\u003c/h1\u003e\\n\u003cp\u003e\u003cvideo autoplay loop poster=\\\"/_next/static/gifs/ec1857995c55d26bf6712cf7c339dbae.jpg\\\"\u003e\u003csource src=\\\"/_next/static/gifs/ec1857995c55d26bf6712cf7c339dbae.webm\\\" type=\\\"video/webm\\\"/\u003e\u003c/video\u003e\u003c/p\u003e\\n\u003cp\u003eThe BenchBot Simulator is an extension of the \u003ca href=\\\"https://developer.nvidia.com/isaac-sdk\\\"\u003eNVIDIA Isaac SDK\u003c/a\u003e that establishes ROS communications to a running instance of an Unreal Engine-based \u003ca href=\\\"https://developer.nvidia.com/isaac-sim\\\"\u003eNVIDIA Isaac SIM\u003c/a\u003e. BenchBot simulator is explicitly linked to version 2019.2 of Isaac, the last version with direct support for the Unreal Engine-based simulator. In the future we intend to move to \u003ca href=\\\"https://developer.nvidia.com/nvidia-omniverse\\\"\u003eOmniverse\u003c/a\u003e, NVIDIA's new 3D production pipeline with RTX support.\u003c/p\u003e\\n\u003cp\u003eBenchBot simulator provides direct access to the following data on the simulated robot. Access is via ROS on the topic provided in brackets:\u003c/p\u003e\\n\u003cul\u003e\\n\u003cli\u003eRGB images from the top camera (\u003ccode class=\\\"language-none\\\"\u003e/camera/color/image_raw\u003c/code\u003e)\u003c/li\u003e\\n\u003cli\u003eCamera information for RGB images from the top camera (\u003ccode class=\\\"language-none\\\"\u003e/camera/color/camera_info\u003c/code\u003e)\u003c/li\u003e\\n\u003cli\u003eDepth images from the top camera (\u003ccode class=\\\"language-none\\\"\u003e/camera/depth/image_raw\u003c/code\u003e)\u003c/li\u003e\\n\u003cli\u003eCamera information for depth images from the top camera (\u003ccode class=\\\"language-none\\\"\u003e/camera/depth/camera_info\u003c/code\u003e)\u003c/li\u003e\\n\u003cli\u003eLaserscan data from the LiDAR (\u003ccode class=\\\"language-none\\\"\u003e/scan_laser\u003c/code\u003e)\u003c/li\u003e\\n\u003cli\u003eRaw odometry data (\u003ccode class=\\\"language-none\\\"\u003e/odom\u003c/code\u003e)\u003c/li\u003e\\n\u003cli\u003eA full transform tree (\u003ccode class=\\\"language-none\\\"\u003e/tf\u003c/code\u003e)\u003c/li\u003e\\n\u003c/ul\u003e\\n\u003cp\u003eDirect control of the robot is also facilitated via:\u003c/p\u003e\\n\u003cul\u003e\\n\u003cli\u003e3D twist velocities sent to topic \u003ccode class=\\\"language-none\\\"\u003e/cmd_vel\u003c/code\u003e\u003c/li\u003e\\n\u003c/ul\u003e\\n\u003ch2\u003eInstalling BenchBot Simulator\u003c/h2\u003e\\n\u003cp\u003e\u003cstrong\u003ePlease see the note at the top of the page; installation of BenchBot Simulator in isolation is generally not what you want!\u003c/strong\u003e\u003c/p\u003e\\n\u003cp\u003eIf you are sure you need to install the simulator in isolation, the following steps should be sufficient. Note there are a significant number of driver \u0026amp; software requirements for your system:\u003c/p\u003e\\n\u003col\u003e\\n\u003cli\u003e\\n\u003cp\u003eDownload version 2019.2 of the Isaac SDK from the \u003ca href=\\\"https://developer.nvidia.com/isaac/downloads\\\"\u003eNVIDIA site\u003c/a\u003e. If creating your own environments, also download version 2019.2 of Isaac SIM (\u003cem\u003enot\u003c/em\u003e NavSim). You will have to create / sign in to an NVIDIA developer account, and look in the \u0026quot;Archive\u0026quot; drop down for version 2019.2.\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\\n\u003cp\u003eEither setup your system with Isaac SIM, or download our environments:\u003c/p\u003e\\n\u003cp\u003ea) Follow the \u003ca href=\\\"https://docs.nvidia.com/isaac/isaac_sim/setup.html\\\"\u003einstall instructions\u003c/a\u003e for Isaac SIM to get Unreal Engine (through IsaacSimProject) running on your system. You will have to link Epic Games to your Github account to get access.\u003c/p\u003e\\n\u003cp\u003eb) Download our latest environments: \u003ca href=https://github.com/benchbot-addons/envs_isaac_develop/blob/master/.remote\u003eIsaac Development Environments\u003c/a\u003e, and \u003ca href=https://github.com/benchbot-addons/envs_isaac_challenge/blob/master/.remote\u003eIsaac Challenge Environments\u003c/a\u003e\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\\n\u003cp\u003eInstall the Isaac SDK by following the instructions \u003ca href=\\\"https://docs.nvidia.com/isaac/archive/2019.2/doc/setup.html\\\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\\n\u003cp\u003eClone the BenchBot simulator, apply our patches to the installed Isaac SDK, \u0026amp; build the simulator using the Bazel wrapper script (ensure the environment variable \u003ccode class=\\\"language-none\\\"\u003eISAAC_SDK_PATH\u003c/code\u003e is set to where you installed Isaac SDK):\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003eu@pc:~$ git clone https://github.com/qcr/benchbot_simulator \u0026amp;\u0026amp; cd benchbot_simulator\\nu@pc:~$ .isaac_patches/apply_patches\\nu@pc:~$ ./bazelros build //apps/benchbot_simulator\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003c/li\u003e\\n\u003c/ol\u003e\\n\u003ch2\u003eRunning BenchBot Simulator\u003c/h2\u003e\\n\u003cp\u003eThe BenchBot simulator interface is run alongside a running Isaac Unreal Engine Simulator. To get both components running:\u003c/p\u003e\\n\u003col\u003e\\n\u003cli\u003e\\n\u003cp\u003eStart the Unreal Engine Simulator, either via our precompiled environments or the IsaacSimProject Unreal Editor:\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003eu@pc:~$ ./IsaacSimProject \u0026lt;map_name\u0026gt; \\\\\\n    -isaac_sim_config_json='\u0026lt;path_to_isaac\u0026gt;/apps/carter/carter_sim/bridge_config/carter_full.json' \\\\\\n    -windowed -ResX=960 -ResY=540 -vulkan -game\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\\n\u003cp\u003eLaunch BenchBot simulator Isaac application (you first need to hardcode the pose unfortunately...):\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003eu@pc:~$ START_POSE=\u0026lt;robot_start_pose\u0026gt; \\\\\\n    sed -i \u0026quot;0,/\\\\\u0026quot;pose\\\\\u0026quot;:/{s/\\\\(\\\\\u0026quot;pose\\\\\u0026quot;: \\\\)\\\\(.*\\\\)/\\\\1$START_POSE}\u0026quot; \\\\\\n    \u0026lt;path_to_isaac\u0026gt;/apps/carter/carter_sim/bridge_config/carter_full_config.json\\nu@pc:~$ ./bazelros run //apps/benchbot_simulator\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003c/li\u003e\\n\u003c/ol\u003e\\n\u003cp\u003eAt this point you will have a running Isaac Unreal Engine Simulator, with sensorimotor data available from the robot in ROS!\u003c/p\u003e\\n\u003ch2\u003eUsing BenchBot Simulator with the BenchBot Robot Controller\u003c/h2\u003e\\n\u003cp\u003eThe \u003ca href=https://github.com/qcr/benchbot_robot_controller\u003eBenchBot Robot Controller\u003c/a\u003e is a wrapping ROS / HTTP hybrid script that manages running robots and their required subprocesses. See the \u003ccode class=\\\"language-none\\\"\u003ecarter_sim.yaml\u003c/code\u003e configuration in the \u003ca href=https://github.com/qcr/benchbot_supervisor\u003eBenchBot Supervisor\u003c/a\u003e for an example configuration of how to run BenchBot Simulator through the Robot Controller.\u003c/p\u003e\\n\",\"name\":\"BenchBot Simulator (Isaac)\",\"type\":\"code\",\"url\":\"https://github.com/qcr/benchbot_simulator\",\"src\":\"/content/benchbot/benchbot-simulator.md\",\"id\":\"benchbot-simulator\",\"image_position\":\"center\",\"image\":\"/_next/static/gifs/ec1857995c55d26bf6712cf7c339dbae.jpg\",\"_image\":\"/_next/static/gifs/ec1857995c55d26bf6712cf7c339dbae.webm\"}],\"datasets\":[{\"content\":\"\u003cp\u003eThe Semantic Scene Understanding (development) is a set of Unreal Engine environments for use with the \u003ca href=\\\"http://benchbot.org\\\"\u003eBenchBot software stack\u003c/a\u003e in the \u003ca href=\\\"https://evalai.cloudcv.org/web/challenges/challenge-page/625/overview\\\"\u003eACRV Semantic Scene Understanding Challenge\u003c/a\u003e. A collage of the robot starting position for each of the environments is shown below:\u003c/p\u003e\\n\u003cp\u003e\u003cimg src=\\\"/_next/static/images/develop_envs-c77d4d986222aed06900114eb00b4663.png\\\" alt=\\\"Robot starting positions in environments from the semantic scene understanding (development) dataset\\\"\u003e\u003c/p\u003e\\n\u003cp\u003eFeatures of the dataset include:\u003c/p\u003e\\n\u003cul\u003e\\n\u003cli\u003ea total of 10 different environments\u003c/li\u003e\\n\u003cli\u003e2 different places: a small apartment room, and a Scandinavian house\u003c/li\u003e\\n\u003cli\u003eeach place has 5 different variations\u003c/li\u003e\\n\u003cli\u003ebetween variations there are changes in lighting, time of day, starting location, robot trajectory, and object placements\u003c/li\u003e\\n\u003c/ul\u003e\\n\u003cp\u003eFor more details of the dataset, challenge, BenchBot, and how it all fits together, please see our summary video below:\u003c/p\u003e\\n\u003cdiv class=\\\"embedded-block block-embed-service-youtube\\\"\u003e\u003ciframe type=\\\"text/html\\\" src=\\\"//www.youtube.com/embed/jQPkV29KFvI\\\" frameborder=\\\"0\\\" width=\\\"640\\\" height=\\\"390\\\" webkitallowfullscreen mozallowfullscreen allowfullscreen\u003e\u003c/iframe\u003e\u003c/div\u003e\\n\",\"name\":\"Semantic Scene Understanding (development)\",\"type\":\"dataset\",\"url\":\"https://cloudstor.aarnet.edu.au/plus/s/1MNBnLZan8X95qb/download\",\"size\":\"8.4GB\",\"src\":\"/content/benchbot/benchbot-develop.md\",\"id\":\"benchbot-develop\",\"image_position\":\"center\",\"image\":\"/_next/static/images/develop_envs-c77d4d986222aed06900114eb00b4663.png\"},{\"content\":\"\u003cp\u003eThe Semantic Scene Understanding (challenge) is a set of Unreal Engine environments for use with the \u003ca href=\\\"http://benchbot.org\\\"\u003eBenchBot software stack\u003c/a\u003e in the \u003ca href=\\\"https://evalai.cloudcv.org/web/challenges/challenge-page/625/overview\\\"\u003eACRV Semantic Scene Understanding Challenge\u003c/a\u003e. A collage of the robot starting position for each of the environments is shown below:\u003c/p\u003e\\n\u003cp\u003e\u003cimg src=\\\"/_next/static/images/challenge_envs-1bb1e48b62de2cdd9e3540368bf44c0f.png\\\" alt=\\\"Robot starting positions in environments from the semantic scene understanding (challenge) dataset\\\"\u003e\u003c/p\u003e\\n\u003cp\u003eFeatures of the dataset include:\u003c/p\u003e\\n\u003cul\u003e\\n\u003cli\u003ea total of 15 different environments\u003c/li\u003e\\n\u003cli\u003e3 different places: a luxurious penthouse apartment, an office workspace and a large corporate building\u003c/li\u003e\\n\u003cli\u003eeach place has 5 different variations\u003c/li\u003e\\n\u003cli\u003ebetween variations there are changes in lighting, time of day, starting location, robot trajectory, and object placements\u003c/li\u003e\\n\u003c/ul\u003e\\n\u003cp\u003eFor more details of the dataset, challenge, BenchBot, and how it all fits together, please see our summary video below:\u003c/p\u003e\\n\u003cdiv class=\\\"embedded-block block-embed-service-youtube\\\"\u003e\u003ciframe type=\\\"text/html\\\" src=\\\"//www.youtube.com/embed/jQPkV29KFvI\\\" frameborder=\\\"0\\\" width=\\\"640\\\" height=\\\"390\\\" webkitallowfullscreen mozallowfullscreen allowfullscreen\u003e\u003c/iframe\u003e\u003c/div\u003e\\n\",\"name\":\"Semantic Scene Understanding (challenge)\",\"type\":\"dataset\",\"url\":\"https://cloudstor.aarnet.edu.au/plus/s/gRg5N85PZYRcI2c/download\",\"size\":\"7.5GB\",\"src\":\"/content/benchbot/benchbot-challenge.md\",\"id\":\"benchbot-challenge\",\"image_position\":\"center\",\"image\":\"/_next/static/images/challenge_envs-1bb1e48b62de2cdd9e3540368bf44c0f.png\"}],\"feature\":1,\"src\":\"/content/benchbot/collection.md\",\"image_position\":\"100% center\",\"image\":\"/_next/static/gifs/0f460afe63fb093a8b44efcd5c652cf8.jpg\"},{\"content\":\"\u003cp\u003eThe Human Cues for Robot Navigation ARC Discovery Project (DP140103216) investigated how a robot can navigate using the same navigation cues humans use when navigating built environments. Types of navigation cues targeted include labels, directional signs, signboards, maps \u0026amp; floor plans, navigational gestures, and spoken directions \u0026amp; descriptions. The main contribution from this work is the abstract map, a navigational tool that allows a robot to employ symbolic spatial information in its navigation of unseen spaces.\u003c/p\u003e\\n\",\"name\":\"Human Cues for Robot Navigation\",\"type\":\"collection\",\"url\":\"https://btalb.github.io/abstract_map\",\"code\":[{\"content\":\"\u003cp align=center\u003e\u003cstrong\u003e~ Please see the \u003ca href=\\\"https://btalb.github.io/abstract_map/\\\"\u003eabstract map site\u003c/a\u003e for further details about the research publication ~\u003c/strong\u003e\u003c/p\u003e\\n\u003ch1\u003eThe Abstract Map - using symbols to navigate\u003c/h1\u003e\\n\u003cp\u003e\u003cimg src=\\\"/_next/static/images/abstract_map_in_action-261a2f7eea1f79411b48203e72995f14.png\\\" alt=\\\"The abstract map in action\\\"\u003e\u003c/p\u003e\\n\u003cp\u003eThis repository provides the implementation of the abstract map used in our \u003ca href=\\\"https://doi.org/10.1109/TCDS.2020.2993855\\\"\u003eIEEE TCDS journal\u003c/a\u003e. The implementation, done in Python, includes the following features:\u003c/p\u003e\\n\u003cul\u003e\\n\u003cli\u003ea novel dynamics-based malleable spatial model for imagining unseen spaces from symbols (which includes simulated springs, friction, repulsive forces, \u0026amp; collision models)\u003c/li\u003e\\n\u003cli\u003ea visualiser \u0026amp; text-based commentator for introspection of your navigation system (both shown in videos on the \u003ca href=\\\"https://btalb.github.io/abstract_map/\\\"\u003erepository website\u003c/a\u003e)\u003c/li\u003e\\n\u003cli\u003eeasy ROS bindings for getting up \u0026amp; running in simulation or on a real robot\u003c/li\u003e\\n\u003cli\u003etag readers \u0026amp; interpreters for extracting symbolic spatial information from \u003ca href=\\\"http://wiki.ros.org/apriltag_ros\\\"\u003eAprilTags\u003c/a\u003e\u003c/li\u003e\\n\u003cli\u003econfiguration files for the zoo experiments performed on GP-S11 of QUT's Gardens Point campus (see \u003ca href=\\\"https://doi.org/10.1109/TCDS.2020.2993855\\\"\u003ethe paper\u003c/a\u003e for further details)\u003c/li\u003e\\n\u003cli\u003eserialisation methods for passing an entire abstract map state between machines, or saving to file\u003c/li\u003e\\n\u003c/ul\u003e\\n\u003cp\u003ePlease see our other related repositories for further resources, and related parts of the abstract map studies:\u003c/p\u003e\\n\u003cul\u003e\\n\u003cli\u003e\u003cstrong\u003e\u003ca href=https://github.com/btalb/abstract_map_simulator\u003eabstract_map_simulator\u003c/a\u003e:\u003c/strong\u003e all of the resources needed to run a full 2D simulation of the zoo experiments performed on GP-S11 of our Gardens Point campus at QUT\u003c/li\u003e\\n\u003cli\u003e\u003cstrong\u003e\u003ca href=https://github.com/btalb/abstract_map_app\u003eabstract_map_app\u003c/a\u003e:\u003c/strong\u003e mobile Android application used by human participants to complete navigation tasks as part of the zoo experiments (the app used the on-board camera to scan tags \u0026amp; present the mapped symbolic spatial information in real time)\u003c/li\u003e\\n\u003c/ul\u003e\\n\u003ch2\u003eGetting up \u0026amp; running with the abstract map\u003c/h2\u003e\\n\u003cp\u003e\u003cem\u003eNote: if you wish to run this in simulation (significantly easier than on a real robot platform), you will also need the \u003ca href=https://github.com/btalb/abstract_map_simulator\u003eabstract_map_simulator\u003c/a\u003e package\u003c/em\u003e\u003c/p\u003e\\n\u003ch3\u003eSetting up your environment\u003c/h3\u003e\\n\u003cp\u003eClone the repo \u0026amp; install all Python dependencies:\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003egit clone https://github.com/btalb/abstract_map\\npip install -r abstract_map/requirements.txt\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eAdd the new package to your ROS workspace at \u003ccode class=\\\"language-none\\\"\u003e\u0026lt;ROS_WS\u0026gt;/\u003c/code\u003e by linking in the cloned repository:\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003eln -s \u0026lt;LOCATION_REPO_WAS_CLONED_ABOVE\u0026gt; \u0026lt;ROS_WS\u0026gt;/src/\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eInstall all of the listed ROS dependencies, and build the package:\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003ecd \u0026lt;ROS_WS\u0026gt;/src/\\nrosdep install abstract_map\\ncd \u0026lt;ROS_WS\u0026gt;\\ncatkin_make\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003ch3\u003eRunning the Zoo experiments\u003c/h3\u003e\\n\u003cp\u003eStart the experiment (this will try \u0026amp; launch the 2D simulation back-end by default, so make sure you have that installed if you are using it):\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003eroslaunch abstract_map experiment.launch\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003e\u003cem\u003e(please see \u003ca href=https://github.com/btalb/abstract_map_simulator/issues/1\u003ethis issue\u003c/a\u003e for details if you get the spam of TF based errors... which probably shouldn't even be errors... )\u003c/em\u003e\u003c/p\u003e\\n\u003cp\u003eIn another terminal, start the hierarchy publisher to give the abstract map the contextual symbolic spatial information to begin with:\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003erosrun abstract_map hierarchy_publisher\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eThis will use the hierarchy available in \u003ccode class=\\\"language-none\\\"\u003e./experiments/zoo_hierarchy.xml\u003c/code\u003e by default. Feel free to make your own if you would like to do different experiments.\u003c/p\u003e\\n\u003cp\u003eStart the visualiser in preparation of beginning the experiment (pick either light or dark mode with one of the two commands):\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003erosrun abstract_map visualiser\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003erosrun abstract_map visualiser --dark\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003e\u003cimg src=\\\"/_next/static/images/abstract_map_light_vs_dark-ae93c3e7b8419b56719b5d876dd150f4.png\\\" alt=\\\"Visualise the abstract map with dark or light colours\\\"\u003e\u003c/p\u003e\\n\u003cp\u003eFinally, start the abstract map with a goal, and watch it attempt to complete the navigation task:\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003eroslaunch abstract_map abstract_map.launch goal:=Lion\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eIf you want to manually drive the robot around and observe how the abstract map evolves over time, you can run the above command without a goal to start in \u0026quot;observe mode\u0026quot;.\u003c/p\u003e\\n\u003ch2\u003eAcknowledgements \u0026amp; Citing our work\u003c/h2\u003e\\n\u003cp\u003eThis work was supported by the Australian Research Council's Discovery Projects Funding Scheme under Project DP140103216. The authors are with the \u003ca href=\\\"https://research.qut.edu.au/qcr/\\\"\u003eQUT Centre for Robotics\u003c/a\u003e.\u003c/p\u003e\\n\u003cp\u003eIf you use this software in your research, or for comparisons, please kindly cite our work:\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003e@ARTICLE{9091567,  \\n    author={B. {Talbot} and F. {Dayoub} and P. {Corke} and G. {Wyeth}},  \\n    journal={IEEE Transactions on Cognitive and Developmental Systems},   \\n    title={Robot Navigation in Unseen Spaces using an Abstract Map},   \\n    year={2020},  \\n    volume={},  \\n    number={},  \\n    pages={1-1},\\n    keywords={Navigation;Robot sensing systems;Measurement;Linguistics;Visualization;symbol grounding;symbolic spatial information;abstract map;navigation;cognitive robotics;intelligent robots.},\\n    doi={10.1109/TCDS.2020.2993855},\\n    ISSN={2379-8939},\\n    month={},}\\n}\\n\u003c/code\u003e\u003c/pre\u003e\\n\",\"name\":\"Abstract Map (Python)\",\"type\":\"code\",\"url\":\"https://github.com/btalb/abstract_map\",\"src\":\"/content/human_cues/abstract-map.md\",\"id\":\"abstract-map\",\"image_position\":\"center\",\"image\":\"/_next/static/images/abstract_map_in_action-261a2f7eea1f79411b48203e72995f14.png\"},{\"content\":\"\u003cp align=center\u003e\u003cstrong\u003e~ Please see the \u003ca href=\\\"https://btalb.github.io/abstract_map/\\\"\u003eabstract map site\u003c/a\u003e for further details about the research publication ~\u003c/strong\u003e\u003c/p\u003e\\n\u003ch1\u003eUsing the Abstract Map in a 2D Stage simulation\u003c/h1\u003e\\n\u003cp\u003e\u003cimg src=\\\"/_next/static/images/abstract_map_simulation-8e1275a3c88423d73d8d661443eeefdf.png\\\" alt=\\\"2D Stage simulation with with simulated tags\\\"\u003e\u003c/p\u003e\\n\u003cp\u003ePackage contains everything needed to simulate the zoo experiments performed in our \u003ca href=\\\"https://doi.org/10.1109/TCDS.2020.2993855\\\"\u003eIEEE TCDS journal\u003c/a\u003e. The package includes:\u003c/p\u003e\\n\u003cul\u003e\\n\u003cli\u003eworld \u0026amp; launch files for a stage simulation of the GP-S11 environment on QUT's Gardens Point campus\u003c/li\u003e\\n\u003cli\u003ea tool for creating simulated tags in an environment \u0026amp; saving them to file,\u003c/li\u003e\\n\u003cli\u003elaunch \u0026amp; config files for using the move_base navigation stack with gmapping to explore unseen simulated environments\u003c/li\u003e\\n\u003c/ul\u003e\\n\u003ch2\u003eInstalling the abstract map simulator\u003c/h2\u003e\\n\u003cp\u003e\u003cem\u003eNote: this is just the simulator; to use the abstract map with the simulator please make sure you use the \u003ca href=https://github.com/btalb/abstract_map\u003eabstract_map\u003c/a\u003e package\u003c/em\u003e\u003c/p\u003e\\n\u003cp\u003eClone the repo \u0026amp; install all Python dependencies:\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003egit clone https://github.com/btalb/abstract_map_simulator\\npip install -r abstract_map_simulator/requirements.txt\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eAdd the new package to your ROS workspace at \u003ccode class=\\\"language-none\\\"\u003e\u0026lt;ROS_WS\u0026gt;/\u003c/code\u003e by linking in the cloned repository:\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003eln -s \u0026lt;LOCATION_REPO_WAS_CLONED_ABOVE\u0026gt; \u0026lt;ROS_WS\u0026gt;/src/\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eInstall all of the listed ROS dependencies, and build the package:\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003ecd \u0026lt;ROS_WS\u0026gt;/src/\\nrosdep install abstract_map_simulator\\ncd \u0026lt;ROS_WS\u0026gt;\\ncatkin_make\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003ch2\u003eAcknowledgements \u0026amp; Citing our work\u003c/h2\u003e\\n\u003cp\u003eThis work was supported by the Australian Research Council's Discovery Projects Funding Scheme under Project DP140103216. The authors are with the \u003ca href=\\\"https://research.qut.edu.au/qcr/\\\"\u003eQUT Centre for Robotics\u003c/a\u003e.\u003c/p\u003e\\n\u003cp\u003eIf you use this software in your research, or for comparisons, please kindly cite our work:\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003e@ARTICLE{9091567,  \\n    author={B. {Talbot} and F. {Dayoub} and P. {Corke} and G. {Wyeth}},  \\n    journal={IEEE Transactions on Cognitive and Developmental Systems},   \\n    title={Robot Navigation in Unseen Spaces using an Abstract Map},   \\n    year={2020},  \\n    volume={},  \\n    number={},  \\n    pages={1-1},\\n    keywords={Navigation;Robot sensing systems;Measurement;Linguistics;Visualization;symbol grounding;symbolic spatial information;abstract map;navigation;cognitive robotics;intelligent robots.},\\n    doi={10.1109/TCDS.2020.2993855},\\n    ISSN={2379-8939},\\n    month={},}\\n}\\n\u003c/code\u003e\u003c/pre\u003e\\n\",\"name\":\"2D Simulator for Zoo Experiments\",\"type\":\"code\",\"url\":\"https://github.com/btalb/abstract_map_simulator\",\"src\":\"/content/human_cues/abstract-map-simulator.md\",\"id\":\"abstract-map-simulator\",\"image_position\":\"center\",\"image\":\"/_next/static/images/abstract_map_simulation-8e1275a3c88423d73d8d661443eeefdf.png\"},{\"content\":\"\u003cp align=center\u003e\u003cstrong\u003e~ Please see the \u003ca href=\\\"https://btalb.github.io/abstract_map/\\\"\u003eabstract map site\u003c/a\u003e for further details about the research publication ~\u003c/strong\u003e\u003c/p\u003e\\n\u003ch1\u003eApp for the Human vs Abstract Map Zoo Experiments\u003c/h1\u003e\\n\u003cp\u003e\u003cvideo autoplay loop poster=\\\"/_next/static/gifs/1e64d3716d81982074296f38479c3ae2.jpg\\\"\u003e\u003csource src=\\\"/_next/static/gifs/1e64d3716d81982074296f38479c3ae2.webm\\\" type=\\\"video/webm\\\"/\u003e\u003c/video\u003e\u003c/p\u003e\\n\u003cp\u003eThis repository contains the mobile application used by human participants in the zoo experiments described in our \u003ca href=\\\"https://doi.org/10.1109/TCDS.2020.2993855\\\"\u003eIEEE TCDS journal\u003c/a\u003e. The app, created with Android Studio, includes the following:\u003c/p\u003e\\n\u003cul\u003e\\n\u003cli\u003eopening screen for users to select experiment name \u0026amp; goal location\u003c/li\u003e\\n\u003cli\u003elive display of the camera to help users correctly capture a tag\u003c/li\u003e\\n\u003cli\u003einstant visual feedback when a tag is detected, with colouring to denote whether symbolic spatial information is not the goal (red), navigation information (orange), or the goal (green)\u003c/li\u003e\\n\u003cli\u003eexperiment definitions \u0026amp; tag mappings are creatable via the same XML style used in the \u003ca href=https://github.com/btalb/abstract_map\u003eabstract_map\u003c/a\u003e package\u003c/li\u003e\\n\u003cli\u003eintegration with the \u003ca href=https://github.com/AprilRobotics/apriltag\u003enative C AprilTags\u003c/a\u003e using the Android NDK\u003c/li\u003e\\n\u003c/ul\u003e\\n\u003ch2\u003eDeveloping \u0026amp; producing the app\u003c/h2\u003e\\n\u003cp\u003eThe project should be directly openable using Android Studio.\u003c/p\u003e\\n\u003cp\u003ePlease keep in mind that this app was last developed in 2019, and Android Studio often introduces minor breaking changes with new versions. Often you will have to tweak things like Gradle versions / syntax etc. to get a project working with newer versions. Android Studio is very good though with pointing out where it sees errors and offering suggestions for how to resolve them.\u003c/p\u003e\\n\u003cp\u003eOnce you have the project open, you should be able to compile the app and load it directly onto a device without issues.\u003c/p\u003e\\n\u003ch2\u003eAcknowledgements \u0026amp; Citing our work\u003c/h2\u003e\\n\u003cp\u003eThis work was supported by the Australian Research Council's Discovery Projects Funding Scheme under Project DP140103216. The authors are with the \u003ca href=\\\"https://research.qut.edu.au/qcr/\\\"\u003eQUT Centre for Robotics\u003c/a\u003e.\u003c/p\u003e\\n\u003cp\u003eIf you use this software in your research, or for comparisons, please kindly cite our work:\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003e@ARTICLE{9091567,  \\n    author={B. {Talbot} and F. {Dayoub} and P. {Corke} and G. {Wyeth}},  \\n    journal={IEEE Transactions on Cognitive and Developmental Systems},   \\n    title={Robot Navigation in Unseen Spaces using an Abstract Map},   \\n    year={2020},  \\n    volume={},  \\n    number={},  \\n    pages={1-1},\\n    keywords={Navigation;Robot sensing systems;Measurement;Linguistics;Visualization;symbol grounding;symbolic spatial information;abstract map;navigation;cognitive robotics;intelligent robots.},\\n    doi={10.1109/TCDS.2020.2993855},\\n    ISSN={2379-8939},\\n    month={},}\\n}\\n\u003c/code\u003e\u003c/pre\u003e\\n\",\"name\":\"Android App for Human Participants\",\"type\":\"code\",\"url\":\"https://github.com/btalb/abstract_map_app\",\"src\":\"/content/human_cues/abstract-map-app.md\",\"id\":\"abstract-map-app\",\"image_position\":\"center\",\"image\":\"/_next/static/gifs/1e64d3716d81982074296f38479c3ae2.jpg\",\"_image\":\"/_next/static/gifs/1e64d3716d81982074296f38479c3ae2.webm\"}],\"feature\":0,\"src\":\"/content/human_cues/human-cues.md\",\"id\":\"human-cues\",\"image_position\":\"center\",\"image\":\"/_next/static/images/abstract_map_in_action-261a2f7eea1f79411b48203e72995f14.png\"},{\"content\":\"\u003cp\u003ePython Robotics is a collection of software packages providing robotics-specific functionality to Python. While leveraging Python's advantages of portability, ubiquity and support, and the capability of the open-source ecosystem for linear algebra (numpy, scipy), graphics (matplotlib, three.js, WebGL), interactive development (jupyter, jupyterlab, mybinder.org), and documentation (sphinx).\u003c/p\u003e\\n\u003cp\u003eThe collection is built on top of Spatialmath which underpins all of robotics and robotic vision where we need to describe the position, orientation or pose of objects in 2D or 3D spaces. The core of the collection is the the Robotics Toolbox for Python while Swift provides a light-weight browser-based simulation environment.\u003c/p\u003e\\n\",\"name\":\"Python Robotics\",\"type\":\"collection\",\"url\":\"https://petercorke.github.io/robotics-toolbox-python/\",\"image\":\"/_next/static/images/RobToolBox_RoundLogoB-9563d226662903b6e404b809e72e3235.png\",\"image_fit\":\"contain\",\"id\":\"python_robotics\",\"code\":[{\"content\":\"\u003ch1\u003eSpatial Maths for Python\u003c/h1\u003e\\n\u003cp\u003e\u003ca href=\\\"https://badge.fury.io/py/spatialmath-python\\\"\u003e\u003cimg src=\\\"https://badge.fury.io/py/spatialmath-python.svg\\\" alt=\\\"PyPI version\\\"\u003e\u003c/a\u003e\\n\u003cimg src=\\\"https://img.shields.io/pypi/pyversions/roboticstoolbox-python.svg\\\" alt=\\\"PyPI - Python Version\\\"\u003e\\n\u003ca href=\\\"https://opensource.org/licenses/MIT\\\"\u003e\u003cimg src=\\\"https://img.shields.io/badge/License-MIT-yellow.svg\\\" alt=\\\"License: MIT\\\"\u003e\u003c/a\u003e\\n\u003ca href=\\\"https://qcr.github.io\\\"\u003e\u003cimg src=https://github.com/qcr/qcr.github.io/raw/master/misc/badge.svg alt=\\\"QUT Centre for Robotics Open Source\\\"\u003e\u003c/a\u003e\u003c/p\u003e\\n\u003cp\u003e\u003ca href=https://github.com/petercorke/spatialmath-python/actions?query=workflow%3Abuild\u003e\u003cimg src=https://github.com/petercorke/spatialmath-python/workflows/build/badge.svg?branch=master alt=\\\"Build Status\\\"\u003e\u003c/a\u003e\\n\u003ca href=\\\"https://codecov.io/gh/petercorke/spatialmath-python\\\"\u003e\u003cimg src=\\\"https://codecov.io/gh/petercorke/spatialmath-python/branch/master/graph/badge.svg\\\" alt=\\\"Coverage\\\"\u003e\u003c/a\u003e\\n\u003ca href=\\\"https://lgtm.com/projects/g/petercorke/spatialmath-python/context:python\\\"\u003e\u003cimg src=\\\"https://img.shields.io/lgtm/grade/python/g/petercorke/spatialmath-python.svg?logo=lgtm\u0026amp;logoWidth=18\\\" alt=\\\"Language grade: Python\\\"\u003e\u003c/a\u003e\\n\u003ca href=\\\"https://pypistats.org/packages/spatialmath-python\\\"\u003e\u003cimg src=\\\"https://img.shields.io/pypi/dw/spatialmath-python\\\" alt=\\\"PyPI - Downloads\\\"\u003e\u003c/a\u003e\\n\u003ca href=https://GitHub.com/petercorke/spatialmath-python/stargazers/\u003e\u003cimg src=\\\"https://img.shields.io/github/stars/petercorke/spatialmath-python.svg?style=social\u0026amp;label=Star\\\" alt=\\\"GitHub stars\\\"\u003e\u003c/a\u003e\u003c/p\u003e\\n\u003ctable style=\\\"border:0px\\\"\u003e\\n\u003ctr style=\\\"border:0px\\\"\u003e\\n\u003ctd style=\\\"border:0px\\\"\u003e\\n\u003cimg src=https://github.com/petercorke/spatialmath-python/raw/master/docs/figs/CartesianSnakes_LogoW.png width=\\\"200\\\"\u003e\u003c/td\u003e\\n\u003ctd style=\\\"border:0px\\\"\u003e\\nA Python implementation of the \u003ca href=\\\"https://github.com/petercorke/spatial-math\\\"\u003eSpatial Math Toolbox for MATLAB\u003csup\u003e\u0026reg;\u003c/sup\u003e\u003c/a\u003e\\n\u003cul\u003e\\n\u003cli\u003e\u003ca href=\\\"https://github.com/petercorke/spatialmath-python\\\"\u003eGitHub repository \u003c/a\u003e\u003c/li\u003e\\n\u003cli\u003e\u003ca href=\\\"https://petercorke.github.io/spatialmath-python\\\"\u003eDocumentation\u003c/a\u003e\u003c/li\u003e\\n\u003cli\u003e\u003ca href=\\\"https://github.com/petercorke/spatialmath-python/wiki\\\"\u003eExamples and details\u003c/a\u003e\u003c/li\u003e\\n\u003cli\u003e\u003ca href=\\\"installation#\\\"\u003eInstallation\u003c/a\u003e\u003c/li\u003e\\n\u003c/ul\u003e\\n\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003c/table\u003e\\n\u003cp\u003eSpatial mathematics capability underpins all of robotics and robotic vision where we need to describe the position, orientation or pose of objects in 2D or 3D spaces.\u003c/p\u003e\\n\u003ch1\u003eWhat it does\u003c/h1\u003e\\n\u003cp\u003eThe package provides classes to represent pose and orientation in 3D and 2D\\nspace:\u003c/p\u003e\\n\u003ctable\u003e\\n\u003cthead\u003e\\n\u003ctr\u003e\\n\u003cth\u003eRepresents\u003c/th\u003e\\n\u003cth\u003ein 3D\u003c/th\u003e\\n\u003cth\u003ein 2D\u003c/th\u003e\\n\u003c/tr\u003e\\n\u003c/thead\u003e\\n\u003ctbody\u003e\\n\u003ctr\u003e\\n\u003ctd\u003epose\u003c/td\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003eSE3\u003c/code\u003e \u003ccode class=\\\"language-none\\\"\u003eTwist3\u003c/code\u003e \u003ccode class=\\\"language-none\\\"\u003eUnitDualQuaternion\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003eSE2\u003c/code\u003e \u003ccode class=\\\"language-none\\\"\u003eTwist2\u003c/code\u003e\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003ctr\u003e\\n\u003ctd\u003eorientation\u003c/td\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003eSO3\u003c/code\u003e \u003ccode class=\\\"language-none\\\"\u003eUnitQuaternion\u003c/code\u003e\u003c/td\u003e\\n\u003ctd\u003e\u003ccode class=\\\"language-none\\\"\u003eSO2\u003c/code\u003e\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003c/tbody\u003e\\n\u003c/table\u003e\\n\u003cp\u003eMore specifically:\u003c/p\u003e\\n\u003cul\u003e\\n\u003cli\u003e\u003ccode class=\\\"language-none\\\"\u003eSE3\u003c/code\u003e matrices belonging to the group SE(3) for position and orientation (pose) in 3-dimensions\u003c/li\u003e\\n\u003cli\u003e\u003ccode class=\\\"language-none\\\"\u003eSO3\u003c/code\u003e matrices belonging to the group SO(3) for orientation in 3-dimensions\u003c/li\u003e\\n\u003cli\u003e\u003ccode class=\\\"language-none\\\"\u003eUnitQuaternion\u003c/code\u003e belonging to the group S3 for orientation in 3-dimensions\u003c/li\u003e\\n\u003cli\u003e\u003ccode class=\\\"language-none\\\"\u003eTwist3\u003c/code\u003e vectors belonging to the group se(3) for pose in 3-dimensions\u003c/li\u003e\\n\u003cli\u003e\u003ccode class=\\\"language-none\\\"\u003eUnitDualQuaternion\u003c/code\u003e maps to the group SE(3) for position and orientation (pose) in 3-dimensions\u003c/li\u003e\\n\u003cli\u003e\u003ccode class=\\\"language-none\\\"\u003eSE2\u003c/code\u003e matrices belonging to the group SE(2) for position and orientation (pose) in 2-dimensions\u003c/li\u003e\\n\u003cli\u003e\u003ccode class=\\\"language-none\\\"\u003eSO2\u003c/code\u003e matrices belonging to the group SO(2) for orientation in 2-dimensions\u003c/li\u003e\\n\u003cli\u003e\u003ccode class=\\\"language-none\\\"\u003eTwist2\u003c/code\u003e vectors belonging to the group se(2) for pose in 2-dimensions\u003c/li\u003e\\n\u003c/ul\u003e\\n\u003cp\u003eThese classes provide convenience and type safety, as well as methods and overloaded operators to support:\u003c/p\u003e\\n\u003cul\u003e\\n\u003cli\u003ecomposition, using the \u003ccode class=\\\"language-none\\\"\u003e*\u003c/code\u003e operator\u003c/li\u003e\\n\u003cli\u003epoint transformation, using the \u003ccode class=\\\"language-none\\\"\u003e*\u003c/code\u003e operator\u003c/li\u003e\\n\u003cli\u003eexponent, using the \u003ccode class=\\\"language-none\\\"\u003e**\u003c/code\u003e operator\u003c/li\u003e\\n\u003cli\u003enormalization\u003c/li\u003e\\n\u003cli\u003einversion\u003c/li\u003e\\n\u003cli\u003econnection to the Lie algebra via matrix exponential and logarithm operations\u003c/li\u003e\\n\u003cli\u003econversion of orientation to/from Euler angles, roll-pitch-yaw angles and angle-axis forms.\u003c/li\u003e\\n\u003cli\u003elist operations such as append, insert and get\u003c/li\u003e\\n\u003c/ul\u003e\\n\u003cp\u003eThese are layered over a set of base functions that perform many of the same operations but represent data explicitly in terms of \u003ccode class=\\\"language-none\\\"\u003enumpy\u003c/code\u003e arrays.\u003c/p\u003e\\n\u003cp\u003eThe class, method and functions names largely mirror those of the MATLAB toolboxes, and the semantics are quite similar.\u003c/p\u003e\\n\u003cp\u003e\u003cimg src=https://github.com/petercorke/spatialmath-python/raw/master/docs/figs/fig1.png alt=\\\"trplot\\\"\u003e\u003c/p\u003e\\n\u003cp\u003e\u003cvideo autoplay loop poster=\\\"/_next/static/gifs/f53aa66b328813113b38f087b50da80f.jpg\\\"\u003e\u003csource src=\\\"/_next/static/gifs/f53aa66b328813113b38f087b50da80f.webm\\\" type=\\\"video/webm\\\"/\u003e\u003c/video\u003e\u003c/p\u003e\\n\u003ch1\u003eInstallation\u003c/h1\u003e\\n\u003ch2\u003eUsing pip\u003c/h2\u003e\\n\u003cp\u003eInstall a snapshot from PyPI\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003epip install spatialmath-python\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003ch2\u003eFrom GitHub\u003c/h2\u003e\\n\u003cp\u003eInstall the current code base from GitHub and pip install a link to that cloned copy\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003egit clone https://github.com/petercorke/spatialmath-python.git\\ncd spatialmath-python\\npip install -e .\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003ch2\u003eDependencies\u003c/h2\u003e\\n\u003cp\u003e\u003ccode class=\\\"language-none\\\"\u003enumpy\u003c/code\u003e, \u003ccode class=\\\"language-none\\\"\u003escipy\u003c/code\u003e, \u003ccode class=\\\"language-none\\\"\u003ematplotlib\u003c/code\u003e, \u003ccode class=\\\"language-none\\\"\u003effmpeg\u003c/code\u003e (if rendering animations as a movie)\u003c/p\u003e\\n\u003ch1\u003eExamples\u003c/h1\u003e\\n\u003ch2\u003eHigh-level classes\u003c/h2\u003e\\n\u003cp\u003eThese classes abstract the low-level numpy arrays into objects that obey the rules associated with the mathematical groups SO(2), SE(2), SO(3), SE(3) as well as twists and quaternions.\u003c/p\u003e\\n\u003cp\u003eUsing classes ensures type safety, for example it stops us mixing a 2D homogeneous transformation with a 3D rotation matrix -- both of which are 3x3 matrices.  It also ensures that the internal matrix representation is always a valid member of the relevant group.\u003c/p\u003e\\n\u003cp\u003eFor example, to create an object representing a rotation of 0.3 radians about the x-axis is simply\u003c/p\u003e\\n\u003cpre class=\\\"language-python\\\"\u003e\u003ccode class=\\\"language-python\\\"\u003e\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003e\u003c/span\u003e\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003c/span\u003e R1 \u003cspan class=\\\"token operator\\\"\u003e=\u003c/span\u003e SO3\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eRx\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e0.3\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003e\u003c/span\u003e\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003c/span\u003e R1\\n   \u003cspan class=\\\"token number\\\"\u003e1\u003c/span\u003e         \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e         \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e          \\n   \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e         \u003cspan class=\\\"token number\\\"\u003e0.955336\u003c/span\u003e \u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e0.29552\u003c/span\u003e    \\n   \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e         \u003cspan class=\\\"token number\\\"\u003e0.29552\u003c/span\u003e   \u003cspan class=\\\"token number\\\"\u003e0.955336\u003c/span\u003e         \\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003ewhile a rotation of 30 deg about the z-axis is\u003c/p\u003e\\n\u003cpre class=\\\"language-python\\\"\u003e\u003ccode class=\\\"language-python\\\"\u003e\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003e\u003c/span\u003e\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003c/span\u003e R2 \u003cspan class=\\\"token operator\\\"\u003e=\u003c/span\u003e SO3\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eRz\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e30\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e \u003cspan class=\\\"token string\\\"\u003e'deg'\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003e\u003c/span\u003e\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003c/span\u003e R2\\n   \u003cspan class=\\\"token number\\\"\u003e0.866025\u003c/span\u003e \u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e0.5\u003c/span\u003e       \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e          \\n   \u003cspan class=\\\"token number\\\"\u003e0.5\u003c/span\u003e       \u003cspan class=\\\"token number\\\"\u003e0.866025\u003c/span\u003e  \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e          \\n   \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e         \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e         \u003cspan class=\\\"token number\\\"\u003e1\u003c/span\u003e    \\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eand the composition of these two rotations is\u003c/p\u003e\\n\u003cpre class=\\\"language-python\\\"\u003e\u003ccode class=\\\"language-python\\\"\u003e\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003e\u003c/span\u003e\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003c/span\u003e R \u003cspan class=\\\"token operator\\\"\u003e=\u003c/span\u003e R1 \u003cspan class=\\\"token operator\\\"\u003e*\u003c/span\u003e R2\\n   \u003cspan class=\\\"token number\\\"\u003e0.866025\u003c/span\u003e \u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e0.5\u003c/span\u003e       \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e          \\n   \u003cspan class=\\\"token number\\\"\u003e0.433013\u003c/span\u003e  \u003cspan class=\\\"token number\\\"\u003e0.75\u003c/span\u003e     \u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e0.5\u003c/span\u003e        \\n   \u003cspan class=\\\"token number\\\"\u003e0.25\u003c/span\u003e      \u003cspan class=\\\"token number\\\"\u003e0.433013\u003c/span\u003e  \u003cspan class=\\\"token number\\\"\u003e0.866025\u003c/span\u003e \\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eWe can find the corresponding Euler angles (in radians)\u003c/p\u003e\\n\u003cpre class=\\\"language-python\\\"\u003e\u003ccode class=\\\"language-python\\\"\u003e\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003e\u003c/span\u003e R\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eeul\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\narray\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e[\u003c/span\u003e\u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e1.57079633\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e  \u003cspan class=\\\"token number\\\"\u003e0.52359878\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e  \u003cspan class=\\\"token number\\\"\u003e2.0943951\u003c/span\u003e \u003cspan class=\\\"token punctuation\\\"\u003e]\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eFrequently in robotics we want a sequence, a trajectory, of rotation matrices or poses. These pose classes inherit capability from the \u003ccode class=\\\"language-none\\\"\u003elist\u003c/code\u003e class\u003c/p\u003e\\n\u003cpre class=\\\"language-python\\\"\u003e\u003ccode class=\\\"language-python\\\"\u003e\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003e\u003c/span\u003e\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003c/span\u003e R \u003cspan class=\\\"token operator\\\"\u003e=\u003c/span\u003e SO3\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e   \u003cspan class=\\\"token comment\\\"\u003e# the identity\u003c/span\u003e\\n\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003e\u003c/span\u003e\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003c/span\u003e R\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eappend\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003eR1\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003e\u003c/span\u003e\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003c/span\u003e R\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eappend\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003eR2\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003e\u003c/span\u003e\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003c/span\u003e \u003cspan class=\\\"token builtin\\\"\u003elen\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003eR\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n \u003cspan class=\\\"token number\\\"\u003e3\u003c/span\u003e\\n\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003e\u003c/span\u003e\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003c/span\u003e R\u003cspan class=\\\"token punctuation\\\"\u003e[\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e1\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e]\u003c/span\u003e\\n   \u003cspan class=\\\"token number\\\"\u003e1\u003c/span\u003e         \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e         \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e          \\n   \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e         \u003cspan class=\\\"token number\\\"\u003e0.955336\u003c/span\u003e \u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e0.29552\u003c/span\u003e    \\n   \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e         \u003cspan class=\\\"token number\\\"\u003e0.29552\u003c/span\u003e   \u003cspan class=\\\"token number\\\"\u003e0.955336\u003c/span\u003e             \\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eand this can be used in \u003ccode class=\\\"language-none\\\"\u003efor\u003c/code\u003e loops and list comprehensions.\u003c/p\u003e\\n\u003cp\u003eAn alternative way of constructing this would be (\u003ccode class=\\\"language-none\\\"\u003eR1\u003c/code\u003e, \u003ccode class=\\\"language-none\\\"\u003eR2\u003c/code\u003e defined above)\u003c/p\u003e\\n\u003cpre class=\\\"language-python\\\"\u003e\u003ccode class=\\\"language-python\\\"\u003e\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003e\u003c/span\u003e\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003c/span\u003e R \u003cspan class=\\\"token operator\\\"\u003e=\u003c/span\u003e SO3\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e \u003cspan class=\\\"token punctuation\\\"\u003e[\u003c/span\u003e SO3\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e R1\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e R2 \u003cspan class=\\\"token punctuation\\\"\u003e]\u003c/span\u003e \u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e       \\n\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003e\u003c/span\u003e\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003c/span\u003e \u003cspan class=\\\"token builtin\\\"\u003elen\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003eR\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n \u003cspan class=\\\"token number\\\"\u003e3\u003c/span\u003e\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eMany of the constructors such as \u003ccode class=\\\"language-none\\\"\u003e.Rx\u003c/code\u003e, \u003ccode class=\\\"language-none\\\"\u003e.Ry\u003c/code\u003e and \u003ccode class=\\\"language-none\\\"\u003e.Rz\u003c/code\u003e support vectorization\u003c/p\u003e\\n\u003cpre class=\\\"language-python\\\"\u003e\u003ccode class=\\\"language-python\\\"\u003e\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003e\u003c/span\u003e\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003c/span\u003e R \u003cspan class=\\\"token operator\\\"\u003e=\u003c/span\u003e SO3\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eRx\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e np\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003earange\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e \u003cspan class=\\\"token number\\\"\u003e2\u003c/span\u003e\u003cspan class=\\\"token operator\\\"\u003e*\u003c/span\u003enp\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003epi\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e \u003cspan class=\\\"token number\\\"\u003e0.2\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003e\u003c/span\u003e\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003c/span\u003e \u003cspan class=\\\"token builtin\\\"\u003elen\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003eR\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n \u003cspan class=\\\"token number\\\"\u003e32\u003c/span\u003e\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003ewhich has created, in a single line, a list of rotation matrices.\u003c/p\u003e\\n\u003cp\u003eVectorization also applies to the operators, for instance\u003c/p\u003e\\n\u003cpre class=\\\"language-python\\\"\u003e\u003ccode class=\\\"language-python\\\"\u003e\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003e\u003c/span\u003e\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003c/span\u003e A \u003cspan class=\\\"token operator\\\"\u003e=\u003c/span\u003e R \u003cspan class=\\\"token operator\\\"\u003e*\u003c/span\u003e SO3\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eRy\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e0.5\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003e\u003c/span\u003e\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003c/span\u003e \u003cspan class=\\\"token builtin\\\"\u003elen\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003eR\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n \u003cspan class=\\\"token number\\\"\u003e32\u003c/span\u003e\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003ewill produce a result where each element is the product of each element of the left-hand side with the right-hand side, ie. \u003ccode class=\\\"language-none\\\"\u003eR[i] * SO3.Ry(0.5)\u003c/code\u003e.\u003c/p\u003e\\n\u003cp\u003eSimilarly\u003c/p\u003e\\n\u003cpre class=\\\"language-python\\\"\u003e\u003ccode class=\\\"language-python\\\"\u003e\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003e\u003c/span\u003e\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003c/span\u003e A \u003cspan class=\\\"token operator\\\"\u003e=\u003c/span\u003e SO3\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eRy\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e0.5\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e \u003cspan class=\\\"token operator\\\"\u003e*\u003c/span\u003e R \\n\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003e\u003c/span\u003e\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003c/span\u003e \u003cspan class=\\\"token builtin\\\"\u003elen\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003eR\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n \u003cspan class=\\\"token number\\\"\u003e32\u003c/span\u003e\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003ewill produce a result where each element is the product of the left-hand side with each element of the right-hand side , ie. \u003ccode class=\\\"language-none\\\"\u003eSO3.Ry(0.5) * R[i] \u003c/code\u003e.\u003c/p\u003e\\n\u003cp\u003eFinally\u003c/p\u003e\\n\u003cpre class=\\\"language-python\\\"\u003e\u003ccode class=\\\"language-python\\\"\u003e\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003e\u003c/span\u003e\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003c/span\u003e A \u003cspan class=\\\"token operator\\\"\u003e=\u003c/span\u003e R \u003cspan class=\\\"token operator\\\"\u003e*\u003c/span\u003e R \\n\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003e\u003c/span\u003e\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003c/span\u003e \u003cspan class=\\\"token builtin\\\"\u003elen\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003eR\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n \u003cspan class=\\\"token number\\\"\u003e32\u003c/span\u003e\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003ewill produce a result where each element is the product of each element of the left-hand side with each element of the right-hand side , ie. \u003ccode class=\\\"language-none\\\"\u003eR[i] * R[i] \u003c/code\u003e.\u003c/p\u003e\\n\u003cp\u003eThe underlying representation of these classes is a numpy matrix, but the class ensures that the structure of that matrix is valid for the particular group represented: SO(2), SE(2), SO(3), SE(3).  Any operation that is not valid for the group will return a matrix rather than a pose class, for example\u003c/p\u003e\\n\u003cpre class=\\\"language-python\\\"\u003e\u003ccode class=\\\"language-python\\\"\u003e\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003e\u003c/span\u003e\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003c/span\u003e SO3\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eRx\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e0.3\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e \u003cspan class=\\\"token operator\\\"\u003e*\u003c/span\u003e \u003cspan class=\\\"token number\\\"\u003e2\u003c/span\u003e\\narray\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e[\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e[\u003c/span\u003e \u003cspan class=\\\"token number\\\"\u003e2\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003e        \u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e  \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003e        \u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e  \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003e        \u003cspan class=\\\"token punctuation\\\"\u003e]\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e\\n       \u003cspan class=\\\"token punctuation\\\"\u003e[\u003c/span\u003e \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003e        \u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e  \u003cspan class=\\\"token number\\\"\u003e1.91067298\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e \u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e0.59104041\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e]\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e\\n       \u003cspan class=\\\"token punctuation\\\"\u003e[\u003c/span\u003e \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003e        \u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e  \u003cspan class=\\\"token number\\\"\u003e0.59104041\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e  \u003cspan class=\\\"token number\\\"\u003e1.91067298\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e]\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e]\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n\\n\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003e\u003c/span\u003e\u003cspan class=\\\"token operator\\\"\u003e\u003e\u003c/span\u003e SO3\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eRx\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e0.3\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e \u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e \u003cspan class=\\\"token number\\\"\u003e1\u003c/span\u003e\\narray\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e[\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e[\u003c/span\u003e \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003e        \u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e \u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e1\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003e        \u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e \u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e1\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003e        \u003cspan class=\\\"token punctuation\\\"\u003e]\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e\\n       \u003cspan class=\\\"token punctuation\\\"\u003e[\u003c/span\u003e\u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e1\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003e        \u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e \u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e0.04466351\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e \u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e1.29552021\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e]\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e\\n       \u003cspan class=\\\"token punctuation\\\"\u003e[\u003c/span\u003e\u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e1\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003e        \u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e \u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e0.70447979\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e \u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e0.04466351\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e]\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e]\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eWe can print and plot these objects as well\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003e\u0026gt;\u0026gt;\u0026gt; T = SE3(1,2,3) * SE3.Rx(30, 'deg')\\n\u0026gt;\u0026gt;\u0026gt; T.print()\\n   1         0         0         1          \\n   0         0.866025 -0.5       2          \\n   0         0.5       0.866025  3          \\n   0         0         0         1          \\n\\n\u0026gt;\u0026gt;\u0026gt; T.printline()\\nt =        1,        2,        3; rpy/zyx =       30,        0,        0 deg\\n\\n\u0026gt;\u0026gt;\u0026gt; T.plot()\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003e\u003cimg src=https://github.com/petercorke/spatialmath-python/raw/master/docs/figs/fig1.png alt=\\\"trplot\\\"\u003e\u003c/p\u003e\\n\u003cp\u003e\u003ccode class=\\\"language-none\\\"\u003eprintline\u003c/code\u003e is a compact single line format for tabular listing, whereas \u003ccode class=\\\"language-none\\\"\u003eprint\u003c/code\u003e shows the underlying matrix and for consoles that support it, it is colorised, with rotational elements in red and translational elements in blue.\u003c/p\u003e\\n\u003cp\u003eFor more detail checkout the shipped Python notebooks:\u003c/p\u003e\\n\u003cul\u003e\\n\u003cli\u003e\u003ca href=https://github.com/petercorke/spatialmath-python/blob/master/spatialmath/gentle-introduction.ipynb\u003egentle introduction\u003c/a\u003e\u003c/li\u003e\\n\u003cli\u003e\u003ca href=https://github.com/petercorke/spatialmath-python/blob/master/spatialmath/introduction.ipynb\u003edeeper introduction\u003c/a\u003e\u003c/li\u003e\\n\u003c/ul\u003e\\n\u003cp\u003eYou can browse it statically through the links above, or clone the toolbox and run them interactively using \u003ca href=\\\"https://jupyter.org\\\"\u003eJupyter\u003c/a\u003e or \u003ca href=\\\"https://jupyter.org\\\"\u003eJupyterLab\u003c/a\u003e.\u003c/p\u003e\\n\u003ch2\u003eLow-level spatial math\u003c/h2\u003e\\n\u003cp\u003eImport the low-level transform functions\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003e\u0026gt;\u0026gt;\u0026gt; import spatialmath.base as tr\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eWe can create a 3D rotation matrix\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003e\u0026gt;\u0026gt;\u0026gt; tr.rotx(0.3)\\narray([[ 1.        ,  0.        ,  0.        ],\\n       [ 0.        ,  0.95533649, -0.29552021],\\n       [ 0.        ,  0.29552021,  0.95533649]])\\n\\n\u0026gt;\u0026gt;\u0026gt; tr.rotx(30, unit='deg')\\narray([[ 1.       ,  0.       ,  0.       ],\\n       [ 0.       ,  0.8660254, -0.5      ],\\n       [ 0.       ,  0.5      ,  0.8660254]])\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eThe results are \u003ccode class=\\\"language-none\\\"\u003enumpy\u003c/code\u003e arrays so to perform matrix multiplication you need to use the \u003ccode class=\\\"language-none\\\"\u003e@\u003c/code\u003e operator, for example\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003erotx(0.3) @ roty(0.2)\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eWe also support multiple ways of passing vector information to functions that require it:\u003c/p\u003e\\n\u003cul\u003e\\n\u003cli\u003eas separate positional arguments\u003c/li\u003e\\n\u003c/ul\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003etransl2(1, 2)\\narray([[1., 0., 1.],\\n       [0., 1., 2.],\\n       [0., 0., 1.]])\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cul\u003e\\n\u003cli\u003eas a list or a tuple\u003c/li\u003e\\n\u003c/ul\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003etransl2( [1,2] )\\narray([[1., 0., 1.],\\n       [0., 1., 2.],\\n       [0., 0., 1.]])\\n\\ntransl2( (1,2) )\\nOut[444]: \\narray([[1., 0., 1.],\\n       [0., 1., 2.],\\n       [0., 0., 1.]])\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cul\u003e\\n\u003cli\u003eor as a \u003ccode class=\\\"language-none\\\"\u003enumpy\u003c/code\u003e array\u003c/li\u003e\\n\u003c/ul\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003etransl2( np.array([1,2]) )\\nOut[445]: \\narray([[1., 0., 1.],\\n       [0., 1., 2.],\\n       [0., 0., 1.]])\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eThere is a single module that deals with quaternions, unit or not, and the representation is a \u003ccode class=\\\"language-none\\\"\u003enumpy\u003c/code\u003e array of four elements.  As above, functions can accept the \u003ccode class=\\\"language-none\\\"\u003enumpy\u003c/code\u003e array, a list, dict or \u003ccode class=\\\"language-none\\\"\u003enumpy\u003c/code\u003e row or column vectors.\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003e\u0026gt;\u0026gt;\u0026gt; from spatialmath.base.quaternion import *\\n\u0026gt;\u0026gt;\u0026gt; q = qqmul([1,2,3,4], [5,6,7,8])\\n\u0026gt;\u0026gt;\u0026gt; q\\narray([-60,  12,  30,  24])\\n\u0026gt;\u0026gt;\u0026gt; qprint(q)\\n-60.000000 \u0026lt; 12.000000, 30.000000, 24.000000 \u0026gt;\\n\u0026gt;\u0026gt;\u0026gt; qnorm(q)\\n72.24956747275377\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003ch2\u003eGraphics\u003c/h2\u003e\\n\u003cp\u003e\u003cimg src=https://github.com/petercorke/spatialmath-python/raw/master/docs/figs/transforms3d.png alt=\\\"trplot\\\"\u003e\u003c/p\u003e\\n\u003cp\u003eThe functions support various plotting styles\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003etrplot( transl(1,2,3), frame='A', rviz=True, width=1, dims=[0, 10, 0, 10, 0, 10])\\ntrplot( transl(3,1, 2), color='red', width=3, frame='B')\\ntrplot( transl(4, 3, 1)@trotx(math.pi/3), color='green', frame='c', dims=[0,4,0,4,0,4])\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eAnimation is straightforward\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003etranimate(transl(4, 3, 4)@trotx(2)@troty(-2), frame=' arrow=False, dims=[0, 5], nframes=200)\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eand it can be saved to a file by\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003etranimate(transl(4, 3, 4)@trotx(2)@troty(-2), frame=' arrow=False, dims=[0, 5], nframes=200, movie='out.mp4')\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003e\u003cvideo autoplay loop poster=\\\"/_next/static/gifs/f53aa66b328813113b38f087b50da80f.jpg\\\"\u003e\u003csource src=\\\"/_next/static/gifs/f53aa66b328813113b38f087b50da80f.webm\\\" type=\\\"video/webm\\\"/\u003e\u003c/video\u003e\u003c/p\u003e\\n\u003cp\u003eAt the moment we can only save as an MP4, but the following incantation will covert that to an animated GIF for embedding in web pages\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003effmpeg -i out -r 20 -vf \u0026quot;fps=10,scale=640:-1:flags=lanczos,split[s0][s1];[s0]palettegen[p];[s1][p]paletteuse\u0026quot; out.gif\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003ch2\u003eSymbolic support\u003c/h2\u003e\\n\u003cp\u003eSome functions have support for symbolic variables, for example\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003eimport sympy\\n\\ntheta = sym.symbols('theta')\\nprint(rotx(theta))\\n[[1 0 0]\\n [0 cos(theta) -sin(theta)]\\n [0 sin(theta) cos(theta)]]\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eThe resulting \u003ccode class=\\\"language-none\\\"\u003enumpy\u003c/code\u003e array is an array of symbolic objects not numbers – the constants are also symbolic objects.  You can read the elements of the matrix\u003c/p\u003e\\n\u003cpre class=\\\"language-none\\\"\u003e\u003ccode class=\\\"language-none\\\"\u003ea = T[0,0]\\n\\na\\nOut[258]: 1\\n\\ntype(a)\\nOut[259]: int\\n\\na = T[1,1]\\na\\nOut[256]: \\ncos(theta)\\ntype(a)\\nOut[255]: cos\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eWe see that the symbolic constants are converted back to Python numeric types on read.\u003c/p\u003e\\n\u003cp\u003eSimilarly when we assign an element or slice of the symbolic matrix to a numeric value, they are converted to symbolic constants on the way in.\u003c/p\u003e\\n\",\"name\":\"Spatialmath Python\",\"type\":\"code\",\"url\":\"https://github.com/petercorke/spatialmath-python\",\"image\":\"/_next/static/images/CartesianSnakes_LogoW-292d336acf7d3ffebbf1da8f9f6ccc9d.png\",\"image_fit\":\"contain\",\"src\":\"/content/robotics_toolbox/spatialmath-python.md\",\"id\":\"spatialmath-python\",\"image_position\":\"center\"},{\"content\":\"\u003ch1\u003eRobotics Toolbox for Python\u003c/h1\u003e\\n\u003cp\u003e\u003ca href=\\\"https://badge.fury.io/py/roboticstoolbox-python\\\"\u003e\u003cimg src=\\\"https://badge.fury.io/py/roboticstoolbox-python.svg\\\" alt=\\\"PyPI version\\\"\u003e\u003c/a\u003e\\n\u003cimg src=\\\"https://img.shields.io/pypi/pyversions/roboticstoolbox-python.svg\\\" alt=\\\"PyPI - Python Version\\\"\u003e\\n\u003ca href=\\\"https://opensource.org/licenses/MIT\\\"\u003e\u003cimg src=\\\"https://img.shields.io/badge/License-MIT-yellow.svg\\\" alt=\\\"License: MIT\\\"\u003e\u003c/a\u003e\\n\u003ca href=\\\"https://mybinder.org/v2/gh/petercorke/robotics-toolbox-python/master?filepath=notebooks\\\"\u003e\u003cimg src=\\\"https://mybinder.org/badge_logo.svg\\\" alt=\\\"Binder\\\"\u003e\u003c/a\u003e\\n\u003ca href=\\\"https://qcr.github.io\\\"\u003e\u003cimg src=https://github.com/qcr/qcr.github.io/raw/master/misc/badge.svg alt=\\\"QUT Centre for Robotics Open Source\\\"\u003e\u003c/a\u003e\u003c/p\u003e\\n\u003cp\u003e\u003ca href=https://github.com/petercorke/robotics-toolbox-python/actions?query=workflow%3Abuild\u003e\u003cimg src=https://github.com/petercorke/robotics-toolbox-python/workflows/build/badge.svg?branch=master alt=\\\"Build Status\\\"\u003e\u003c/a\u003e\\n\u003ca href=\\\"https://codecov.io/gh/petercorke/robotics-toolbox-python\\\"\u003e\u003cimg src=\\\"https://codecov.io/gh/petercorke/robotics-toolbox-python/branch/master/graph/badge.svg\\\" alt=\\\"Coverage\\\"\u003e\u003c/a\u003e\\n\u003ca href=\\\"https://lgtm.com/projects/g/petercorke/robotics-toolbox-python/context:python\\\"\u003e\u003cimg src=\\\"https://img.shields.io/lgtm/grade/python/g/petercorke/robotics-toolbox-python.svg?logo=lgtm\u0026amp;logoWidth=18\\\" alt=\\\"Language grade: Python\\\"\u003e\u003c/a\u003e\\n\u003ca href=\\\"https://pypistats.org/packages/roboticstoolbox-python\\\"\u003e\u003cimg src=\\\"https://img.shields.io/pypi/dw/roboticstoolbox-python\\\" alt=\\\"PyPI - Downloads\\\"\u003e\u003c/a\u003e\u003c/p\u003e\\n\u003ctable style=\\\"border:0px\\\"\u003e\\n\u003ctr style=\\\"border:0px\\\"\u003e\\n\u003ctd style=\\\"border:0px\\\"\u003e\\n\u003cimg src=https://github.com/petercorke/robotics-toolbox-python/raw/master/docs/figs/RobToolBox_RoundLogoB.png width=\\\"200\\\"\u003e\u003c/td\u003e\\n\u003ctd style=\\\"border:0px\\\"\u003e\\nA Python implementation of the \u003ca href=\\\"https://github.com/petercorke/robotics-toolbox-matlab\\\"\u003eRobotics Toolbox for MATLAB\u003csup\u003e\u0026reg;\u003c/sup\u003e\u003c/a\u003e\\n\u003cul\u003e\\n\u003cli\u003e\u003ca href=\\\"https://github.com/petercorke/robotics-toolbox-python\\\"\u003eGitHub repository \u003c/a\u003e\u003c/li\u003e\\n\u003cli\u003e\u003ca href=\\\"https://petercorke.github.io/robotics-toolbox-python\\\"\u003eDocumentation\u003c/a\u003e\u003c/li\u003e\\n\u003cli\u003e\u003ca href=\\\"https://github.com/petercorke/robotics-toolbox-python/wiki\\\"\u003eExamples and details\u003c/a\u003e\u003c/li\u003e\\n\u003c/ul\u003e\\n\u003c/td\u003e\\n\u003c/tr\u003e\\n\u003c/table\u003e\\n\u003ch2\u003eSynopsis\u003c/h2\u003e\\n\u003cp\u003eThis toolbox brings robotics-specific functionality to Python, and leverages\\nPython's advantages of portability, ubiquity and support, and the capability of\\nthe open-source ecosystem for linear algebra (numpy, scipy),  graphics\\n(matplotlib, three.js, WebGL), interactive development (jupyter, jupyterlab,\\nmybinder.org), and documentation (sphinx).\u003c/p\u003e\\n\u003cp\u003eThe Toolbox provides tools for representing the kinematics and dynamics of\\nserial-link manipulators  - you can easily create your own in Denavit-Hartenberg\\nform, import a URDF file, or use over 30 supplied models for well-known\\ncontemporary robots from Franka-Emika, Kinova, Universal Robotics, Rethink as\\nwell as classical robots such as the Puma 560 and the Stanford arm.\u003c/p\u003e\\n\u003cp\u003eThe toolbox will also support mobile robots with functions for robot motion models\\n(unicycle, bicycle), path planning algorithms (bug, distance transform, D*,\\nPRM), kinodynamic planning (lattice, RRT), localization (EKF, particle filter),\\nmap building (EKF) and simultaneous localization and mapping (EKF).\u003c/p\u003e\\n\u003cp\u003eThe Toolbox provides:\u003c/p\u003e\\n\u003cul\u003e\\n\u003cli\u003ecode that is mature and provides a point of comparison for other\\nimplementations of the same algorithms;\u003c/li\u003e\\n\u003cli\u003eroutines which are generally written in a straightforward manner which\\nallows for easy understanding, perhaps at the expense of computational\\nefficiency;\u003c/li\u003e\\n\u003cli\u003esource code which can be read for learning and teaching;\u003c/li\u003e\\n\u003cli\u003ebackward compatability with the Robotics Toolbox for MATLAB\u003c/li\u003e\\n\u003c/ul\u003e\\n\u003cp\u003eThe Toolbox leverages the \u003ca href=https://github.com/petercorke/spatialmath-python\u003eSpatial Maths Toolbox for Python\u003c/a\u003e to\\nprovide support for data types such as SO(n) and SE(n) matrices, quaternions, twists and spatial vectors.\u003c/p\u003e\\n\u003ch2\u003eCode Example\u003c/h2\u003e\\n\u003cp\u003eWe will load a model of the Franka-Emika Panda robot defined classically using\\nmodified (Craig's convention) Denavit-Hartenberg notation\u003c/p\u003e\\n\u003cpre class=\\\"language-python\\\"\u003e\u003ccode class=\\\"language-python\\\"\u003e\u003cspan class=\\\"token keyword\\\"\u003eimport\u003c/span\u003e roboticstoolbox \u003cspan class=\\\"token keyword\\\"\u003eas\u003c/span\u003e rtb\\nrobot \u003cspan class=\\\"token operator\\\"\u003e=\u003c/span\u003e rtb\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003emodels\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eDH\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003ePanda\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n\u003cspan class=\\\"token keyword\\\"\u003eprint\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003erobot\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n\\n\\t┏━━━━━━━━┳━━━━━━━━┳━━━━━┳━━━━━━━┳━━━━━━━━━┳━━━━━━━━┓\\n\\t┃ aⱼ₋₁   ┃  ⍺ⱼ₋₁  ┃ θⱼ  ┃  dⱼ   ┃   q⁻    ┃   q⁺   ┃\\n\\t┣━━━━━━━━╋━━━━━━━━╋━━━━━╋━━━━━━━╋━━━━━━━━━╋━━━━━━━━┫\\n\\t┃    \u003cspan class=\\\"token number\\\"\u003e0.0\u003c/span\u003e ┃   \u003cspan class=\\\"token number\\\"\u003e0.0\u003c/span\u003e° ┃  q1 ┃ \u003cspan class=\\\"token number\\\"\u003e0.333\u003c/span\u003e ┃ \u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e166.0\u003c/span\u003e° ┃ \u003cspan class=\\\"token number\\\"\u003e166.0\u003c/span\u003e° ┃\\n\\t┃    \u003cspan class=\\\"token number\\\"\u003e0.0\u003c/span\u003e ┃ \u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e90.0\u003c/span\u003e° ┃  q2 ┃   \u003cspan class=\\\"token number\\\"\u003e0.0\u003c/span\u003e ┃ \u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e101.0\u003c/span\u003e° ┃ \u003cspan class=\\\"token number\\\"\u003e101.0\u003c/span\u003e° ┃\\n\\t┃    \u003cspan class=\\\"token number\\\"\u003e0.0\u003c/span\u003e ┃  \u003cspan class=\\\"token number\\\"\u003e90.0\u003c/span\u003e° ┃  q3 ┃ \u003cspan class=\\\"token number\\\"\u003e0.316\u003c/span\u003e ┃ \u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e166.0\u003c/span\u003e° ┃ \u003cspan class=\\\"token number\\\"\u003e166.0\u003c/span\u003e° ┃\\n\\t┃ \u003cspan class=\\\"token number\\\"\u003e0.0825\u003c/span\u003e ┃  \u003cspan class=\\\"token number\\\"\u003e90.0\u003c/span\u003e° ┃  q4 ┃   \u003cspan class=\\\"token number\\\"\u003e0.0\u003c/span\u003e ┃ \u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e176.0\u003c/span\u003e° ┃  \u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e4.0\u003c/span\u003e° ┃\\n\\t┃\u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e0.0825\u003c/span\u003e ┃ \u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e90.0\u003c/span\u003e° ┃  q5 ┃ \u003cspan class=\\\"token number\\\"\u003e0.384\u003c/span\u003e ┃ \u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e166.0\u003c/span\u003e° ┃ \u003cspan class=\\\"token number\\\"\u003e166.0\u003c/span\u003e° ┃\\n\\t┃    \u003cspan class=\\\"token number\\\"\u003e0.0\u003c/span\u003e ┃  \u003cspan class=\\\"token number\\\"\u003e90.0\u003c/span\u003e° ┃  q6 ┃   \u003cspan class=\\\"token number\\\"\u003e0.0\u003c/span\u003e ┃   \u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e1.0\u003c/span\u003e° ┃ \u003cspan class=\\\"token number\\\"\u003e215.0\u003c/span\u003e° ┃\\n\\t┃  \u003cspan class=\\\"token number\\\"\u003e0.088\u003c/span\u003e ┃  \u003cspan class=\\\"token number\\\"\u003e90.0\u003c/span\u003e° ┃  q7 ┃ \u003cspan class=\\\"token number\\\"\u003e0.107\u003c/span\u003e ┃ \u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e166.0\u003c/span\u003e° ┃ \u003cspan class=\\\"token number\\\"\u003e166.0\u003c/span\u003e° ┃\\n\\t┗━━━━━━━━┻━━━━━━━━┻━━━━━┻━━━━━━━┻━━━━━━━━━┻━━━━━━━━┛\\n\\t\\n\\t┌─────┬───────────────────────────────────────┐\\n\\t│tool │ t \u003cspan class=\\\"token operator\\\"\u003e=\u003c/span\u003e \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e \u003cspan class=\\\"token number\\\"\u003e0.1\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e;\u003c/span\u003e rpy\u003cspan class=\\\"token operator\\\"\u003e/\u003c/span\u003exyz \u003cspan class=\\\"token operator\\\"\u003e=\u003c/span\u003e \u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e45\u003c/span\u003e°\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e°\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e° │\\n\\t└─────┴───────────────────────────────────────┘\\n\\t\\n\\t┌─────┬─────┬────────┬─────┬───────┬─────┬───────┬──────┐\\n\\t│name │ q0  │ q1     │ q2  │ q3    │ q4  │ q5    │ q6   │\\n\\t├─────┼─────┼────────┼─────┼───────┼─────┼───────┼──────┤\\n\\t│  qz │  \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e° │  \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e°    │  \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e° │  \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e°   │  \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e° │  \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e°   │  \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e°  │\\n\\t│  qr │  \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e° │ \u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e17.2\u003c/span\u003e° │  \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e° │ \u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e126\u003c/span\u003e° │  \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e° │  \u003cspan class=\\\"token number\\\"\u003e115\u003c/span\u003e° │  \u003cspan class=\\\"token number\\\"\u003e45\u003c/span\u003e° │\\n\\t└─────┴─────┴────────┴─────┴───────┴─────┴───────┴──────┘\\n\\nT \u003cspan class=\\\"token operator\\\"\u003e=\u003c/span\u003e robot\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003efkine\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003erobot\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eqz\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e  \u003cspan class=\\\"token comment\\\"\u003e# forward kinematics\u003c/span\u003e\\n\u003cspan class=\\\"token keyword\\\"\u003eprint\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003eT\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n\\n\\t   \u003cspan class=\\\"token number\\\"\u003e0.707107\u003c/span\u003e    \u003cspan class=\\\"token number\\\"\u003e0.707107\u003c/span\u003e    \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e           \u003cspan class=\\\"token number\\\"\u003e0.088\u003c/span\u003e        \\n\\t   \u003cspan class=\\\"token number\\\"\u003e0.707107\u003c/span\u003e   \u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e0.707107\u003c/span\u003e    \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e           \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e            \\n\\t   \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e           \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e          \u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e1\u003c/span\u003e           \u003cspan class=\\\"token number\\\"\u003e0.823\u003c/span\u003e        \\n\\t   \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e           \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e           \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e           \u003cspan class=\\\"token number\\\"\u003e1\u003c/span\u003e          \\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003e(Python prompts are not shown to make it easy to copy+paste the code, console output is indented)\u003c/p\u003e\\n\u003cp\u003eWe can solve inverse kinematics very easily.  We first choose an SE(3) pose\\ndefined in terms of position and orientation (end-effector z-axis down (A=-Z) and finger\\norientation parallel to y-axis (O=+Y)).\u003c/p\u003e\\n\u003cpre class=\\\"language-python\\\"\u003e\u003ccode class=\\\"language-python\\\"\u003e\u003cspan class=\\\"token keyword\\\"\u003efrom\u003c/span\u003e spatialmath \u003cspan class=\\\"token keyword\\\"\u003eimport\u003c/span\u003e SE3\\n\\nT \u003cspan class=\\\"token operator\\\"\u003e=\u003c/span\u003e SE3\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e0.8\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e \u003cspan class=\\\"token number\\\"\u003e0.2\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e \u003cspan class=\\\"token number\\\"\u003e0.1\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e \u003cspan class=\\\"token operator\\\"\u003e*\u003c/span\u003e SE3\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eOA\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e[\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e \u003cspan class=\\\"token number\\\"\u003e1\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e]\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e \u003cspan class=\\\"token punctuation\\\"\u003e[\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e \u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e1\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e]\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\nsol \u003cspan class=\\\"token operator\\\"\u003e=\u003c/span\u003e robot\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eikine_min\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003eT\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e         \u003cspan class=\\\"token comment\\\"\u003e# solve IK\u003c/span\u003e\\n\u003cspan class=\\\"token keyword\\\"\u003eprint\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003esol\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eq\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e                     \u003cspan class=\\\"token comment\\\"\u003e# display joint angles\u003c/span\u003e\\n\\n\\t\u003cspan class=\\\"token punctuation\\\"\u003e[\u003c/span\u003e\u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e0.01044\u003c/span\u003e    \u003cspan class=\\\"token number\\\"\u003e7.876\u003c/span\u003e    \u003cspan class=\\\"token number\\\"\u003e1.557\u003c/span\u003e    \u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e6.81\u003c/span\u003e    \u003cspan class=\\\"token number\\\"\u003e1.571\u003c/span\u003e    \u003cspan class=\\\"token number\\\"\u003e4.686\u003c/span\u003e   \u003cspan class=\\\"token number\\\"\u003e0.5169\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e]\u003c/span\u003e\\n\\n\u003cspan class=\\\"token keyword\\\"\u003eprint\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003erobot\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003efkine\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003esol\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eq\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e    \u003cspan class=\\\"token comment\\\"\u003e# FK shows that desired end-effector pose was achieved\u003c/span\u003e\\n\\n\\tOut\u003cspan class=\\\"token punctuation\\\"\u003e[\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e35\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e]\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e:\u003c/span\u003e \\n\\tSE3\u003cspan class=\\\"token punctuation\\\"\u003e:\u003c/span\u003e┏                                           ┓\\n\\t\\t┃\u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e1\u003c/span\u003e         \u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e4e\u003c/span\u003e\u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e08\u003c/span\u003e      \u003cspan class=\\\"token number\\\"\u003e0.000521\u003c/span\u003e   \u003cspan class=\\\"token number\\\"\u003e0.615\u003c/span\u003e    ┃\\n\\t\\t┃ \u003cspan class=\\\"token number\\\"\u003e2.79e-08\u003c/span\u003e   \u003cspan class=\\\"token number\\\"\u003e1\u003c/span\u003e          \u003cspan class=\\\"token number\\\"\u003e0.00013\u003c/span\u003e    \u003cspan class=\\\"token number\\\"\u003e0.154\u003c/span\u003e    ┃\\n\\t\\t┃\u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e0.000521\u003c/span\u003e   \u003cspan class=\\\"token number\\\"\u003e0.00013\u003c/span\u003e   \u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e1\u003c/span\u003e          \u003cspan class=\\\"token number\\\"\u003e0.105\u003c/span\u003e    ┃\\n\\t\\t┃ \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e          \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e          \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e          \u003cspan class=\\\"token number\\\"\u003e1\u003c/span\u003e        ┃\\n\\t\\t┗                                           ┛\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eNote that because this robot is redundant we don't have any control over the arm configuration apart from end-effector pose, ie. we can't control the elbow height.\u003c/p\u003e\\n\u003cp\u003eWe can animate a path from the upright \u003ccode class=\\\"language-none\\\"\u003eqz\u003c/code\u003e configuration to this pickup configuration\u003c/p\u003e\\n\u003cpre class=\\\"language-python\\\"\u003e\u003ccode class=\\\"language-python\\\"\u003eqt \u003cspan class=\\\"token operator\\\"\u003e=\u003c/span\u003e rtb\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003etrajectory\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003ejtraj\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003erobot\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eqz\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e q_pickup\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e \u003cspan class=\\\"token number\\\"\u003e50\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\nrobot\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eplot\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003eqt\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eq\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e movie\u003cspan class=\\\"token operator\\\"\u003e=\u003c/span\u003e\u003cspan class=\\\"token string\\\"\u003e'panda1.gif'\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003e\u003cvideo autoplay loop poster=\\\"/_next/static/gifs/826a58e84a13c9100ba2527f636dc267.jpg\\\"\u003e\u003csource src=\\\"/_next/static/gifs/826a58e84a13c9100ba2527f636dc267.webm\\\" type=\\\"video/webm\\\"/\u003e\u003c/video\u003e\u003c/p\u003e\\n\u003cp\u003ewhich uses the default matplotlib backend.  Grey arrows show the joint axes and the colored frame shows the end-effector pose.\u003c/p\u003e\\n\u003cp\u003eLet's now load a URDF model of the same robot. The kinematic representation is no longer\\nbased on Denavit-Hartenberg parameters, it is now a rigid-body tree.\u003c/p\u003e\\n\u003cpre class=\\\"language-python\\\"\u003e\u003ccode class=\\\"language-python\\\"\u003erobot \u003cspan class=\\\"token operator\\\"\u003e=\u003c/span\u003e rtb\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003emodels\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eURDF\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003ePanda\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e  \u003cspan class=\\\"token comment\\\"\u003e# load URDF version of the Panda\u003c/span\u003e\\n\u003cspan class=\\\"token keyword\\\"\u003eprint\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003erobot\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e    \u003cspan class=\\\"token comment\\\"\u003e# display the model\u003c/span\u003e\\n\\n\\t┌───┬──────────────┬─────────────┬──────────────┬─────────────────────────────────────────────┐\\n\\t│\u003cspan class=\\\"token builtin\\\"\u003eid\u003c/span\u003e │     link     │   parent    │    joint     │                     ETS                     │\\n\\t├───┼──────────────┼─────────────┼──────────────┼─────────────────────────────────────────────┤\\n\\t│ \u003cspan class=\\\"token number\\\"\u003e0\u003c/span\u003e │  panda_link0 │           \u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e │              │                                             │\\n\\t│ \u003cspan class=\\\"token number\\\"\u003e1\u003c/span\u003e │  panda_link1 │ panda_link0 │ panda_joint1 │                          tz\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e0.333\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e \u003cspan class=\\\"token operator\\\"\u003e*\u003c/span\u003e Rz\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003eq0\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e │\\n\\t│ \u003cspan class=\\\"token number\\\"\u003e2\u003c/span\u003e │  panda_link2 │ panda_link1 │ panda_joint2 │                           Rx\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e90\u003c/span\u003e°\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e \u003cspan class=\\\"token operator\\\"\u003e*\u003c/span\u003e Rz\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003eq1\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e │\\n\\t│ \u003cspan class=\\\"token number\\\"\u003e3\u003c/span\u003e │  panda_link3 │ panda_link2 │ panda_joint3 │               ty\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e0.316\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e \u003cspan class=\\\"token operator\\\"\u003e*\u003c/span\u003e Rx\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e90\u003c/span\u003e°\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e \u003cspan class=\\\"token operator\\\"\u003e*\u003c/span\u003e Rz\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003eq2\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e │\\n\\t│ \u003cspan class=\\\"token number\\\"\u003e4\u003c/span\u003e │  panda_link4 │ panda_link3 │ panda_joint4 │               tx\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e0.0825\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e \u003cspan class=\\\"token operator\\\"\u003e*\u003c/span\u003e Rx\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e90\u003c/span\u003e°\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e \u003cspan class=\\\"token operator\\\"\u003e*\u003c/span\u003e Rz\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003eq3\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e │\\n\\t│ \u003cspan class=\\\"token number\\\"\u003e5\u003c/span\u003e │  panda_link5 │ panda_link4 │ panda_joint5 │ tx\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e0.0825\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e \u003cspan class=\\\"token operator\\\"\u003e*\u003c/span\u003e ty\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e0.384\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e \u003cspan class=\\\"token operator\\\"\u003e*\u003c/span\u003e Rx\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token operator\\\"\u003e-\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e90\u003c/span\u003e°\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e \u003cspan class=\\\"token operator\\\"\u003e*\u003c/span\u003e Rz\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003eq4\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e │\\n\\t│ \u003cspan class=\\\"token number\\\"\u003e6\u003c/span\u003e │  panda_link6 │ panda_link5 │ panda_joint6 │                            Rx\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e90\u003c/span\u003e°\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e \u003cspan class=\\\"token operator\\\"\u003e*\u003c/span\u003e Rz\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003eq5\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e │\\n\\t│ \u003cspan class=\\\"token number\\\"\u003e7\u003c/span\u003e │  panda_link7 │ panda_link6 │ panda_joint7 │                tx\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e0.088\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e \u003cspan class=\\\"token operator\\\"\u003e*\u003c/span\u003e Rx\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e90\u003c/span\u003e°\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e \u003cspan class=\\\"token operator\\\"\u003e*\u003c/span\u003e Rz\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003eq6\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e │\\n\\t│ \u003cspan class=\\\"token number\\\"\u003e8\u003c/span\u003e │ @panda_link8 │ panda_link7 │ panda_joint8 │                                   tz\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e0.107\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e │\\n\\t└───┴──────────────┴─────────────┴──────────────┴─────────────────────────────────────────────┘\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eThe symbol \u003ccode class=\\\"language-none\\\"\u003e@\u003c/code\u003e indicates the link as an end-effector, a leaf node in the rigid-body\\ntree.\u003c/p\u003e\\n\u003cp\u003eWe can instantiate our robot inside a browser-based 3d-simulation environment.\u003c/p\u003e\\n\u003cpre class=\\\"language-python\\\"\u003e\u003ccode class=\\\"language-python\\\"\u003eenv \u003cspan class=\\\"token operator\\\"\u003e=\u003c/span\u003e rtb\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003ebackends\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eSwift\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e  \u003cspan class=\\\"token comment\\\"\u003e# instantiate 3D browser-based visualizer\u003c/span\u003e\\nenv\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003elaunch\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e                \u003cspan class=\\\"token comment\\\"\u003e# activate it\u003c/span\u003e\\nenv\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eadd\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003erobot\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e              \u003cspan class=\\\"token comment\\\"\u003e# add robot to the 3D scene\u003c/span\u003e\\n\u003cspan class=\\\"token keyword\\\"\u003efor\u003c/span\u003e qk \u003cspan class=\\\"token keyword\\\"\u003ein\u003c/span\u003e qt\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eq\u003cspan class=\\\"token punctuation\\\"\u003e:\u003c/span\u003e             \u003cspan class=\\\"token comment\\\"\u003e# for each joint configuration on trajectory\u003c/span\u003e\\n      robot\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eq \u003cspan class=\\\"token operator\\\"\u003e=\u003c/span\u003e qk          \u003cspan class=\\\"token comment\\\"\u003e# update the robot state\u003c/span\u003e\\n      env\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003estep\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e            \u003cspan class=\\\"token comment\\\"\u003e# update visualization\u003c/span\u003e\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp align=\\\"center\\\"\u003e\\n \u003cimg src=\\\"/_next/static/gifs/d064326b92f5b2c4e0c25c057731e6a7.gif\\\"\u003e\\n\u003c/p\u003e\\n\u003ch1\u003eGetting going\u003c/h1\u003e\\n\u003ch2\u003eInstalling\u003c/h2\u003e\\n\u003cp\u003eYou will need Python \u0026gt;= 3.6\u003c/p\u003e\\n\u003ch3\u003eUsing pip\u003c/h3\u003e\\n\u003cp\u003eInstall a snapshot from PyPI\u003c/p\u003e\\n\u003cpre class=\\\"language-shell\\\"\u003e\u003ccode class=\\\"language-shell\\\"\u003epip3 \u003cspan class=\\\"token function\\\"\u003einstall\u003c/span\u003e roboticstoolbox-python\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eAvailable options are:\u003c/p\u003e\\n\u003cul\u003e\\n\u003cli\u003e\u003ccode class=\\\"language-none\\\"\u003evpython\u003c/code\u003e install \u003ca href=\\\"https://vpython.org\\\"\u003eVPython\u003c/a\u003e backend\u003c/li\u003e\\n\u003cli\u003e\u003ccode class=\\\"language-none\\\"\u003ecollision\u003c/code\u003e install collision checking with \u003ca href=\\\"https://pybullet.org\\\"\u003epybullet\u003c/a\u003e\u003c/li\u003e\\n\u003c/ul\u003e\\n\u003cp\u003ePut the options in a comma separated list like\u003c/p\u003e\\n\u003cpre class=\\\"language-shell\\\"\u003e\u003ccode class=\\\"language-shell\\\"\u003epip3 \u003cspan class=\\\"token function\\\"\u003einstall\u003c/span\u003e roboticstoolbox-python\u003cspan class=\\\"token punctuation\\\"\u003e[\u003c/span\u003eoptionlist\u003cspan class=\\\"token punctuation\\\"\u003e]\u003c/span\u003e\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003e\u003ca href=https://github.com/jhavl/swift\u003eSwift\u003c/a\u003e, a web-based visualizer, is\\ninstalled as part of Robotics Toolbox.\u003c/p\u003e\\n\u003ch3\u003eFrom GitHub\u003c/h3\u003e\\n\u003cp\u003eTo install the bleeding-edge version from GitHub\u003c/p\u003e\\n\u003cpre class=\\\"language-shell\\\"\u003e\u003ccode class=\\\"language-shell\\\"\u003e\u003cspan class=\\\"token function\\\"\u003egit\u003c/span\u003e clone https://github.com/petercorke/robotics-toolbox-python.git\\n\u003cspan class=\\\"token builtin class-name\\\"\u003ecd\u003c/span\u003e robotics-toolbox-python\\npip3 \u003cspan class=\\\"token function\\\"\u003einstall\u003c/span\u003e -e \u003cspan class=\\\"token builtin class-name\\\"\u003e.\u003c/span\u003e\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003ch2\u003eRun some examples\u003c/h2\u003e\\n\u003cp\u003eThe \u003ca href=https://github.com/petercorke/robotics-toolbox-python/tree/master/notebooks\u003e\u003ccode class=\\\"language-none\\\"\u003enotebooks\u003c/code\u003e\u003c/a\u003e folder contains some tutorial Jupyter notebooks which you can browse on GitHub.\u003c/p\u003e\\n\u003cp\u003eOr you can run them, and experiment with them, at \u003ca href=\\\"https://mybinder.org/v2/gh/petercorke/robotics-toolbox-python/master?filepath=notebooks\\\"\u003emybinder.org\u003c/a\u003e.\u003c/p\u003e\\n\u003ch2\u003eToolbox Research Applications\u003c/h2\u003e\\n\u003cp\u003eThe toolbox is incredibly useful for developing and prototyping algorithms for research, thanks to the exhaustive set of well documented and mature robotic functions exposed through clean and painless APIs. Additionally, the ease at which a user can visualize their algorithm supports a rapid prototyping paradigm.\u003c/p\u003e\\n\u003ch3\u003ePublication List\u003c/h3\u003e\\n\u003cp\u003eJ. Haviland and P. Corke, \u0026quot;\u003cstrong\u003eNEO: A Novel Expeditious Optimisation Algorithm for Reactive Motion Control of Manipulators\u003c/strong\u003e,\u0026quot; in \u003cem\u003eIEEE Robotics and Automation Letters\u003c/em\u003e, doi: 10.1109/LRA.2021.3056060. In the video, the robot is controlled using the Robotics toolbox for Python and features a recording from the \u003ca href=https://github.com/jhavl/swift\u003eSwift\u003c/a\u003e Simulator.\u003c/p\u003e\\n\u003cp\u003e[\u003ca href=\\\"https://arxiv.org/abs/2010.08686\\\"\u003eArxiv Paper\u003c/a\u003e] [\u003ca href=\\\"https://ieeexplore.ieee.org/document/9343718\\\"\u003eIEEE Xplore\u003c/a\u003e] [\u003ca href=\\\"https://jhavl.github.io/neo/\\\"\u003eProject Website\u003c/a\u003e] [\u003ca href=\\\"https://youtu.be/jSLPJBr8QTY\\\"\u003eVideo\u003c/a\u003e] [\u003ca href=https://github.com/petercorke/robotics-toolbox-python/blob/master/examples/neo.py\u003eCode Example\u003c/a\u003e]\u003c/p\u003e\\n\u003cp\u003e\\n  \u003ca href=\\\"https://youtu.be/jSLPJBr8QTY\\\"\u003e\\n    \u003cimg src=https://github.com/petercorke/robotics-toolbox-python/raw/master/docs/figs/neo_youtube.png width=\\\"560\\\"\u003e\\n  \u003c/a\u003e\\n\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eA Purely-Reactive Manipulability-Maximising Motion Controller\u003c/strong\u003e, J. Haviland and P. Corke. In the video, the robot is controlled using the Robotics toolbox for Python.\u003c/p\u003e\\n\u003cp\u003e[\u003ca href=\\\"https://arxiv.org/abs/2002.11901\\\"\u003ePaper\u003c/a\u003e] [\u003ca href=\\\"https://jhavl.github.io/mmc/\\\"\u003eProject Website\u003c/a\u003e] [\u003ca href=\\\"https://youtu.be/Vu_rcPlaADI\\\"\u003eVideo\u003c/a\u003e] [\u003ca href=https://github.com/petercorke/robotics-toolbox-python/blob/master/examples/mmc.py\u003eCode Example\u003c/a\u003e]\u003c/p\u003e\\n\u003cp\u003e\\n  \u003ca href=\\\"https://youtu.be/Vu_rcPlaADI\\\"\u003e\\n    \u003cimg src=https://github.com/petercorke/robotics-toolbox-python/raw/master/docs/figs/mmc_youtube.png width=\\\"560\\\"\u003e\\n  \u003c/a\u003e\\n\u003c/p\u003e\\n\u003cbr\u003e\\n\",\"name\":\"Robotics Toolbox Python\",\"type\":\"code\",\"url\":\"https://github.com/petercorke/robotics-toolbox-python\",\"image\":\"/_next/static/images/RobToolBox_RoundLogoB-9563d226662903b6e404b809e72e3235.png\",\"image_fit\":\"contain\",\"src\":\"/content/robotics_toolbox/robotics-toolbox-python.md\",\"id\":\"robotics-toolbox-python\",\"image_position\":\"center\"},{\"content\":\"\u003ch1\u003eSwift\u003c/h1\u003e\\n\u003cp\u003e\u003ca href=\\\"https://badge.fury.io/py/swift-sim\\\"\u003e\u003cimg src=\\\"https://badge.fury.io/py/swift-sim.svg\\\" alt=\\\"PyPI version\\\"\u003e\u003c/a\u003e\\n\u003ca href=\\\"https://img.shields.io/pypi/pyversions/swift-sim\\\"\u003e\u003cimg src=\\\"https://img.shields.io/pypi/pyversions/swift-sim\\\" alt=\\\"PyPI - Python Version\\\"\u003e\u003c/a\u003e\\n\u003ca href=\\\"https://opensource.org/licenses/MIT\\\"\u003e\u003cimg src=\\\"https://img.shields.io/badge/License-MIT-yellow.svg\\\" alt=\\\"License: MIT\\\"\u003e\u003c/a\u003e\\n\u003ca href=\\\"https://qcr.github.io\\\"\u003e\u003cimg src=https://github.com/qcr/qcr.github.io/raw/master/misc/badge.svg alt=\\\"QUT Centre for Robotics Open Source\\\"\u003e\u003c/a\u003e\u003c/p\u003e\\n\u003cp\u003eSwift is a light-weight browser-based simulator built on top of the \u003ca href=https://github.com/petercorke/robotics-toolbox-python\u003eRobotics Toolbox for Python\u003c/a\u003e. This simulator provides robotics-specific functionality for rapid prototyping of algorithms, research, and education. Built using Python and Javascript, Swift is cross-platform (Linux, MacOS, and Windows) while also leveraging the ubiquity and support of these languages.\u003c/p\u003e\\n\u003cp\u003eThrough the \u003ca href=https://github.com/petercorke/robotics-toolbox-python\u003eRobotics Toolbox for Python\u003c/a\u003e, Swift can visualise over 30 supplied robot models: well-known contemporary robots from Franka-Emika, Kinova, Universal Robotics, Rethink as well as classical robots such as the Puma 560 and the Stanford arm. Swift is under development and will support mobile robots in the future.\u003c/p\u003e\\n\u003cp\u003eSwift provides:\u003c/p\u003e\\n\u003cul\u003e\\n\u003cli\u003evisualisation of mesh objects (Collada and STL files) and primitive shapes;\u003c/li\u003e\\n\u003cli\u003erobot visualisation and simulation;\u003c/li\u003e\\n\u003cli\u003erecording and saving a video of the simulation;\u003c/li\u003e\\n\u003cli\u003esource code which can be read for learning and teaching;\u003c/li\u003e\\n\u003c/ul\u003e\\n\u003ch2\u003eInstalling\u003c/h2\u003e\\n\u003ch3\u003eUsing pip\u003c/h3\u003e\\n\u003cp\u003eSwift is designed to be controlled through the \u003ca href=https://github.com/petercorke/robotics-toolbox-python\u003eRobotics Toolbox for Python\u003c/a\u003e. By installing the toolbox through PyPI, swift is installed as a dependency\u003c/p\u003e\\n\u003cpre class=\\\"language-shell\\\"\u003e\u003ccode class=\\\"language-shell\\\"\u003epip3 \u003cspan class=\\\"token function\\\"\u003einstall\u003c/span\u003e roboticstoolbox-python\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eOtherwise, Swift can be install by\u003c/p\u003e\\n\u003cpre class=\\\"language-shell\\\"\u003e\u003ccode class=\\\"language-shell\\\"\u003epip3 \u003cspan class=\\\"token function\\\"\u003einstall\u003c/span\u003e swift-sim\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003ch3\u003eFrom GitHub\u003c/h3\u003e\\n\u003cp\u003eTo install the latest version from GitHub\u003c/p\u003e\\n\u003cpre class=\\\"language-shell\\\"\u003e\u003ccode class=\\\"language-shell\\\"\u003e\u003cspan class=\\\"token function\\\"\u003egit\u003c/span\u003e clone https://github.com/jhavl/swift.git\\n\u003cspan class=\\\"token builtin class-name\\\"\u003ecd\u003c/span\u003e swift\\npip3 \u003cspan class=\\\"token function\\\"\u003einstall\u003c/span\u003e -e \u003cspan class=\\\"token builtin class-name\\\"\u003e.\u003c/span\u003e\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003ch2\u003eCode Examples\u003c/h2\u003e\\n\u003ch3\u003eRobot Plot\u003c/h3\u003e\\n\u003cp\u003eWe will load a model of the Franka-Emika Panda robot and plot it. We set the joint angles of the robot into the ready joint configuration qr.\u003c/p\u003e\\n\u003cpre class=\\\"language-python\\\"\u003e\u003ccode class=\\\"language-python\\\"\u003e\u003cspan class=\\\"token keyword\\\"\u003eimport\u003c/span\u003e roboticstoolbox \u003cspan class=\\\"token keyword\\\"\u003eas\u003c/span\u003e rp\\n\\npanda \u003cspan class=\\\"token operator\\\"\u003e=\u003c/span\u003e rp\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003emodels\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003ePanda\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\npanda\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eplot\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003eq\u003cspan class=\\\"token operator\\\"\u003e=\u003c/span\u003epanda\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eqr\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp align=\\\"center\\\"\u003e\\n \u003cimg src=https://github.com/jhavl/swift/blob/master/.github/figures/panda.png\u003e\\n\u003c/p\u003e\\n\u003ch3\u003eResolved-Rate Motion Control\u003c/h3\u003e\\n\u003cp\u003eWe will load a model of the Franka-Emika Panda robot and make it travel towards a goal pose defined by the variable Tep.\u003c/p\u003e\\n\u003cpre class=\\\"language-python\\\"\u003e\u003ccode class=\\\"language-python\\\"\u003e\u003cspan class=\\\"token keyword\\\"\u003eimport\u003c/span\u003e roboticstoolbox \u003cspan class=\\\"token keyword\\\"\u003eas\u003c/span\u003e rtb\\n\u003cspan class=\\\"token keyword\\\"\u003eimport\u003c/span\u003e spatialmath \u003cspan class=\\\"token keyword\\\"\u003eas\u003c/span\u003e sm\\n\u003cspan class=\\\"token keyword\\\"\u003eimport\u003c/span\u003e numpy \u003cspan class=\\\"token keyword\\\"\u003eas\u003c/span\u003e np\\n\\n\u003cspan class=\\\"token comment\\\"\u003e# Make and instance of the Swift simulator and open it\u003c/span\u003e\\nenv \u003cspan class=\\\"token operator\\\"\u003e=\u003c/span\u003e rtb\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003ebackends\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eSwift\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\nenv\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003elaunch\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n\\n\u003cspan class=\\\"token comment\\\"\u003e# Make a panda model and set its joint angles to the ready joint configuration\u003c/span\u003e\\npanda \u003cspan class=\\\"token operator\\\"\u003e=\u003c/span\u003e rtb\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003emodels\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003ePanda\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\npanda\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eq \u003cspan class=\\\"token operator\\\"\u003e=\u003c/span\u003e panda\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eqr\\n\\n\u003cspan class=\\\"token comment\\\"\u003e# Set a desired and effector pose an an offset from the current end-effector pose\u003c/span\u003e\\nTep \u003cspan class=\\\"token operator\\\"\u003e=\u003c/span\u003e panda\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003efkine\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003epanda\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eq\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e \u003cspan class=\\\"token operator\\\"\u003e*\u003c/span\u003e sm\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eSE3\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eTx\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e0.2\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e \u003cspan class=\\\"token operator\\\"\u003e*\u003c/span\u003e sm\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eSE3\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eTy\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e0.2\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e \u003cspan class=\\\"token operator\\\"\u003e*\u003c/span\u003e sm\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eSE3\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eTz\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e0.45\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n\\n\u003cspan class=\\\"token comment\\\"\u003e# Add the robot to the simulator\u003c/span\u003e\\nenv\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eadd\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003epanda\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n\\n\u003cspan class=\\\"token comment\\\"\u003e# Simulate the robot while it has not arrived at the goal\u003c/span\u003e\\narrived \u003cspan class=\\\"token operator\\\"\u003e=\u003c/span\u003e \u003cspan class=\\\"token boolean\\\"\u003eFalse\u003c/span\u003e\\n\u003cspan class=\\\"token keyword\\\"\u003ewhile\u003c/span\u003e \u003cspan class=\\\"token keyword\\\"\u003enot\u003c/span\u003e arrived\u003cspan class=\\\"token punctuation\\\"\u003e:\u003c/span\u003e\\n\\n    \u003cspan class=\\\"token comment\\\"\u003e# Work out the required end-effector velocity to go towards the goal\u003c/span\u003e\\n    v\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e arrived \u003cspan class=\\\"token operator\\\"\u003e=\u003c/span\u003e rtb\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003ep_servo\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003epanda\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003efkine\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003epanda\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eq\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e Tep\u003cspan class=\\\"token punctuation\\\"\u003e,\u003c/span\u003e \u003cspan class=\\\"token number\\\"\u003e1\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n    \\n    \u003cspan class=\\\"token comment\\\"\u003e# Set the Panda's joint velocities\u003c/span\u003e\\n    panda\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eqd \u003cspan class=\\\"token operator\\\"\u003e=\u003c/span\u003e np\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003elinalg\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003epinv\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003epanda\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003ejacobe\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003epanda\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003eq\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e @ v\\n    \\n    \u003cspan class=\\\"token comment\\\"\u003e# Step the simulator by 50 milliseconds\u003c/span\u003e\\n    env\u003cspan class=\\\"token punctuation\\\"\u003e.\u003c/span\u003estep\u003cspan class=\\\"token punctuation\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"token number\\\"\u003e0.05\u003c/span\u003e\u003cspan class=\\\"token punctuation\\\"\u003e)\u003c/span\u003e\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp align=\\\"center\\\"\u003e\\n \u003cimg src=\\\"/_next/static/gifs/0c7102b6a6bab096effb4fed9f4ba2e5.gif\\\"\u003e\\n\u003c/p\u003e\\n\",\"name\":\"Swift\",\"type\":\"code\",\"url\":\"https://github.com/jhavl/swift\",\"image\":\"/_next/static/images/panda-08fefd194b35f7baa2af3c22759caa53.png\",\"src\":\"/content/robotics_toolbox/swift.md\",\"id\":\"swift\",\"image_position\":\"center\"}],\"feature\":2,\"src\":\"/content/robotics_toolbox/collection.md\",\"image_position\":\"center\"}]"},"__N_SSG":true},"page":"/[list]","query":{"list":"collection"},"buildId":"1nuS-y2A2y9fnoeaTjLIs","nextExport":false,"isFallback":false,"gsp":true}</script><script nomodule="" src="/_next/static/chunks/polyfills-ff94e68042added27a93.js"></script><script src="/_next/static/chunks/main-c439d75cfca1ce6a0f7f.js" async=""></script><script src="/_next/static/chunks/webpack-50bee04d1dc61f8adf5b.js" async=""></script><script src="/_next/static/chunks/framework.a6402fb70cc88f6f61b0.js" async=""></script><script src="/_next/static/chunks/commons.455c36b53add9c9c2736.js" async=""></script><script src="/_next/static/chunks/pages/_app-d07085bfa8b88c39a473.js" async=""></script><script src="/_next/static/chunks/3d04e185781834a6bdd2cdc78a14cbdede4fee55.e5e850c413858c1cae6e.js" async=""></script><script src="/_next/static/chunks/pages/%5Blist%5D-3190a030279983f5e879.js" async=""></script><script src="/_next/static/1nuS-y2A2y9fnoeaTjLIs/_buildManifest.js" async=""></script><script src="/_next/static/1nuS-y2A2y9fnoeaTjLIs/_ssgManifest.js" async=""></script></body></html>