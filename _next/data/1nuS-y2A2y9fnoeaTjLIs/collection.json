{"pageProps":{"listData":"[{\"content\":\"<p>The BenchBot software stack is a collection of software packages that allow end users to control robots in real or simulated environments with a simple python API. It leverages the simple &quot;observe, act, repeat&quot; approach to robot problems prevalent in reinforcement learning communities (OpenAI Gym users will find the BenchBot API interface very similar).</p>\\n\",\"name\":\"BenchBot\",\"type\":\"collection\",\"url\":\"http://benchbot.org\",\"id\":\"benchbot\",\"code\":[{\"content\":\"<p align=center><strong>~ Our <a href=\\\"https://evalai.cloudcv.org/web/challenges/challenge-page/807/overview\\\">Robotic Vision Scene Understanding (RVSU) Challenge is live on EvalAI</a> ~<br>(prizes include $2,500USD provided by <a href=\\\"https://www.roboticvision.org/\\\">ACRV</a> & GPUs provided by sponsors <a href=\\\"https://www.nvidia.com/en-us/research/robotics/\\\">NVIDIA</a>)</strong></p>\\n<p align=center><strong>~ Our <a href=\\\"https://github.com/qcr/benchbot/wiki/Tutorial:-Performing-Semantic-SLAM-with-Votenet\\\">BenchBot tutorial</a> is the best place to get started developing with BenchBot ~</strong></p>\\n<h1>BenchBot Software Stack</h1>\\n<p><video autoplay loop poster=\\\"/_next/static/gifs/0f460afe63fb093a8b44efcd5c652cf8.jpg\\\"><source src=\\\"/_next/static/gifs/0f460afe63fb093a8b44efcd5c652cf8.webm\\\" type=\\\"video/webm\\\"/></video></p>\\n<p>The BenchBot software stack is a collection of software packages that allow end users to control robots in real or simulated environments with a simple python API. It leverages the simple &quot;observe, act, repeat&quot; approach to robot problems prevalent in reinforcement learning communities (<a href=\\\"https://gym.openai.com/\\\">OpenAI Gym</a> users will find the BenchBot API interface very similar).</p>\\n<p>BenchBot was created as a tool to assist in the research challenges faced by the semantic scene understanding community; challenges including understanding a scene in simulation, transferring algorithms to real world systems, and meaningfully evaluating algorithm performance. We've since realised, these challenges don't just exist for semantic scene understanding, they're prevalent in a wide range of robotic problems.</p>\\n<p>This led us to create version 2 of BenchBot with a focus on allowing users to define their own functionality for BenchBot through <a href=https://github.com/qcr/benchbot_addons>add-ons</a>. Want to integrate your own environments? Plug-in new robot platforms? Define new tasks? Share examples with others? Add evaluation measures? This all now possible with add-ons, and you don't have to do anything more than add some YAML and Python files defining your new content!</p>\\n<p>The &quot;bench&quot; in &quot;BenchBot&quot; refers to benchmarking, with our goal to provide a system that greatly simplifies the benchmarking of novel algorithms in both realistic 3D simulation and on real robot platforms. If there is something else you would like to use BenchBot for (like integrating different simulators), please let us know. We're very interested in BenchBot being the glue between your novel robotics research and whatever your robot platform may be.</p>\\n<p>This repository contains the software stack needed to develop solutions for BenchBot tasks on your local machine. It installs and configures a significant amount of software for you, wraps software in stable Docker images (~50GB), and provides simple interaction with the stack through 4 basic scripts: <code class=\\\"language-none\\\">benchbot_install</code>, <code class=\\\"language-none\\\">benchbot_run</code>, <code class=\\\"language-none\\\">benchbot_submit</code>, and <code class=\\\"language-none\\\">benchbot_eval</code>.</p>\\n<h2>System recommendations and requirements</h2>\\n<p>The BenchBot software stack is designed to run seamlessly on a wide number of system configurations (currently limited to Ubuntu 18.04+). System hardware requirements are relatively high due to the software run for 3D simulation (Unreal Engine, Nvidia Isaac, Vulkan, etc.):</p>\\n<ul>\\n<li>Nvidia Graphics card (GeForce GTX 1080 minimum, Titan XP+ / GeForce RTX 2070+ recommended)</li>\\n<li>CPU with multiple cores (Intel i7-6800K minimum)</li>\\n<li>32GB+ RAM</li>\\n<li>64GB+ spare storage (an SSD storage device is <strong>strongly</strong> recommended)</li>\\n</ul>\\n<p>Having a system that meets the above hardware requirements is all that is required to begin installing the BenchBot software stack. The install script analyses your system configuration and offers to install any missing software components interactively. The list of 3rd party software components involved includes:</p>\\n<ul>\\n<li>Nvidia Driver (4.18+ required, 4.50+ recommended)</li>\\n<li>CUDA with GPU support (10.0+ required, 10.1+ recommended)</li>\\n<li>Docker Engine - Community Edition (19.03+ required, 19.03.2+ recommended)</li>\\n<li>Nvidia Container Toolkit (1.0+ required, 1.0.5+ recommended)</li>\\n<li>ISAAC 2019.2 SDK (requires an Nvidia developer login)</li>\\n</ul>\\n<h2>Managing your installation</h2>\\n<p>Installation is simple:</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">u@pc:~$ git clone https://github.com/qcr/benchbot &amp;&amp; cd benchbot\\nu@pc:~$ ./install\\n</code></pre>\\n<p>Any missing software components, or configuration issues with your system, should be detected by the install script and resolved interactively. The installation asks if you want to add BenchBot helper scripts to your <code class=\\\"language-none\\\">PATH</code>. Choosing yes will make the following commands available from any directory: <code class=\\\"language-none\\\">benchbot_install</code> (same as <code class=\\\"language-none\\\">./install</code> above), <code class=\\\"language-none\\\">benchbot_run</code>, <code class=\\\"language-none\\\">benchbot_submit</code>, <code class=\\\"language-none\\\">benchbot_eval</code>, and <code class=\\\"language-none\\\">benchbot_batch</code>.</p>\\n<p>BenchBot installs a default set of add-ons (currently <code class=\\\"language-none\\\">'benchbot-addons/ssu'</code>), but this can be changed based on how you want to use BenchBot. For example, the following will also install the <code class=\\\"language-none\\\">'benchbot-addons/sqa'</code> add-ons:</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">u@pc:~$ benchbot_install --addons benchbot-addons/ssu,benchbot-addons/sqa\\n</code></pre>\\n<p>See the <a href=https://github.com/qcr/benchbot_addons>BenchBot Add-ons Manager's documentation</a> for more information on using add-ons.</p>\\n<p>The BenchBot software stack will frequently check for updates and can update itself automatically. To update simply run the install script again (add the <code class=\\\"language-none\\\">--force-clean</code> flag if you would like to install from scratch):</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">u@pc:~$ benchbot_install\\n</code></pre>\\n<p>If you decide to uninstall the BenchBot software stack, run:</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">u@pc:~$ benchbot_install --uninstall\\n</code></pre>\\n<p>There are a number of other options to customise your BenchBot installation, which are all described by running:</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">u@pc:~$ benchbot_install --help\\n</code></pre>\\n<h2>Getting started</h2>\\n<p>Getting a solution up and running with BenchBot is as simple as 1,2,3. Here's how to use BenchBot with content from the <a href=https://github.com/benchbot-addons/ssu>semantic scene understanding add-on</a>:</p>\\n<ol>\\n<li>\\n<p>Run a simulator with the BenchBot software stack by selecting an available robot, environment, and task definition:</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">u@pc:~$ benchbot_run --robot carter --env miniroom:1 --task semantic_slam:active:ground_truth\\n</code></pre>\\n<p>A number of useful flags exist to help you explore what content is available in your installation (see <code class=\\\"language-none\\\">--help</code> for full details). For example, you can list what tasks are available via <code class=\\\"language-none\\\">--list-tasks</code> and view the task specification via <code class=\\\"language-none\\\">--show-task TASK_NAME</code>.</p>\\n</li>\\n<li>\\n<p>Create a solution to a BenchBot task, and run it against the software stack. To run a solution you must select a mode. For example, if you've created a solution in <code class=\\\"language-none\\\">my_solution.py</code> that you would like to run natively:</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">u@pc:~$ benchbot_submit --native python my_solution.py\\n</code></pre>\\n<p>See <code class=\\\"language-none\\\">--help</code> for other options. You also have access to all of the examples available in your installation. For instance, you can run the <code class=\\\"language-none\\\">hello_active</code> example in containerised mode via:</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">u@pc:~$ benchbot_submit --containerised --example hello_active\\n</code></pre>\\n<p>See <code class=\\\"language-none\\\">--list-examples</code> and <code class=\\\"language-none\\\">--show-example EXAMPLE_NAME</code> for full details on what's available out of the box.</p>\\n</li>\\n<li>\\n<p>Evaluate the performance of your system using a supported evaluation method (see <code class=\\\"language-none\\\">--list-methods</code>). To use the <code class=\\\"language-none\\\">omq</code> evaluation method on <code class=\\\"language-none\\\">my_results.json</code>:</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">u@pc:~$ benchbot_eval --method omq my_results.json\\n</code></pre>\\n<p>You can also simply run evaluation automatically after your submission completes:</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">u@pc:~$ benchbot_submit --evaluate-results omq --native --example hello_eval_semantic_slam\\n</code></pre>\\n</li>\\n</ol>\\n<p>The <a href=https://github.com/qcr/benchbot/wiki/Tutorial:-Performing-Semantic-SLAM-with-Votenet>BenchBot Tutorial</a> is a great place to start working with BenchBot; the tutorial takes you from a blank system to a working Semantic SLAM solution, with many educational steps along the way. Also remember the examples in your installation (<a href=https://github.com/benchbot-addons/examples_base><code class=\\\"language-none\\\">benchbot-addons/examples_base</code></a> is a good starting point) which show how to get up and running with the BenchBot software stack.</p>\\n<h2>Power tools for autonomous algorithm evaluation</h2>\\n<p>Once you are confident your algorithm is a solution to the chosen task, the BenchBot software stack's power tools allow you to comprehensively explore your algorithm's performance. You can autonomously run your algorithm over multiple environments, and evaluate it holistically to produce a single summary statistic of your algorithm's performance. Here are some examples again with content from the <a href=https://github.com/benchbot-addons/ssu>semantic scene understanding add-on</a>:</p>\\n<ul>\\n<li>\\n<p>Use <code class=\\\"language-none\\\">benchbot_batch</code> to run your algorithm in a number of environments and produce a set of results. The script has a number of toggles available to customise the process (see <code class=\\\"language-none\\\">--help</code> for full details). To autonomously run your <code class=\\\"language-none\\\">semantic_slam:active:ground_truth</code> algorithm over 3 environments:</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">u@pc:~$ benchbot_batch --robot carter --task semantic_slam:active:ground_truth --envs miniroom:1,miniroom:3,house:5 --native python my_solution.py\\n</code></pre>\\n<p>Or you can use one of the pre-defined environment batches installed via add-ons (e.g. <a href=https://github.com/benchbot-addons/batches_isaac><code class=\\\"language-none\\\">benchbot-addons/batches_isaac</code></a>):</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">u@pc:~$ benchbot_batch --robot carter --task semantic_slam:active:ground_truth --envs-batch develop_1 --native python my_solution.py\\n</code></pre>\\n<p>Additionally, you can create a results ZIP and request an overall evaluation score at the end of the batch:</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">u@pc:~$ benchbot_batch --robot carter --task semantic_slam:active:ground_truth --envs miniroom:1,miniroom:3,house:5 --zip --score-results omq --native python my_solution.py\\n</code></pre>\\n<p>Lastly, both native and containerised submissions are supported exactly as in <code class=\\\"language-none\\\">benchbot_submit</code>:</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">u@pc:~$ benchbot_batch --robot carter --task semantic_slam:active:ground_truth --envs miniroom:1,miniroom:3,house:5 --containerised my_solution_folder/\\n</code></pre>\\n</li>\\n<li>\\n<p>You can also directly call the holistic evaluation performed above by <code class=\\\"language-none\\\">benchbot_batch</code> through the <code class=\\\"language-none\\\">benchbot_eval</code> script. The script supports single result files, multiple results files, or a ZIP of multiple results files. See <code class=\\\"language-none\\\">benchbot_eval --help</code> for full details. Below are examples calling <code class=\\\"language-none\\\">benchbot_eval</code> with a series of results and a ZIP of results respectively:</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">u@pc:~$ benchbot_eval --method omq -o my_jsons_scores result_1.json result_2.json result_3.json\\n</code></pre>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">u@pc:~$ benchbot_eval --method omq -o my_zip_scores results.zip\\n</code></pre>\\n</li>\\n</ul>\\n<h2>Using BenchBot in your research</h2>\\n<p>BenchBot was made to enable and assist the development of high quality, repeatable research results. We welcome any and all use of the BenchBot software stack in your research.</p>\\n<p>To use our system, we just ask that you cite our paper on the BenchBot system. This will help us follow uses of BenchBot in the research community, and understand how we can improve the system to help support future research results. Citation details are as follows:</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">@misc{talbot2020benchbot,\\n    title={BenchBot: Evaluating Robotics Research in Photorealistic 3D Simulation and on Real Robots},\\n    author={Ben Talbot and David Hall and Haoyang Zhang and Suman Raj Bista and Rohan Smith and Feras Dayoub and Niko Sünderhauf},\\n    year={2020},\\n    eprint={2008.00635},\\n    archivePrefix={arXiv},\\n    primaryClass={cs.RO}\\n}\\n</code></pre>\\n<h2>Components of the BenchBot software stack</h2>\\n<p>The BenchBot software stack is split into a number of standalone components, each with their own GitHub repository and documentation. This repository glues them all together for you into a working system. The components of the stack are:</p>\\n<ul>\\n<li><strong><a href=https://github.com/qcr/benchbot_api>benchbot_api</a>:</strong> user-facing Python interface to the BenchBot system, allowing the user to control simulated or real robots in simulated or real world environments through simple commands</li>\\n<li><strong><a href=https://github.com/qcr/benchbot_addons>benchbot_addons</a>:</strong> a Python manager for add-ons to a BenchBot system, with full documentation on how to create and add your own add-ons</li>\\n<li><strong><a href=https://github.com/qcr/benchbot_supervisor>benchbot_supervisor</a>:</strong> a HTTP server facilitating communication between user-facing interfaces and the underlying robot controller</li>\\n<li><strong><a href=https://github.com/qcr/benchbot_robot_controller>benchbot_robot_controller</a>:</strong> a wrapping script which controls the low-level ROS functionality of a simulator or real robot, handles automated subprocess management, and exposes interaction via a HTTP server</li>\\n<li><strong><a href=https://github.com/qcr/benchbot_simulator>benchbot_simulator</a>:</strong> a realistic 3D simulator employing Nvidia's Isaac framework, in combination with Unreal Engine environments</li>\\n<li><strong><a href=https://github.com/qcr/benchbot_eval>benchbot_eval</a>:</strong> Python library for evaluating the performance in a task, based on the results produced by a submission</li>\\n</ul>\\n<h2>Further information</h2>\\n<ul>\\n<li><strong><a href=https://github.com/qcr/benchbot/wiki/FAQs>FAQs</a>:</strong> Wiki page where answers to frequently asked questions and resolutions to common issues will be provided</li>\\n<li><strong><a href=https://github.com/qcr/benchbot/wiki/Tutorial:-Performing-Semantic-SLAM-with-Votenet>Semantic SLAM Tutorial</a>:</strong> a tutorial stepping through creating a semantic SLAM system in BenchBot that utilises the 3D object detector <a href=https://github.com/facebookresearch/votenet>VoteNet</a></li>\\n</ul>\\n<h2>Supporters</h2>\\n<p>Development of the BenchBot software stack was directly supported by:</p>\\n<p><a href=\\\"https://www.roboticvision.org/\\\"><img src=\\\"/_next/static/images/acrv_logo_small-e816f01e0557cf5cee1e9eb709d9a5e5.png\\\" alt=\\\"Australian Centre for Robotic Vision\\\"></a>        <a href=\\\"https://research.qut.edu.au/qcr/\\\"><img src=\\\"data:image/png;base64,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\\\" alt=\\\"QUT Centre for Robotics\\\"></a></p>\\n\",\"name\":\"BenchBot Software Stack\",\"type\":\"code\",\"url\":\"https://github.com/qcr/benchbot\",\"image_position\":\"100% center\",\"src\":\"/content/benchbot/benchbot.md\",\"id\":\"benchbot\",\"image\":\"/_next/static/gifs/0f460afe63fb093a8b44efcd5c652cf8.jpg\",\"_image\":\"/_next/static/gifs/0f460afe63fb093a8b44efcd5c652cf8.webm\"},{\"content\":\"<p><strong>NOTE: this software needs to interface with a running instance of the BenchBot software stack. Unless you are running against a remote stack / robot, please install this software with the BenchBot software stack as described <a href=https://github.com/qcr/benchbot>here</a>.</strong></p>\\n<h1>BenchBot API</h1>\\n<p><video autoplay loop poster=\\\"/_next/static/gifs/566ece96917dbb84cd386109b8457390.jpg\\\"><source src=\\\"/_next/static/gifs/566ece96917dbb84cd386109b8457390.webm\\\" type=\\\"video/webm\\\"/></video></p>\\n<p>The BenchBot API provides a simple interface for controlling a robot or simulator through actions, and receiving data through observations. As shown above, the entire code required for running an agent in a realistic 3D simulator is only a handful of simple Python commands.</p>\\n<p><a href=\\\"https://gym.openai.com\\\">Open AI Gym</a> users will find the breakdown into actions, observations, and steps extremely familiar. BenchBot API allows researchers to develop and test novel algorithms with real robot systems and realistic 3D simulators, without the typical hassles arising when interfacing with complicated multi-component robot systems.</p>\\n<p>Running a robot through an entire environment, with your own custom agent, is as simple as one line of code with the BenchBot API:</p>\\n<pre class=\\\"language-python\\\"><code class=\\\"language-python\\\"><span class=\\\"token keyword\\\">from</span> benchbot_api <span class=\\\"token keyword\\\">import</span> BenchBot\\n<span class=\\\"token keyword\\\">from</span> my_agent <span class=\\\"token keyword\\\">import</span> MyAgent\\n\\nBenchBot<span class=\\\"token punctuation\\\">(</span>agent<span class=\\\"token operator\\\">=</span>MyAgent<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">.</span>run<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span>\\n</code></pre>\\n<p>The above assumes you have created your own agent by overloading the abstract <code class=\\\"language-none\\\">Agent</code> class provided with the API. Overloading the abstract class requires implementing 3 basic methods. Below is a basic example to spin on the spot:</p>\\n<pre class=\\\"language-python\\\"><code class=\\\"language-python\\\"><span class=\\\"token keyword\\\">from</span> benchbot_api <span class=\\\"token keyword\\\">import</span> Agent\\n<span class=\\\"token keyword\\\">import</span> json\\n\\n<span class=\\\"token keyword\\\">class</span> <span class=\\\"token class-name\\\">MyAgent</span><span class=\\\"token punctuation\\\">(</span>Agent<span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">:</span>\\n\\n    <span class=\\\"token keyword\\\">def</span> <span class=\\\"token function\\\">is_done</span><span class=\\\"token punctuation\\\">(</span>self<span class=\\\"token punctuation\\\">,</span> action_result<span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">:</span>\\n        <span class=\\\"token comment\\\"># Go forever</span>\\n        <span class=\\\"token keyword\\\">return</span> <span class=\\\"token boolean\\\">False</span>\\n\\n    <span class=\\\"token keyword\\\">def</span> <span class=\\\"token function\\\">pick_action</span><span class=\\\"token punctuation\\\">(</span>self<span class=\\\"token punctuation\\\">,</span> observations<span class=\\\"token punctuation\\\">,</span> action_list<span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">:</span>\\n        <span class=\\\"token comment\\\"># Rotates on the spot indefinitely, 5 degrees at a time</span>\\n        <span class=\\\"token comment\\\"># (assumes we are running in passive mode)</span>\\n        <span class=\\\"token keyword\\\">return</span> <span class=\\\"token string\\\">'move_angle'</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token punctuation\\\">{</span><span class=\\\"token string\\\">'angle'</span><span class=\\\"token punctuation\\\">:</span> <span class=\\\"token number\\\">5</span><span class=\\\"token punctuation\\\">}</span>\\n\\n    <span class=\\\"token keyword\\\">def</span> <span class=\\\"token function\\\">save_result</span><span class=\\\"token punctuation\\\">(</span>self<span class=\\\"token punctuation\\\">,</span> filename<span class=\\\"token punctuation\\\">,</span> empty_results<span class=\\\"token punctuation\\\">,</span> results_format_fns<span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">:</span>\\n        <span class=\\\"token comment\\\"># Save some blank results</span>\\n        <span class=\\\"token keyword\\\">with</span> <span class=\\\"token builtin\\\">open</span><span class=\\\"token punctuation\\\">(</span>filename<span class=\\\"token punctuation\\\">,</span> <span class=\\\"token string\\\">'w'</span><span class=\\\"token punctuation\\\">)</span> <span class=\\\"token keyword\\\">as</span> f<span class=\\\"token punctuation\\\">:</span>\\n            json<span class=\\\"token punctuation\\\">.</span>dump<span class=\\\"token punctuation\\\">(</span>empty_results<span class=\\\"token punctuation\\\">,</span> f<span class=\\\"token punctuation\\\">)</span>\\n</code></pre>\\n<p>If you prefer to do things manually, a more exhaustive suite of functions are also available as part of the BenchBot API. Instead of using the <code class=\\\"language-none\\\">BenchBot.run()</code> method, a large number of methods are available through the API. Below highlights a handful of the capabilities of BenchBot API:</p>\\n<pre class=\\\"language-python\\\"><code class=\\\"language-python\\\"><span class=\\\"token keyword\\\">from</span> benchbot_api <span class=\\\"token keyword\\\">import</span> BenchBot<span class=\\\"token punctuation\\\">,</span> RESULT_LOCATION\\n<span class=\\\"token keyword\\\">import</span> json\\n<span class=\\\"token keyword\\\">import</span> matplotlib<span class=\\\"token punctuation\\\">.</span>pyplot <span class=\\\"token keyword\\\">as</span> plt\\n\\n<span class=\\\"token comment\\\"># Create a BenchBot instance &amp; reset the simulator / robot to starting state</span>\\nb <span class=\\\"token operator\\\">=</span> BenchBot<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span>\\nobservations<span class=\\\"token punctuation\\\">,</span> action_result <span class=\\\"token operator\\\">=</span> b<span class=\\\"token punctuation\\\">.</span>reset<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span>\\n\\n<span class=\\\"token comment\\\"># Print details of selected task &amp; environment</span>\\n<span class=\\\"token keyword\\\">print</span><span class=\\\"token punctuation\\\">(</span>b<span class=\\\"token punctuation\\\">.</span>task_details<span class=\\\"token punctuation\\\">)</span>\\n<span class=\\\"token keyword\\\">print</span><span class=\\\"token punctuation\\\">(</span>b<span class=\\\"token punctuation\\\">.</span>environment_details<span class=\\\"token punctuation\\\">)</span>\\n\\n<span class=\\\"token comment\\\"># Visualise the current RGB image from the robot</span>\\nplt<span class=\\\"token punctuation\\\">.</span>imshow<span class=\\\"token punctuation\\\">(</span>observations<span class=\\\"token punctuation\\\">[</span><span class=\\\"token string\\\">'image_rgb'</span><span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span>\\n\\n<span class=\\\"token comment\\\"># Move to the next pose if we have a 'move_next' action available</span>\\n<span class=\\\"token keyword\\\">if</span> <span class=\\\"token string\\\">'move_next'</span> <span class=\\\"token keyword\\\">in</span> b<span class=\\\"token punctuation\\\">.</span>actions<span class=\\\"token punctuation\\\">:</span>\\n    observations<span class=\\\"token punctuation\\\">,</span> action_result <span class=\\\"token operator\\\">=</span> b<span class=\\\"token punctuation\\\">.</span>step<span class=\\\"token punctuation\\\">(</span><span class=\\\"token string\\\">'move_next'</span><span class=\\\"token punctuation\\\">)</span>\\n\\n<span class=\\\"token comment\\\"># Save some empty results</span>\\n<span class=\\\"token keyword\\\">with</span> <span class=\\\"token builtin\\\">open</span><span class=\\\"token punctuation\\\">(</span>RESULT_LOCATION<span class=\\\"token punctuation\\\">,</span> <span class=\\\"token string\\\">'w'</span><span class=\\\"token punctuation\\\">)</span> <span class=\\\"token keyword\\\">as</span> f<span class=\\\"token punctuation\\\">:</span>\\n    json<span class=\\\"token punctuation\\\">.</span>dump<span class=\\\"token punctuation\\\">(</span>b<span class=\\\"token punctuation\\\">.</span>empty_results<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">,</span> f<span class=\\\"token punctuation\\\">)</span>\\n</code></pre>\\n<p>For sample solutions that use the BenchBot API, see the examples add-ons available (e.g. <a href=https://github.com/benchbot-addons/examples_base><code class=\\\"language-none\\\">benchbot-addons/examples_base</code></a> and <a href=https://github.com/benchbot-addons/examples_ssu><code class=\\\"language-none\\\">benchbot-addons/examples_ssu</code></a>).</p>\\n<h2>Installing BenchBot API</h2>\\n<p>BenchBot API is a Python package, installable with pip. Run the following in the root directory of where this repository was cloned:</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">u@pc:~$ pip install .\\n</code></pre>\\n<h2>Using the API to communicate with a robot</h2>\\n<p>Communication with the robot comes through a series of &quot;channels&quot; which are defined by the robot's definition file (e.g. <a href=https://github.com/benchbot-addons/robots_isaac/blob/master/robots/carter.yaml>carter</a>). A task definition file (e.g. <a href=https://github.com/benchbot-addons/tasks_ssu/blob/master/tasks/sslam_pgt.yaml>semantic_slam:passive:ground_truth</a>) then declares which of these connections are provided to the API as either sensor observations or actions to be executed by a robot actuator.</p>\\n<p>The API talks to the <a href=https://github.com/qcr/benchbot_supervisor>BenchBot Supervisor</a>, which handles loading and managing the different kinds of back-end configuration files. This abstracts all of the underlying communication complexities away from the user, allowing the BenchBot API to remain a simple interface that focuses on getting observations and sending actions.</p>\\n<p>An action is sent to the robot by calling the <code class=\\\"language-none\\\">BenchBot.step()</code> method with a valid action (found by checking the <code class=\\\"language-none\\\">BenchBot.actions</code> property):</p>\\n<pre class=\\\"language-python\\\"><code class=\\\"language-python\\\"><span class=\\\"token keyword\\\">from</span> benchbot_api <span class=\\\"token keyword\\\">import</span> BenchBot\\n\\nb <span class=\\\"token operator\\\">=</span> BenchBot<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span>\\navailable_actions <span class=\\\"token operator\\\">=</span> b<span class=\\\"token punctuation\\\">.</span>actions\\nb<span class=\\\"token punctuation\\\">.</span>step<span class=\\\"token punctuation\\\">(</span>b<span class=\\\"token punctuation\\\">.</span>actions<span class=\\\"token punctuation\\\">[</span><span class=\\\"token number\\\">0</span><span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token punctuation\\\">{</span><span class=\\\"token string\\\">'action_arg:'</span><span class=\\\"token punctuation\\\">,</span> arg_value<span class=\\\"token punctuation\\\">}</span><span class=\\\"token punctuation\\\">)</span>  <span class=\\\"token comment\\\"># Perform the first available action</span>\\n</code></pre>\\n<p>The second parameter is a dictionary of named arguments for the selected action. For example, moving 5m forward with the <code class=\\\"language-none\\\">'move_distance'</code> action is represented by the dictionary <code class=\\\"language-none\\\">{'distance': 5}</code>.</p>\\n<p>Observations lists are received as return values from a <code class=\\\"language-none\\\">BenchBot.step()</code> call (<code class=\\\"language-none\\\">BenchBot.reset()</code> internally calls <code class=\\\"language-none\\\">BenchBot.step(None)</code>, which means don't perform an action):</p>\\n<pre class=\\\"language-python\\\"><code class=\\\"language-python\\\"><span class=\\\"token keyword\\\">from</span> benchbot_api <span class=\\\"token keyword\\\">import</span> BenchBot\\n\\nb <span class=\\\"token operator\\\">=</span> BenchBot<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span>\\nobservations<span class=\\\"token punctuation\\\">,</span> action_result <span class=\\\"token operator\\\">=</span> b<span class=\\\"token punctuation\\\">.</span>reset<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span>\\nobservations<span class=\\\"token punctuation\\\">,</span> action_result <span class=\\\"token operator\\\">=</span> b<span class=\\\"token punctuation\\\">.</span>step<span class=\\\"token punctuation\\\">(</span><span class=\\\"token string\\\">'move_distance'</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token punctuation\\\">{</span><span class=\\\"token string\\\">'distance'</span><span class=\\\"token punctuation\\\">:</span> <span class=\\\"token number\\\">5</span><span class=\\\"token punctuation\\\">}</span><span class=\\\"token punctuation\\\">)</span>\\n</code></pre>\\n<p>The returned <code class=\\\"language-none\\\">observations</code> variable holds a dictionary with key-value pairs corresponding to the name-data defined by each observation channel.</p>\\n<p>The <code class=\\\"language-none\\\">action_result</code> is an enumerated value denoting the result of the action (use <code class=\\\"language-none\\\">from benchbot_api import ActionResult</code> to access the <code class=\\\"language-none\\\">Enum</code> class). You should use this result to guide the progression of your algorithm either manually or in the <code class=\\\"language-none\\\">is_done()</code> method of your <code class=\\\"language-none\\\">Agent</code>. Possible values for the returned <code class=\\\"language-none\\\">action_result</code> are:</p>\\n<ul>\\n<li><code class=\\\"language-none\\\">ActionResult.SUCCESS</code>: the action was carried out successfully</li>\\n<li><code class=\\\"language-none\\\">ActionResult.FINISHED</code>: the action was carried out successfully, and the robot is now finished its traversal through the scene (only used in <code class=\\\"language-none\\\">passive</code> actuation mode)</li>\\n<li><code class=\\\"language-none\\\">ActionResult.COLLISION</code>: the action crashed the robot into an obstacle, and as a result it will not respond to any further actuation commands (at this point you should quit)</li>\\n</ul>\\n<h3>Standard Communication Channels</h3>\\n<p>Tasks and robot definition files declare actions and observations, and these files are include through <a href=https://github.com/qcr/benchbot_addons>BenchBot add-ons</a>. The add-on creator is free to add and declare channels as they please, but it is a better experience for all if channel definitions are as consistent as possible across the BenchBot ecosystem.</p>\\n<p>So if you're adding a robot that move between a set of poses, declare a channel called <code class=\\\"language-none\\\">'move_next</code> with no arguments. Likewise, a robot that receives image observations should use a channel named <code class=\\\"language-none\\\">'image_rgb'</code> with the same format as described below. Feel free to implement the channels however you please for your robot, but consistent interfaces should always be preferred.</p>\\n<p>If you encounter a task using non-standard channel configurations, the API has all the functionality you need as a user to handle them (<code class=\\\"language-none\\\">actions</code>, <code class=\\\"language-none\\\">config</code>, &amp; <code class=\\\"language-none\\\">observations</code> properties). On the other hand, maybe the non-standard channel should be a new standard. New standard communication channels are always welcome; please open a pull request with the details!</p>\\n<h4>Standard action channels:</h4>\\n<table>\\n<thead>\\n<tr>\\n<th>Name</th>\\n<th style=\\\"text-align:center\\\">Required Arguments</th>\\n<th>Description</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td><code class=\\\"language-none\\\">'move_next'</code></td>\\n<td style=\\\"text-align:center\\\"><code class=\\\"language-none\\\">None</code></td>\\n<td>Moves the robot to the next pose in its list of pre-defined poses (only available in environments that declare a <code class=\\\"language-none\\\">'trajectory_poses'</code> field).</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'move_distance'</code></td>\\n<td style=\\\"text-align:center\\\"><pre class=\\\"language-none\\\">{'distance': float}</pre></td>\\n<td>Moves the robot <code class=\\\"language-none\\\">'distance'</code> metres directly ahead.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'move_angle'</code></td>\\n<td style=\\\"text-align:center\\\"><pre class=\\\"language-none\\\">{'angle': float}</pre></td>\\n<td>Rotate the angle on the spot by <code class=\\\"language-none\\\">'angle'</code> degrees.</td>\\n</tr>\\n</tbody>\\n</table>\\n<h4>Standard observation channels:</h4>\\n<table>\\n<thead>\\n<tr>\\n<th>Name</th>\\n<th style=\\\"text-align:left\\\">Data format</th>\\n<th>Description</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td><code class=\\\"language-none\\\">'image_depth'</code></td>\\n<td style=\\\"text-align:left\\\"><pre class=\\\"language-none\\\">numpy.ndarray(shape=(H,W),<br> dtype='float32')</pre></td>\\n<td>Depth image from the default image sensor with depths in meters.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'image_depth_info'</code></td>\\n<td style=\\\"text-align:left\\\"><pre class=\\\"language-none\\\">{<br> 'frame_id': string<br> 'height': int<br> 'width': int<br> 'matrix_instrinsics':<br> numpy.ndarray(shape=(3,3),<br> dtype='float64')<br>'matrix_projection':<br> numpy.ndarray(shape=(3,4)<br> dtype='float64')<br>}</pre></td>\\n<td>Sensor information for the depth image. <code class=\\\"language-none\\\">'matrix_instrinsics'</code> is of the format:<br><pre class=\\\"language-none\\\">[fx 0 cx]<br>[0 fy cy]<br>[0 0 1]</pre> for a camera with focal lengths <code class=\\\"language-none\\\">(fx,fy)</code>, &amp; principal point <code class=\\\"language-none\\\">(cx,cy)</code>. Likewise, <code class=\\\"language-none\\\">'matrix_projection'</code> is:<br><pre class=\\\"language-none\\\">[fx 0 cx Tx]<br>[0 fy cy Ty]<br>[0 0 1 0]</pre>where <code class=\\\"language-none\\\">(Tx,Ty)</code> is the translation between stereo sensors. See <a href=\\\"http://docs.ros.org/melodic/api/sensor_msgs/html/msg/CameraInfo.html\\\">here</a> for further information on fields.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'image_rgb'</code></td>\\n<td style=\\\"text-align:left\\\"><pre class=\\\"language-none\\\">numpy.ndarray(shape=(H,W,3),<br> dtype='uint8')</pre></td>\\n<td>RGB image from the default image sensor with colour values mapped to the 3 channels, in the 0-255 range.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'image_rgb_info'</code></td>\\n<td style=\\\"text-align:left\\\"><pre class=\\\"language-none\\\">{<br> 'frame_id': string<br> 'height': int<br> 'width': int<br> 'matrix_instrinsics':<br> numpy.ndarray(shape=(3,3),<br> dtype='float64')<br>'matrix_projection':<br> numpy.ndarray(shape=(3,4)<br> dtype='float64')<br>}</pre></td>\\n<td>Sensor information for the RGB image. <code class=\\\"language-none\\\">'matrix_instrinsics'</code> is of the format:<br><pre class=\\\"language-none\\\">[fx 0 cx]<br>[0 fy cy]<br>[0 0 1]</pre> for a camera with focal lengths <code class=\\\"language-none\\\">(fx,fy)</code>, &amp; principal point <code class=\\\"language-none\\\">(cx,cy)</code>. Likewise, <code class=\\\"language-none\\\">'matrix_projection'</code> is:<br><pre class=\\\"language-none\\\">[fx 0 cx Tx]<br>[0 fy cy Ty]<br>[0 0 1 0]</pre>where <code class=\\\"language-none\\\">(Tx,Ty)</code> is the translation between stereo sensors. See <a href=\\\"http://docs.ros.org/melodic/api/sensor_msgs/html/msg/CameraInfo.html\\\">here</a> for further information on fields.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'laser'</code></td>\\n<td style=\\\"text-align:left\\\"><pre class=\\\"language-none\\\">{<br> 'range_max': float64,<br> 'range_min': float64,<br> 'scans':<br> numpy.ndarray(shape=(N,2),<br> dtype='float64')<br>}</pre></td>\\n<td>Set of scan values from a laser sensor, between <code class=\\\"language-none\\\">'range_min'</code> &amp; <code class=\\\"language-none\\\">'range_max'</code> (in meters). The <code class=\\\"language-none\\\">'scans'</code> array consists of <code class=\\\"language-none\\\">N</code> scans of format <code class=\\\"language-none\\\">[scan_angle, scan_value]</code>. For example, <code class=\\\"language-none\\\">scans[100,0]</code> would get the angle of the 100th scan &amp; <code class=\\\"language-none\\\">scans[100,1]</code> would get the distance value.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'poses'</code></td>\\n<td style=\\\"text-align:left\\\"><pre class=\\\"language-none\\\">{<br> ...<br> 'frame_name': {<br> 'parent_frame': string<br> 'rotation_rpy':<br> numpy.ndarray(shape=(3,),<br> dtype='float64')<br> 'rotation_xyzw':<br> numpy.ndarray(shape=(4,),<br> dtype='float64')<br> 'translation_xyz':<br> numpy.ndarray(shape=(3,),<br> dtype='float64')<br> }<br> ...<br>}</pre></td>\\n<td>Dictionary of relative poses for the current system state. The pose of each system component is available at key <code class=\\\"language-none\\\">'frame_name'</code>. Each pose has a <code class=\\\"language-none\\\">'parent_frame'</code> which the pose is relative to (all poses are typically with respect to global <code class=\\\"language-none\\\">'map'</code> frame), &amp; the pose values. <code class=\\\"language-none\\\">'rotation_rpy'</code> is <code class=\\\"language-none\\\">[roll,pitch,yaw]</code>, <code class=\\\"language-none\\\">'rotation_xyzw'</code> is the equivalent quaternion <code class=\\\"language-none\\\">[x,y,z,w]</code>, &amp; <code class=\\\"language-none\\\">'translation_xyz'</code> is the Cartesion <code class=\\\"language-none\\\">[x,y,z]</code> coordinates.</td>\\n</tr>\\n</tbody>\\n</table>\\n<h2>Using the API to communicate with the BenchBot system</h2>\\n<p>A running BenchBot system manages many other elements besides simply getting data to and from a real / simulated robot. BenchBot encapsulates not just the robot, but also the environment it is operating in (whether that be simulator or real) and task that is currently being attempted.</p>\\n<p>The API handles communication for all parts of the BenchBot system, including controlling the currently running environment and obtaining configuration information. Below are details for some of the more useful features of the API (all features are also documented in the <a href=https:/github.com/qcr/benchbot_api/blob/master/benchbot_api/benchbot.py><code class=\\\"language-none\\\">benchbot.py</code></a> source code).</p>\\n<h3>Gathering configuration information</h3>\\n<table>\\n<thead>\\n<tr>\\n<th>API method or property</th>\\n<th>Description</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td><code class=\\\"language-none\\\">config</code></td>\\n<td>Returns a <code class=\\\"language-none\\\">dict</code> exhaustively describing the current BenchBot configuration. Most of the information returned will not be useful for general BenchBot use.</td>\\n</tr>\\n</tbody>\\n</table>\\n<h3>Interacting with the environment</h3>\\n<table>\\n<thead>\\n<tr>\\n<th>API method or property</th>\\n<th>Description</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td><code class=\\\"language-none\\\">reset()</code></td>\\n<td>Resets the current environment scene. For the simulator, this means restarting the running simulator instance with the robot back at its initial position. The method returns initial <code class=\\\"language-none\\\">observations</code>, &amp; the <code class=\\\"language-none\\\">action_result</code> (should always be <code class=\\\"language-none\\\">BenchBot.ActionResult.SUCCESS</code>).</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">next_scene()</code></td>\\n<td>Starts the next scene in the current environment (only relevant for tasks with multiple scenes). Note there is no going back once you have moved to the next scene. Returns the same as <code class=\\\"language-none\\\">reset()</code>.</td>\\n</tr>\\n</tbody>\\n</table>\\n<h3>Interacting with an agent</h3>\\n<table>\\n<thead>\\n<tr>\\n<th>API method or property</th>\\n<th>Description</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td><code class=\\\"language-none\\\">actions</code></td>\\n<td>Returns the list of actions currently available to the agent. This will update as actions are performed in the environment (for example if the agent has collided with an obstacle this list will be empty).</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">observations</code></td>\\n<td>Returns the lists of observations available to the agent.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">step(action, **action_args)</code></td>\\n<td>Performs the requested action with the provided named action arguments. See <a href=https:/github.com/qcr/benchbot_api/#using-the-api-to-communicate-with-a-robot>Using the API to communicate with a robot</a> above for further details.</td>\\n</tr>\\n</tbody>\\n</table>\\n<h3>Creating results</h3>\\n<table>\\n<thead>\\n<tr>\\n<th>API method or property</th>\\n<th>Description</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td><code class=\\\"language-none\\\">empty_results()</code></td>\\n<td>Generates a <code class=\\\"language-none\\\">dict</code> of with required result metadata &amp; empty results. Metadata (<code class=\\\"language-none\\\">'task_details'</code> &amp; <code class=\\\"language-none\\\">'environment_details'</code>) is pre-filled. To create results, all a user needs to do is fill in the empty <code class=\\\"language-none\\\">'results'</code> field using format's results functions. These functions are available through the <code class=\\\"language-none\\\">'results_functions()</code> method.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">results_functions()</code></td>\\n<td>Returns a <code class=\\\"language-none\\\">dict</code> of functions defined by the task's <code class=\\\"language-none\\\">'results_format'</code>. Example use for calling a <code class=\\\"language-none\\\">create()</code> function is <code class=\\\"language-none\\\">results_functions()['create']()</code>.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">RESULT_LOCATION</code> (outside of <code class=\\\"language-none\\\">BenchBot</code> class)</td>\\n<td>A static string denoting where results should be saved (<code class=\\\"language-none\\\">/tmp/results</code>). Using this locations ensures tools in the <a href=https://github.com/qcr/benchbot>BenchBot software stack</a> work as expected.</td>\\n</tr>\\n</tbody>\\n</table>\\n\",\"name\":\"BenchBot Python API\",\"type\":\"code\",\"url\":\"https://github.com/qcr/benchbot_api\",\"image_position\":\"center 100%\",\"src\":\"/content/benchbot/benchbot-api.md\",\"id\":\"benchbot-api\",\"image\":\"/_next/static/gifs/566ece96917dbb84cd386109b8457390.jpg\",\"_image\":\"/_next/static/gifs/566ece96917dbb84cd386109b8457390.webm\"},{\"content\":\"<p><strong>NOTE: this software is part of the BenchBot software stack, and not intended to be run in isolation (although it can be installed independently through pip if desired). For a working BenchBot system, please install the BenchBot software stack by following the instructions <a href=https://github.com/qcr/benchbot>here</a>.</strong></p>\\n<h1>BenchBot Add-ons Manager</h1>\\n<p><video autoplay loop poster=\\\"/_next/static/gifs/8ef442bbcf06f5d9f4a4bd553bd28212.jpg\\\"><source src=\\\"/_next/static/gifs/8ef442bbcf06f5d9f4a4bd553bd28212.webm\\\" type=\\\"video/webm\\\"/></video></p>\\n<p>The BenchBot Add-ons Manager allows you to use BenchBot with a wide array of additional content, and customise your installation to suite your needs. Semantic Scene Understanding not your thing? Install the Semantic Question Answering add-ons instead. Want to create your own content? Write some basic YAML files to make your own add-ons. Need to re-use existing content? Simply include a dependency on that add-on. Add-ons are all about making BenchBot whatever you need it to be—build a BenchBot for your research problems, exactly as you need it.</p>\\n<p>Add-ons come in a variety of types. Anything that you may need to customise for your own experiments or research, should be customisable through an add-on. If not, let us know, and we'll add more add-on enabled functionality to BenchBot!</p>\\n<p>The list of currently supported types of add-ons are:</p>\\n<ul>\\n<li><strong>batches</strong>: a list of environments used for repeatable evaluation scores with the <code class=\\\"language-none\\\">benchbot_batch</code> script.</li>\\n<li><strong>environments</strong>: simulated or real world environments that a task can be performed in, with a robot. Only <a href=\\\"https://developer.nvidia.com/Isaac-sim\\\">Isaac Sim</a> simulation is currently supported, but there is capacity to support other simulators. Please get in contact if you'd like to see another simulator in BenchBot!</li>\\n<li><strong>evaluation_methods</strong>: a method for evaluating a set of formatted results, against a corresponding ground truth, and producing scores describing how well a result performed a given task.</li>\\n<li><strong>formats</strong>: formalisation of a format for results or ground truth data, including helper functions.</li>\\n<li><strong>ground_truths</strong>: ground truth data in a declared format, about a specific environment. Environments can have many different types of ground truths depending on what different tasks require.</li>\\n<li><strong>robots</strong>: a robot definition declaring the communication channels available to the BenchBot ecosystem. Both simulated and real world robots are supported, they just need to run ROS.</li>\\n<li><strong>tasks</strong>: a task is a definition of something we want a robot to do, including what observations and actions it has available, and how results should be reported.</li>\\n</ul>\\n<p>See the sections below for details of how to interact with installed add-ons, how to create your own add-ons, and formalisation of what's required in an add-on.</p>\\n<h2>Installing and using the add-ons manager</h2>\\n<p>In general, you won't use the add-ons manager directly. Instead you interact with the <a href=https://github.com/qcr/benchbot>BenchBot software stack</a>, which uses the add-ons manager to manage and access add-ons.</p>\\n<p>The manager is a Python package if you do find you want to use it directly, and installable with pip. Run the following in the root directory where the repository was cloned:</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">u@pc:~$ pip install .\\n</code></pre>\\n<p>The manager can then be imported and used to manage installation, loading, accessing, processing, and updating of add-ons. Some samples of supported functionality are shown below:</p>\\n<pre class=\\\"language-python\\\"><code class=\\\"language-python\\\"><span class=\\\"token keyword\\\">from</span> benchbot_addons <span class=\\\"token keyword\\\">import</span> manager <span class=\\\"token keyword\\\">as</span> bam\\n\\n<span class=\\\"token comment\\\"># Check if example with 'name' = 'hello_scd' exists</span>\\nbam<span class=\\\"token punctuation\\\">.</span>exists<span class=\\\"token punctuation\\\">(</span><span class=\\\"token string\\\">'examples'</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token punctuation\\\">[</span><span class=\\\"token punctuation\\\">(</span><span class=\\\"token string\\\">'name'</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token string\\\">'hello_scd'</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span>\\n\\n<span class=\\\"token comment\\\"># Find all installed environments</span>\\nbam<span class=\\\"token punctuation\\\">.</span>find_all<span class=\\\"token punctuation\\\">(</span><span class=\\\"token string\\\">'environments'</span><span class=\\\"token punctuation\\\">)</span>\\n\\n<span class=\\\"token comment\\\"># Get a list of the names for all installed tasks</span>\\nbam<span class=\\\"token punctuation\\\">.</span>get_field<span class=\\\"token punctuation\\\">(</span><span class=\\\"token string\\\">'tasks'</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token string\\\">'name'</span><span class=\\\"token punctuation\\\">)</span>\\n\\n<span class=\\\"token comment\\\"># Get a list of (name, variant) pairs for all installed environments</span>\\nbam<span class=\\\"token punctuation\\\">.</span>get_fields<span class=\\\"token punctuation\\\">(</span><span class=\\\"token string\\\">'environments'</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token punctuation\\\">[</span><span class=\\\"token string\\\">'name'</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token string\\\">'variant'</span><span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span>\\n\\n<span class=\\\"token comment\\\"># Find a robot with 'name' = 'carter'</span>\\nbam<span class=\\\"token punctuation\\\">.</span>get_match<span class=\\\"token punctuation\\\">(</span><span class=\\\"token string\\\">'robots'</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token punctuation\\\">[</span><span class=\\\"token punctuation\\\">(</span><span class=\\\"token string\\\">'name'</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token string\\\">'carter'</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span>\\n\\n<span class=\\\"token comment\\\"># Get the 'results_format' value for the task called 'scd:passive:ground_truth'</span>\\nbam<span class=\\\"token punctuation\\\">.</span>get_value_by_name<span class=\\\"token punctuation\\\">(</span><span class=\\\"token string\\\">'tasks'</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token string\\\">'scd:passive:ground_truth'</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token string\\\">'results_format'</span><span class=\\\"token punctuation\\\">)</span>\\n\\n<span class=\\\"token comment\\\"># Load YAML data for all installed ground truths</span>\\nbam<span class=\\\"token punctuation\\\">.</span>load_yaml_list<span class=\\\"token punctuation\\\">(</span>bam<span class=\\\"token punctuation\\\">.</span>find_all<span class=\\\"token punctuation\\\">(</span><span class=\\\"token string\\\">'ground_truths'</span><span class=\\\"token punctuation\\\">,</span> extension<span class=\\\"token operator\\\">=</span><span class=\\\"token string\\\">'json'</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">)</span>\\n\\n<span class=\\\"token comment\\\"># Install a list of comma-separated add-ons</span>\\nbam<span class=\\\"token punctuation\\\">.</span>install_addons<span class=\\\"token punctuation\\\">(</span><span class=\\\"token string\\\">'benchbot-addons/ssu,benchbot-addons/sqa'</span><span class=\\\"token punctuation\\\">)</span>\\n\\n<span class=\\\"token comment\\\"># Install a specific add-on (&amp; it's dependencies)</span>\\nbam<span class=\\\"token punctuation\\\">.</span>install_addon<span class=\\\"token punctuation\\\">(</span><span class=\\\"token string\\\">'tasks_ssu'</span><span class=\\\"token punctuation\\\">)</span>\\n\\n<span class=\\\"token comment\\\"># Print the list of currently installed add-ons, &amp; officially available add-ons</span>\\nbam<span class=\\\"token punctuation\\\">.</span>print_state<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span>\\n\\n<span class=\\\"token comment\\\"># Uninstall all add-ons</span>\\nbam<span class=\\\"token punctuation\\\">.</span>remove_addons<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span>\\n\\n<span class=\\\"token comment\\\"># Uninstall a string separated list of add-ons</span>\\nbam<span class=\\\"token punctuation\\\">.</span>remove_addon<span class=\\\"token punctuation\\\">(</span><span class=\\\"token string\\\">'benchbot-addons/ssu,benchbot-addons/sqa'</span><span class=\\\"token punctuation\\\">)</span>\\n</code></pre>\\n<h2>How to add your own add-ons</h2>\\n<p>There are two different types of add-ons: 'official' add-ons and third-party add-ons.</p>\\n<p>'Official' are add-ons that we've verified, and are stored in our <a href=https://github.com/benchbot-addons>benchbot-addons</a> GitHub organisation. You can get a full list of official add-ons through the <code class=\\\"language-none\\\">manager.official_addons()</code> helper function, or <code class=\\\"language-none\\\">benchbot_install --list-addons</code> script in the <a href=https://github.com/qcr/benchbot>BenchBot software stack</a>.</p>\\n<p>Third-party add-ons only differ in that we haven't looked at them, and they can be hosted anywhere on GitHub you please.</p>\\n<p>Creating all add-ons is exactly the same process, the only difference is whether the repository is inside or outside of the <a href=https://github.com/benchbot-addons>benchbot-addons</a> GitHub organisation:</p>\\n<ol>\\n<li>Create a new GitHub repository</li>\\n<li>Add folders corresponding to the type of content your add-ons provide (i.e. an environments add-on has an <code class=\\\"language-none\\\">environments</code> directory at the root).</li>\\n<li>Add YAML / JSON files for your content, and make sure they match the corresponding format specification from the section below</li>\\n<li>Add in any extra content your add-on may require: Python files, simulator binaries, images, etc. (if your add-on gets too big for a Git repository, you can zip the content up, host it somewhere, and use the <code class=\\\"language-none\\\">.remote</code> metadata file described in the next section)</li>\\n<li>Decide if your add-on is dependent on any others, and declare any dependencies in a <code class=\\\"language-none\\\">.dependencies</code> file</li>\\n<li>Push everything up to git on your default branch</li>\\n</ol>\\n<p><em><strong>Note:</strong> it's a good idea to only include one type of add-on per repository as it makes your add-on package more usable for others. It's not a hard rule though, so feel free to add multiple folders to your add-on if you require.</em></p>\\n<p>Feel free to have a look at any of the <a href=https://github.com/benchbot-addons>official add-ons</a> for help and examples of how to work with add-ons.</p>\\n<h2>Add-ons format specification</h2>\\n<p>Here are the technical details of what's expected in add-on content. The BenchBot system will assume these specifications are adhered to, and errors can be expected if you try to use add-ons that don't match the specifications.</p>\\n<p>An add-on package has the following structure (technically none of the files are required, they just determine what functionality your add-on includes):</p>\\n<table>\\n<thead>\\n<tr>\\n<th>Filename</th>\\n<th>Description</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td><code class=\\\"language-none\\\">.dependencies</code></td>\\n<td>A list of add-on packages that must be installed with this package. Packages are specified by their GitHub identifier (i.e. <code class=\\\"language-none\\\">github_username/repository_name</code>), with one per line</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">.dependencies-python</code></td>\\n<td>A list of Python dependencies for your add-on. Syntax for file is exactly the same as <a href=\\\"https://pip.pypa.io/en/stable/user_guide/#requirements-files\\\"><code class=\\\"language-none\\\">requirements.txt</code></a> files.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">.remote</code></td>\\n<td>Specifies content that should be installed from a remote URL, rather than residing in this repository. A remote resource is specified as a URL and target directory separated by a space. One resource is specified per line. The add-ons manager will fetch the URL specified, and extract the contents to the target directory (e.g. <code class=\\\"language-none\\\">http://myhost/my_content.zip environments</code>)</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">&lt;directory&gt;/</code></td>\\n<td>Each named directory corresponds to an add-on type described below. The directory will be ignored if its name doesn't exactly match any of those below.</td>\\n</tr>\\n</tbody>\\n</table>\\n<h3>Batch add-ons</h3>\\n<p>A YAML file, that must exist in a folder called <code class=\\\"language-none\\\">batches</code> in the root of the add-on package (e.g. <code class=\\\"language-none\\\">batches/my_batch.yaml</code>).</p>\\n<p>The following keys are supported for batch add-ons:</p>\\n<table>\\n<thead>\\n<tr>\\n<th>Key</th>\\n<th>Required</th>\\n<th>Description</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td><code class=\\\"language-none\\\">'name'</code></td>\\n<td>Yes</td>\\n<td>A string used to refer to this batch (must be unique!).</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'environments'</code></td>\\n<td>Yes</td>\\n<td>A list of environment strings of the format <code class=\\\"language-none\\\">'name':'variant'</code> (e.g. <code class=\\\"language-none\\\">'miniroom:1'</code>).</td>\\n</tr>\\n</tbody>\\n</table>\\n<h3>Environment add-ons</h3>\\n<p>A YAML file, that must exist in a folder called <code class=\\\"language-none\\\">environments</code> in the root of the add-on package (e.g. <code class=\\\"language-none\\\">environments/my_environment.yaml</code>).</p>\\n<p>The following keys are supported for environment add-ons:</p>\\n<table>\\n<thead>\\n<tr>\\n<th>Key</th>\\n<th>Required</th>\\n<th>Description</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td><code class=\\\"language-none\\\">'name'</code></td>\\n<td>Yes</td>\\n<td>A string used to refer to this environment's name (the <code class=\\\"language-none\\\">('name', 'variant')</code> pair must be unique!).</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'variant'</code></td>\\n<td>Yes</td>\\n<td>A string used to refer to this environment's variant (the <code class=\\\"language-none\\\">('name', 'variant')</code> pair must be unique!).</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'type'</code></td>\\n<td>Yes</td>\\n<td>A string describing the type of this environment (<code class=\\\"language-none\\\">'sim_unreal'</code> &amp; <code class=\\\"language-none\\\">'real'</code> are the only values currently used).</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'map_path'</code></td>\\n<td>Yes</td>\\n<td>A path to the map for this environment, which will be used by either the simulator or real world system to load the environment.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'start_pose'</code></td>\\n<td>Yes</td>\\n<td>The start pose of the robot that will be provided to users through the <a href=https://github.com/qcr/benchbot_api>BenchBot API</a>. The pose is specified as a list of 7 numbers: quarternion_x, quarternion_y, quarternion_z, quarternion_w, position_x, position_y, position_z. This must be accurate!</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'trajectory_poses'</code></td>\\n<td>No</td>\\n<td>A list of poses for the robot to traverse through in order. Each pose is a list of 7 numbers: quarternion_x, quarternion_y, quarternion_z, quarternion_w, position_x, position_y, position_z. This environment won't be usable for tasks that use the <code class=\\\"language-none\\\">'move_next'</code> action if this parameter isn't provided.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'robots'</code></td>\\n<td>No</td>\\n<td>A list of supported names for robot that are supported in this environment. If this list isn't included, all robots with the same <code class=\\\"language-none\\\">'type'</code> as this environment will be able to run.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'object_labels'</code></td>\\n<td>No</td>\\n<td>A list of labels for the objects that exist in the scene. Can be used with simulated sensors like segmentation sensors.</td>\\n</tr>\\n</tbody>\\n</table>\\n<h3>Evaluation method add-ons</h3>\\n<p>A YAML file, that must exist in a folder called <code class=\\\"language-none\\\">evaluation_methods</code> in the root of the add-on package (e.g. <code class=\\\"language-none\\\">evaluation_methods/my_evaluation_method.yaml</code>).</p>\\n<p>The following keys are supported for evaluation method add-ons:</p>\\n<table>\\n<thead>\\n<tr>\\n<th>Key</th>\\n<th>Required</th>\\n<th>Description</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td><code class=\\\"language-none\\\">'name'</code></td>\\n<td>Yes</td>\\n<td>A string used to refer to this evaluation method (must be unique!)</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'valid_result_formats'</code></td>\\n<td>Yes</td>\\n<td>List of strings denoting results formats supported by the evaluation method. Ideally these format definitions should also be installed.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'valid_ground_truth_formats'</code></td>\\n<td>Yes</td>\\n<td>List of strings denoting ground truth formats supported by the evaluation method. Ideally these format definitions should also be installed.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'functions'</code></td>\\n<td>Yes</td>\\n<td>Dictionary of named functions provided by the evaluation method. The named methods are key value pairs where the key is the function name, and the value is a string describing how the function can be imported with Python. For example, <code class=\\\"language-none\\\">evaluate: &quot;omq.evaluate_method&quot;</code> declares a function called <code class=\\\"language-none\\\">'evaluate'</code> that is imported via <code class=\\\"language-none\\\">from omq import evaluate_method</code>. Likewise <code class=\\\"language-none\\\">&quot;omq.submodule.combine_method&quot;</code> translates to <code class=\\\"language-none\\\">from omq.submodule import combine_method</code>. See below for the list of functions expected for evaluation methods.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'description'</code></td>\\n<td>No</td>\\n<td>A string describing what the evaluation method is and how it works. Should be included if you want users to understand where your method can be used.</td>\\n</tr>\\n</tbody>\\n</table>\\n<p>Evaluation methods expect the following named functions:</p>\\n<table>\\n<thead>\\n<tr>\\n<th>Name</th>\\n<th>Signature</th>\\n<th>Usage</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td><code class=\\\"language-none\\\">'evaluate'</code></td>\\n<td><code class=\\\"language-none\\\">fn(dict: results, list: ground_truths) -&gt; dict</code></td>\\n<td>Evaluates the performance using a <code class=\\\"language-none\\\">results</code> dictionary, and returns a dictionary of containing the scores. It also takes a list of dictionaries containing each ground truth that will be used in evaluation.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'combine'</code></td>\\n<td><code class=\\\"language-none\\\">fn(list: scores) -&gt; dict</code></td>\\n<td>Takes a list of <code class=\\\"language-none\\\">scores</code> dictionaries, and returns an aggregate score. If this method isn't declared, <a href=https://github.com/qcr/benchbot_eval><code class=\\\"language-none\\\">benchbot_eval</code></a> won't return a summary score.</td>\\n</tr>\\n</tbody>\\n</table>\\n<h3>Format definition add-ons</h3>\\n<p>A YAML file, that must exist in a folder called <code class=\\\"language-none\\\">formats</code> in the root of the add-on package (e.g. <code class=\\\"language-none\\\">formats/my_format.yaml</code>).</p>\\n<p>The following keys are supported for format add-ons:</p>\\n<table>\\n<thead>\\n<tr>\\n<th>Key</th>\\n<th>Required</th>\\n<th>Description</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td><code class=\\\"language-none\\\">'name'</code></td>\\n<td>Yes</td>\\n<td>A string used to refer to this format (must be unique!)</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'functions'</code></td>\\n<td>Yes</td>\\n<td>Dictionary of named functions for use with this format. The named methods are key-value pairs where the key is the function name, and the value is a string describing how the function can be imported with Python. For example, <code class=\\\"language-none\\\">create: &quot;object_map.create_empty&quot;</code> declares a function called <code class=\\\"language-none\\\">'create'</code> that is imported via <code class=\\\"language-none\\\">from object_map import create_empty</code>. Likewise <code class=\\\"language-none\\\">&quot;object_map.submodule.validate&quot;</code> translates to <code class=\\\"language-none\\\">from object_map.submodule import validate</code>. See below for the list of functions expected for format definitions.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'description'</code></td>\\n<td>No</td>\\n<td>A string describing what the format is and how it works. Should be included if you want users to understand what your format is supposed to capture.</td>\\n</tr>\\n</tbody>\\n</table>\\n<p>Format definitions expect the following named functions:</p>\\n<table>\\n<thead>\\n<tr>\\n<th>Name</th>\\n<th>Signature</th>\\n<th>Usage</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td><code class=\\\"language-none\\\">'create'</code></td>\\n<td><code class=\\\"language-none\\\">fn() -&gt; dict</code></td>\\n<td>Function that returns an empty instance of this format. As much as possible should be filled in to make it easy for users to create valid instances (especially when a format is used for results).</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'validate'</code></td>\\n<td><code class=\\\"language-none\\\">fn(dict: instance) -&gt; None</code></td>\\n<td>Takes a proposed <code class=\\\"language-none\\\">instance</code> of this format and validates whether it meets the requirements. Will typically use a series of assert statements to confirm fields are valid.</td>\\n</tr>\\n</tbody>\\n</table>\\n<h3>Ground truth add-ons</h3>\\n<p>A JSON file, that must exist in a folder called <code class=\\\"language-none\\\">ground_truths</code> in the root of the add-on package (e.g. <code class=\\\"language-none\\\">ground_truths/my_ground_truth.json</code>).</p>\\n<p>The following keys are supported for ground truth add-ons:</p>\\n<table>\\n<thead>\\n<tr>\\n<th>Key</th>\\n<th>Required</th>\\n<th>Description</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td><code class=\\\"language-none\\\">'environment'</code></td>\\n<td>Yes</td>\\n<td>A dictionary containing the definition data for the ground truth's reference environment. The data in this field should be a direct copy of an environment add-on.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'format'</code></td>\\n<td>Yes</td>\\n<td>A dictionary containing the definition data for the ground truth's format. The data in this field should be a direct copy of a format definition add-on.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'ground_truth'</code></td>\\n<td>Yes</td>\\n<td>A valid instance of the format described by the <code class=\\\"language-none\\\">'format'</code> field. This is where your actual ground truth data should be stored.</td>\\n</tr>\\n</tbody>\\n</table>\\n<p>A lot of these keys should be copied from other valid definitions. Please see the <code class=\\\"language-none\\\">GroundTruthCreator</code> helper class in <a href=https://github.com/qcr/benchbot_eval>BenchBot Evaluation</a> for assistance in creating valid ground truths.</p>\\n<h3>Robot add-ons</h3>\\n<p>A YAML file, that must exist in a folder called <code class=\\\"language-none\\\">robots</code> in the root of the add-on package (e.g. <code class=\\\"language-none\\\">robots/my_robot.yaml</code>).</p>\\n<p>The following keys are supported for robot add-ons:</p>\\n<table>\\n<thead>\\n<tr>\\n<th>Key</th>\\n<th>Required</th>\\n<th>Description</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td><code class=\\\"language-none\\\">'name'</code></td>\\n<td>Yes</td>\\n<td>A string used to refer to this robot (must be unique!).</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'type'</code></td>\\n<td>Yes</td>\\n<td>A string describing the type of this robot (<code class=\\\"language-none\\\">'sim_unreal'</code> &amp; <code class=\\\"language-none\\\">'real'</code> are the only values currently used).</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'address'</code></td>\\n<td>Yes</td>\\n<td>A string for the address where a running <a href=https://github.com/qcr/benchbot_robot_controller>BenchBot Robot Controller</a> can be accessed (e.g. <code class=\\\"language-none\\\">'localhost:10000'</code>)</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'global_frame'</code></td>\\n<td>Yes</td>\\n<td>The name of the global TF frame. All poses reported by the <a href=https://github.com/qcr/benchbot_api>BenchBot API</a> will be with respect to this frame.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'robot_frame'</code></td>\\n<td>Yes</td>\\n<td>The name of the robot's TF frame.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'poses'</code></td>\\n<td>Yes</td>\\n<td>A list of named poses that this robot provides. This list of poses will be available in observations provided by the <a href=https://github.com/qcr/benchbot_api>BenchBot API</a>.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'start_cmds'</code></td>\\n<td>Yes</td>\\n<td>A list of commands describing how to start the robot (this will often include the simulator). The commands will be run in parallel, and executed via <code class=\\\"language-none\\\">bash -c '&lt;your_command_string&gt;'</code></td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'connections'</code></td>\\n<td>Yes</td>\\n<td>A dictionary of connections that your robot makes available to the BenchBot ecosystem. The name of the key-value pair is important, and should follow the recommendations provided on standard channels in the <a href=https://github.com/qcr/benchbot_api>BenchBot API documentation</a>. A description of connection definitions is provided below.</td>\\n</tr>\\n</tbody>\\n</table>\\n<p>Connections are the lifeblood of interaction between BenchBot and robot platforms. They are defined by named entries, with the following fields:</p>\\n<table>\\n<thead>\\n<tr>\\n<th>Key</th>\\n<th>Required</th>\\n<th>Description</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td><code class=\\\"language-none\\\">'connection'</code></td>\\n<td>Yes</td>\\n<td>Connection type string, used by the <a href=https://github.com/qcr/benchbot_robot_controller>BenchBot Robot Controller</a>. Supported values are <code class=\\\"language-none\\\">'api_to_ros'</code> (used for actions), <code class=\\\"language-none\\\">'ros_to_api'</code> (used for observations), and <code class=\\\"language-none\\\">'roscache_to_api'</code> (special value used for caching observation values).</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'ros_topic'</code></td>\\n<td>Yes</td>\\n<td>Topic name for the ROS side of the connection.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'ros_type'</code></td>\\n<td>Yes</td>\\n<td>Topic type for the ROS side of the connection.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'callback_api'</code></td>\\n<td>No</td>\\n<td>A callback that is run on the HTTP encoded data received / sent on the API end of the connection. It takes in data, and returns transformed data based on the callback's action. Callbacks are specified by a string denoting how the callback can be accessed (e.g. <code class=\\\"language-none\\\">'api_callbacks.convert_to_rgb</code> = <code class=\\\"language-none\\\">from api_callbacks import convert_to_rgb</code>). No data transformation occurs if no callback is provided.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'callback_ros'</code></td>\\n<td>No</td>\\n<td>A callback that is run on the ROS data received / sent on the robot controller end of the connection. It takes in data and a reference to the robot controller. <code class=\\\"language-none\\\">'api_to_ros'</code> connections use this data to act on the robot, whereas <code class=\\\"language-none\\\">'ros_to_api'</code> connections turn this data into a dictionary that can be serialised into HTTP traffic. Callbacks are specified by a string denoting how the callback can be accessed (e.g. <code class=\\\"language-none\\\">'api_callbacks.convert_to_rgb</code> = <code class=\\\"language-none\\\">from api_callbacks import convert_to_rgb</code>). No action occurs at the ROS level if no callback is provided.</td>\\n</tr>\\n</tbody>\\n</table>\\n<h3>Task add-ons</h3>\\n<p>A YAML file, that must exist in a folder called <code class=\\\"language-none\\\">tasks</code> in the root of the add-on package (e.g. <code class=\\\"language-none\\\">tasks/my_task.yaml</code>).</p>\\n<p>The following keys are supported for task add-ons:</p>\\n<table>\\n<thead>\\n<tr>\\n<th>Key</th>\\n<th>Required</th>\\n<th>Description</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td><code class=\\\"language-none\\\">'name'</code></td>\\n<td>Yes</td>\\n<td>A string used to refer to this task (must be unique!).</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'actions'</code></td>\\n<td>Yes</td>\\n<td>A list of named connections to be provided as actions through the <a href=https://github.com/qcr/benchbot_api>BenchBot API</a>. Running this task will fail if the robot doesn't provide these named connections.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'observations'</code></td>\\n<td>Yes</td>\\n<td>A list of named connections to be provided as observations through the <a href=https://github.com/qcr/benchbot_api>BenchBot API</a>. Running this task will fail if the robot doesn't provide these named connections.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'results_format'</code></td>\\n<td>Yes</td>\\n<td>A string naming the format for results. The format must be installed, as <a href=https://github.com/qcr/benchbot_api>BenchBot API</a> will use the format's functions to provide the user with empty results.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'description'</code></td>\\n<td>No</td>\\n<td>A string describing what the task is, and how it works. Should be included if you want users to understand what challenges your task is trying to capture.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'type'</code></td>\\n<td>No</td>\\n<td>A string describing what robot / environment types are valid for this task. For example, a task that provides a magic image segmentation sensor would only be made available for <code class=\\\"language-none\\\">'sim_unreal'</code> type robots / environments.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">'scene_count'</code></td>\\n<td>No</td>\\n<td>Integer representing the number of scenes (i.e. environment variations required for a task). If omitted, a default value of 1 will be used for the task.</td>\\n</tr>\\n</tbody>\\n</table>\\n\",\"name\":\"BenchBot Add-ons Manager\",\"type\":\"code\",\"url\":\"https://github.com/qcr/benchbot_addons\",\"src\":\"/content/benchbot/benchbot-addons.md\",\"id\":\"benchbot-addons\",\"image_position\":\"center\",\"image\":\"/_next/static/gifs/8ef442bbcf06f5d9f4a4bd553bd28212.jpg\",\"_image\":\"/_next/static/gifs/8ef442bbcf06f5d9f4a4bd553bd28212.webm\"},{\"content\":\"<p><strong>NOTE: this software is part of the BenchBot software stack, and not intended to be run in isolation (although it can be installed independently through pip and run on results files if desired). For a working BenchBot system, please install the BenchBot software stack by following the instructions <a href=https://github.com/qcr/benchbot>here</a>.</strong></p>\\n<h1>BenchBot Evaluation</h1>\\n<p>BenchBot Evaluation is a library of functions used to call evaluation methods. These methods are installed through the <a href=https://github.com/qcr/benchbot-addons>BenchBot Add-ons Manager</a>, and evaluate the performance of a BenchBot system against the metric. The easiest way to use this module is through the helper scripts provided with the <a href=https://github.com/qcr/benchbot>BenchBot software stack</a>.</p>\\n<h2>Installing and performing evaluation with BenchBot Evaluation</h2>\\n<p>BenchBot Evaluation is a Python package, installable with pip. Run the following in the root directory of where this repository was cloned:</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">u@pc:~$ pip install .\\n</code></pre>\\n<p>Although evaluation is best run from within the BenchBot software stack, it can be run in isolation if desired. The following code snippet shows how to perform evaluation with the <code class=\\\"language-none\\\">'omq'</code> method from Python:</p>\\n<pre class=\\\"language-python\\\"><code class=\\\"language-python\\\"><span class=\\\"token keyword\\\">from</span> benchbot_eval<span class=\\\"token punctuation\\\">.</span>evaluator <span class=\\\"token keyword\\\">import</span> Evaluator<span class=\\\"token punctuation\\\">,</span> Validator\\n\\nValidator<span class=\\\"token punctuation\\\">(</span>results_file<span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">.</span>validate_results_data<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span>\\nEvaluator<span class=\\\"token punctuation\\\">(</span><span class=\\\"token string\\\">'omq'</span><span class=\\\"token punctuation\\\">,</span> scores_file<span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">.</span>evaluate<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span>\\n</code></pre>\\n<p>This prints the final scores to the screen and saves them to a file using the following inputs:</p>\\n<ul>\\n<li><code class=\\\"language-none\\\">results_file</code>: points to the JSON file with the output from your experiment</li>\\n<li><code class=\\\"language-none\\\">ground_truth_folder</code>: the directory containing the relevant environment ground truth JSON files</li>\\n<li><code class=\\\"language-none\\\">save_file</code>: is where final scores are to be saved</li>\\n</ul>\\n<h2>How add-ons interact with BenchBot Evaluation</h2>\\n<p>Two types of add-ons are used in the BenchBot Evaluation process: format definitions, and evaluation methods. An evaluation method's YAML file defines what results formats and ground truth formats the method supports. This means:</p>\\n<ul>\\n<li>this package requires installation of the <a href=https://github.com/qcr/benchbot_addons>BenchBot Add-ons Manager</a> for interacting with installed add-ons</li>\\n<li>the <code class=\\\"language-none\\\">results_file</code> must be a valid instance of a supported format</li>\\n<li>there must be a valid ground truth available in a supported format, for the same environment as the results</li>\\n<li>validity is determined by the format-specific validation function described in the format's YAML file</li>\\n</ul>\\n<p>Please see the <a href=https://github.com/qcr/benchbot_addons>BenchBot Add-ons Manager's documentation</a> for further details on the different types of add-ons.</p>\\n<h2>Creating valid results and ground truth files</h2>\\n<p>The <a href=https://github.com/qcr/benchbot>BenchBot software stack</a> includes tools to assist in creating results and ground truth files:</p>\\n<ul>\\n<li>\\n<p><strong>results:</strong> are best created using the <code class=\\\"language-none\\\">empty_results()</code> and <code class=\\\"language-none\\\">results_functions()</code> helper functions in the <a href=https://github.com/qcr/benchbot_api>BenchBot API</a>, which automatically populate metadata for your current task and environment.</p>\\n</li>\\n<li>\\n<p><strong>ground truths:</strong> this package includes a <code class=\\\"language-none\\\">GroundTruthCreator</code> class to aid in creating ground truths of a specific format, for a specific environment. Example use includes:</p>\\n<pre class=\\\"language-python\\\"><code class=\\\"language-python\\\"><span class=\\\"token keyword\\\">from</span> benchbot_eval<span class=\\\"token punctuation\\\">.</span>ground_truth_creator <span class=\\\"token keyword\\\">import</span> GroundTruthCreator\\n\\ngtc <span class=\\\"token operator\\\">=</span> GroundTruthCreator<span class=\\\"token punctuation\\\">(</span><span class=\\\"token string\\\">'object_map_ground_truth'</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token string\\\">'miniroom:1'</span><span class=\\\"token punctuation\\\">)</span>\\ngt <span class=\\\"token operator\\\">=</span> gtc<span class=\\\"token punctuation\\\">.</span>create_empty<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">;</span>\\n<span class=\\\"token keyword\\\">print</span><span class=\\\"token punctuation\\\">(</span>gtc<span class=\\\"token punctuation\\\">.</span>functions<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">)</span>  <span class=\\\"token comment\\\"># ['create', 'create_object']</span>\\ngt<span class=\\\"token punctuation\\\">[</span><span class=\\\"token string\\\">'ground_truth'</span><span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">[</span><span class=\\\"token string\\\">'objects'</span><span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">[</span><span class=\\\"token number\\\">0</span><span class=\\\"token punctuation\\\">]</span> <span class=\\\"token operator\\\">=</span> gtc<span class=\\\"token punctuation\\\">.</span>functions<span class=\\\"token punctuation\\\">(</span><span class=\\\"token string\\\">'create_object'</span><span class=\\\"token punctuation\\\">)</span>\\n</code></pre>\\n</li>\\n</ul>\\n\",\"name\":\"BenchBot Evaluation Tools\",\"type\":\"code\",\"url\":\"https://github.com/qcr/benchbot_eval\",\"src\":\"/content/benchbot/benchbot-eval.md\",\"id\":\"benchbot-eval\",\"image_position\":\"center\",\"image\":\"/_next/static/images/qcr_logo_light_filled-b2f2ba81b0ef111afdf9fa7264fb4adf.png\"},{\"content\":\"<p><strong>NOTE: this software is part of the BenchBot software stack, and not intended to be run in isolation. For a working BenchBot system, please install the BenchBot software stack by following the instructions <a href=https://github.com/qcr/benchbot>here</a>.</strong></p>\\n<h1>BenchBot Supervisor</h1>\\n<p align=\\\"center\\\"><img alt=\\\"benchbot_supervisor\\\" src=\\\"/_next/static/images/benchbot_supervisor-308d8e63428bf85c3824123d688af972.jpg\\\" width=\\\"60%\\\"/></p>\\n<p>The BenchBot Supervisor is a HTTP server facilitating communication between user-facing interfaces like the <a href=https://github.com/qcr/benchbot_api>BenchBot API</a>, and the low-level robot components like <a href=https://github.com/qcr/benchbot_simulator>BenchBot Simulator</a> or real robots. Communication is typically routed through a <a href=https://github.com/qcr/benchbot_robot_controller>BenchBot Robot Controller</a>, which provides automated process management for low-level components and wraps all ROS communications.</p>\\n<h2>Installing and running the BenchBot Supervisor</h2>\\n<p>BenchBot Supervisor is a Python package containing a <code class=\\\"language-none\\\">Supervisor</code> class that wraps a HTTP server for both upstream and downstream communication. Install by running the following in the root directory of where this repository was cloned:</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">u@pc:~$ pip install .\\n</code></pre>\\n<p>Once installed, the Python class can be used as follows:</p>\\n<pre class=\\\"language-python\\\"><code class=\\\"language-python\\\"><span class=\\\"token keyword\\\">from</span> benchbot_supervisor <span class=\\\"token keyword\\\">import</span> Supervisor\\n\\ns <span class=\\\"token operator\\\">=</span> Supervisor<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">.</span><span class=\\\"token punctuation\\\">.</span><span class=\\\"token punctuation\\\">.</span>args<span class=\\\"token punctuation\\\">.</span><span class=\\\"token punctuation\\\">.</span><span class=\\\"token punctuation\\\">.</span><span class=\\\"token punctuation\\\">)</span>\\ns<span class=\\\"token punctuation\\\">.</span>run<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span>\\n</code></pre>\\n<p>The following parameters are typically required for a useful instantiation of the supervisor:</p>\\n<ul>\\n<li><strong>addons_path</strong>: path to installed <a href=https://github.com/qcr/benchbot_addons>BenchBot add-ons</a> (is the same as the directory where <code class=\\\"language-none\\\">manager.py</code> can be found)</li>\\n<li><strong>task_name</strong>: string matching the <code class=\\\"language-none\\\">'name'</code> field of an installed task</li>\\n<li><strong>robot_name</strong>: string matching the <code class=\\\"language-none\\\">'name'</code> field of an installed robot</li>\\n<li><strong>environment_names</strong>: list of strings, each matching the <code class=\\\"language-none\\\">'name':'variant'</code> field combination of an installed environment (the <code class=\\\"language-none\\\">'name'</code> must be the same for all environments in the list)</li>\\n<li><strong>port</strong>: select a different port than the default (10000)</li>\\n</ul>\\n<p>The module can also be executed directly, which makes the passing of arguments from the command line simple (see <code class=\\\"language-none\\\">python -m benchbot_supervisor --help</code> for argument details):</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">u@pc:~$ python -m benchbot_supervisor ...args...\\n</code></pre>\\n<p>As an example, the below command runs the supervisor for a scene change detection task, where active control is employed with ground truth localisation on a simulated Carter robot, and environments miniroom:1 and miniroom:5 are used:</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">u@pc:~$ python -m benchbot_supervisor \\\\\\n    --task-name scd:active:ground_truth \\\\\\n    --robot-name carter \\\\\\n    --environment-names miniroom:1,miniroom:5\\n</code></pre>\\n<h2>Employing task, robot, and environment configurations</h2>\\n<p>The BenchBot Supervisor requires configuration details for the selected tasks, robots, and environments. It uses these details to manage each of the system components, like API interaction and control of the simulator / real robot. Configuration details are provided by YAML files, which are referenced via their <code class=\\\"language-none\\\">'name'</code> field as shown above.</p>\\n<p>The <a href=https://github.com/qcr/benchbot_addons>BenchBot Add-ons Manager</a> manages the installation of, and access to, these files. See the documentation there for further details on configuration files. All you need to do to use add-ons with the supervisor is provide the location via the <code class=\\\"language-none\\\">'addons_path'</code> argument.</p>\\n<h2>Interacting with the BenchBot Supervisor</h2>\\n<p>The supervisor includes a RESTful HTTP API for all interaction with a user-facing API. The RESTful API includes the following commands:</p>\\n<table>\\n<thead>\\n<tr>\\n<th>Request Route</th>\\n<th>Response Format</th>\\n<th>Description</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td><code class=\\\"language-none\\\">/</code></td>\\n<td><pre class=\\\"language-none\\\">Hello, I am the BenchBot supervisor</pre></td>\\n<td>Arbitrary response to confirm connection.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">/config/</code></td>\\n<td><pre class=\\\"language-none\\\">{<br> ...<br> 'param_name': param_value,<br> ...<br>}</pre></td>\\n<td>Dictionary containing containing parameter values for all of supervisor configuration settings. Keys correspond to parameter name, &amp; values to parameter value.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">/config/&lt;config&gt;</code></td>\\n<td><code class=\\\"language-none\\\">config_value</code></td>\\n<td>Directly retrieve the value of a supervisor configuration parameter with name <code class=\\\"language-none\\\">'config'</code>. Returns <code class=\\\"language-none\\\">param_value</code> of <code class=\\\"language-none\\\">'config'</code>.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">/connections/&lt;connection&gt;</code></td>\\n<td><code class=\\\"language-none\\\">dict</code></td>\\n<td>Returns the response of the connection (e.g. an <code class=\\\"language-none\\\">image_rgb</code> connection would return the image) as a <code class=\\\"language-none\\\">dict</code>. Format &amp; style of the <code class=\\\"language-none\\\">dict</code> is defined by the methods described above in &quot;Defining environment, robot, &amp; task configurations&quot;.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">/results_functions/</code></td>\\n<td><code class=\\\"language-none\\\">list</code></td>\\n<td>Returns a list of the results function names that can be remotely executed via the route below.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">/results_functions/&lt;function&gt;</code></td>\\n<td><code class=\\\"language-none\\\">dict</code></td>\\n<td>Calls results function with name <code class=\\\"language-none\\\">'function'</code>, and returns the result of the function call in the response's JSON body.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">/robot/</code></td>\\n<td><pre class=\\\"language-none\\\">Hello, I am the BenchBot robot controller</pre></td>\\n<td>Arbitrary response confirming a robot controller is available.</td>\\n</tr>\\n<tr>\\n<td><code class=\\\"language-none\\\">/robot/&lt;command&gt;</code></td>\\n<td><code class=\\\"language-none\\\">dict</code></td>\\n<td>Passes the command <code class=\\\"language-none\\\">command</code> down to a running robot controller manager. See <a href=https://github.com/qcr/benchbot_robot_controller>BenchBot Robot Controller</a> for documentation of supported commands &amp; expected responses.</td>\\n</tr>\\n</tbody>\\n</table>\\n\",\"name\":\"BenchBot Backend Supervisor\",\"type\":\"code\",\"url\":\"https://github.com/qcr/benchbot_supervisor\",\"image_position\":\"center 0%\",\"src\":\"/content/benchbot/benchbot-supervisor.md\",\"id\":\"benchbot-supervisor\",\"image\":\"/_next/static/images/benchbot_supervisor-308d8e63428bf85c3824123d688af972.jpg\"},{\"content\":\"<p><strong>NOTE: this software is part of the BenchBot software stack, and not intended to be run in isolation. For a working BenchBot system, please install the BenchBot software stack by following the instructions <a href=https://github.com/qcr/benchbot>here</a>.</strong></p>\\n<h1>BenchBot Simulator</h1>\\n<p><video autoplay loop poster=\\\"/_next/static/gifs/ec1857995c55d26bf6712cf7c339dbae.jpg\\\"><source src=\\\"/_next/static/gifs/ec1857995c55d26bf6712cf7c339dbae.webm\\\" type=\\\"video/webm\\\"/></video></p>\\n<p>The BenchBot Simulator is an extension of the <a href=\\\"https://developer.nvidia.com/isaac-sdk\\\">NVIDIA Isaac SDK</a> that establishes ROS communications to a running instance of an Unreal Engine-based <a href=\\\"https://developer.nvidia.com/isaac-sim\\\">NVIDIA Isaac SIM</a>. BenchBot simulator is explicitly linked to version 2019.2 of Isaac, the last version with direct support for the Unreal Engine-based simulator. In the future we intend to move to <a href=\\\"https://developer.nvidia.com/nvidia-omniverse\\\">Omniverse</a>, NVIDIA's new 3D production pipeline with RTX support.</p>\\n<p>BenchBot simulator provides direct access to the following data on the simulated robot. Access is via ROS on the topic provided in brackets:</p>\\n<ul>\\n<li>RGB images from the top camera (<code class=\\\"language-none\\\">/camera/color/image_raw</code>)</li>\\n<li>Camera information for RGB images from the top camera (<code class=\\\"language-none\\\">/camera/color/camera_info</code>)</li>\\n<li>Depth images from the top camera (<code class=\\\"language-none\\\">/camera/depth/image_raw</code>)</li>\\n<li>Camera information for depth images from the top camera (<code class=\\\"language-none\\\">/camera/depth/camera_info</code>)</li>\\n<li>Laserscan data from the LiDAR (<code class=\\\"language-none\\\">/scan_laser</code>)</li>\\n<li>Raw odometry data (<code class=\\\"language-none\\\">/odom</code>)</li>\\n<li>A full transform tree (<code class=\\\"language-none\\\">/tf</code>)</li>\\n</ul>\\n<p>Direct control of the robot is also facilitated via:</p>\\n<ul>\\n<li>3D twist velocities sent to topic <code class=\\\"language-none\\\">/cmd_vel</code></li>\\n</ul>\\n<h2>Installing BenchBot Simulator</h2>\\n<p><strong>Please see the note at the top of the page; installation of BenchBot Simulator in isolation is generally not what you want!</strong></p>\\n<p>If you are sure you need to install the simulator in isolation, the following steps should be sufficient. Note there are a significant number of driver &amp; software requirements for your system:</p>\\n<ol>\\n<li>\\n<p>Download version 2019.2 of the Isaac SDK from the <a href=\\\"https://developer.nvidia.com/isaac/downloads\\\">NVIDIA site</a>. If creating your own environments, also download version 2019.2 of Isaac SIM (<em>not</em> NavSim). You will have to create / sign in to an NVIDIA developer account, and look in the &quot;Archive&quot; drop down for version 2019.2.</p>\\n</li>\\n<li>\\n<p>Either setup your system with Isaac SIM, or download our environments:</p>\\n<p>a) Follow the <a href=\\\"https://docs.nvidia.com/isaac/isaac_sim/setup.html\\\">install instructions</a> for Isaac SIM to get Unreal Engine (through IsaacSimProject) running on your system. You will have to link Epic Games to your Github account to get access.</p>\\n<p>b) Download our latest environments: <a href=https://github.com/benchbot-addons/envs_isaac_develop/blob/master/.remote>Isaac Development Environments</a>, and <a href=https://github.com/benchbot-addons/envs_isaac_challenge/blob/master/.remote>Isaac Challenge Environments</a></p>\\n</li>\\n<li>\\n<p>Install the Isaac SDK by following the instructions <a href=\\\"https://docs.nvidia.com/isaac/archive/2019.2/doc/setup.html\\\">here</a>.</p>\\n</li>\\n<li>\\n<p>Clone the BenchBot simulator, apply our patches to the installed Isaac SDK, &amp; build the simulator using the Bazel wrapper script (ensure the environment variable <code class=\\\"language-none\\\">ISAAC_SDK_PATH</code> is set to where you installed Isaac SDK):</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">u@pc:~$ git clone https://github.com/qcr/benchbot_simulator &amp;&amp; cd benchbot_simulator\\nu@pc:~$ .isaac_patches/apply_patches\\nu@pc:~$ ./bazelros build //apps/benchbot_simulator\\n</code></pre>\\n</li>\\n</ol>\\n<h2>Running BenchBot Simulator</h2>\\n<p>The BenchBot simulator interface is run alongside a running Isaac Unreal Engine Simulator. To get both components running:</p>\\n<ol>\\n<li>\\n<p>Start the Unreal Engine Simulator, either via our precompiled environments or the IsaacSimProject Unreal Editor:</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">u@pc:~$ ./IsaacSimProject &lt;map_name&gt; \\\\\\n    -isaac_sim_config_json='&lt;path_to_isaac&gt;/apps/carter/carter_sim/bridge_config/carter_full.json' \\\\\\n    -windowed -ResX=960 -ResY=540 -vulkan -game\\n</code></pre>\\n</li>\\n<li>\\n<p>Launch BenchBot simulator Isaac application (you first need to hardcode the pose unfortunately...):</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">u@pc:~$ START_POSE=&lt;robot_start_pose&gt; \\\\\\n    sed -i &quot;0,/\\\\&quot;pose\\\\&quot;:/{s/\\\\(\\\\&quot;pose\\\\&quot;: \\\\)\\\\(.*\\\\)/\\\\1$START_POSE}&quot; \\\\\\n    &lt;path_to_isaac&gt;/apps/carter/carter_sim/bridge_config/carter_full_config.json\\nu@pc:~$ ./bazelros run //apps/benchbot_simulator\\n</code></pre>\\n</li>\\n</ol>\\n<p>At this point you will have a running Isaac Unreal Engine Simulator, with sensorimotor data available from the robot in ROS!</p>\\n<h2>Using BenchBot Simulator with the BenchBot Robot Controller</h2>\\n<p>The <a href=https://github.com/qcr/benchbot_robot_controller>BenchBot Robot Controller</a> is a wrapping ROS / HTTP hybrid script that manages running robots and their required subprocesses. See the <code class=\\\"language-none\\\">carter_sim.yaml</code> configuration in the <a href=https://github.com/qcr/benchbot_supervisor>BenchBot Supervisor</a> for an example configuration of how to run BenchBot Simulator through the Robot Controller.</p>\\n\",\"name\":\"BenchBot Simulator (Isaac)\",\"type\":\"code\",\"url\":\"https://github.com/qcr/benchbot_simulator\",\"src\":\"/content/benchbot/benchbot-simulator.md\",\"id\":\"benchbot-simulator\",\"image_position\":\"center\",\"image\":\"/_next/static/gifs/ec1857995c55d26bf6712cf7c339dbae.jpg\",\"_image\":\"/_next/static/gifs/ec1857995c55d26bf6712cf7c339dbae.webm\"}],\"datasets\":[{\"content\":\"<p>The Semantic Scene Understanding (development) is a set of Unreal Engine environments for use with the <a href=\\\"http://benchbot.org\\\">BenchBot software stack</a> in the <a href=\\\"https://evalai.cloudcv.org/web/challenges/challenge-page/625/overview\\\">ACRV Semantic Scene Understanding Challenge</a>. A collage of the robot starting position for each of the environments is shown below:</p>\\n<p><img src=\\\"/_next/static/images/develop_envs-c77d4d986222aed06900114eb00b4663.png\\\" alt=\\\"Robot starting positions in environments from the semantic scene understanding (development) dataset\\\"></p>\\n<p>Features of the dataset include:</p>\\n<ul>\\n<li>a total of 10 different environments</li>\\n<li>2 different places: a small apartment room, and a Scandinavian house</li>\\n<li>each place has 5 different variations</li>\\n<li>between variations there are changes in lighting, time of day, starting location, robot trajectory, and object placements</li>\\n</ul>\\n<p>For more details of the dataset, challenge, BenchBot, and how it all fits together, please see our summary video below:</p>\\n<div class=\\\"embedded-block block-embed-service-youtube\\\"><iframe type=\\\"text/html\\\" src=\\\"//www.youtube.com/embed/jQPkV29KFvI\\\" frameborder=\\\"0\\\" width=\\\"640\\\" height=\\\"390\\\" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe></div>\\n\",\"name\":\"Semantic Scene Understanding (development)\",\"type\":\"dataset\",\"url\":\"https://cloudstor.aarnet.edu.au/plus/s/1MNBnLZan8X95qb/download\",\"size\":\"8.4GB\",\"src\":\"/content/benchbot/benchbot-develop.md\",\"id\":\"benchbot-develop\",\"image_position\":\"center\",\"image\":\"/_next/static/images/develop_envs-c77d4d986222aed06900114eb00b4663.png\"},{\"content\":\"<p>The Semantic Scene Understanding (challenge) is a set of Unreal Engine environments for use with the <a href=\\\"http://benchbot.org\\\">BenchBot software stack</a> in the <a href=\\\"https://evalai.cloudcv.org/web/challenges/challenge-page/625/overview\\\">ACRV Semantic Scene Understanding Challenge</a>. A collage of the robot starting position for each of the environments is shown below:</p>\\n<p><img src=\\\"/_next/static/images/challenge_envs-1bb1e48b62de2cdd9e3540368bf44c0f.png\\\" alt=\\\"Robot starting positions in environments from the semantic scene understanding (challenge) dataset\\\"></p>\\n<p>Features of the dataset include:</p>\\n<ul>\\n<li>a total of 15 different environments</li>\\n<li>3 different places: a luxurious penthouse apartment, an office workspace and a large corporate building</li>\\n<li>each place has 5 different variations</li>\\n<li>between variations there are changes in lighting, time of day, starting location, robot trajectory, and object placements</li>\\n</ul>\\n<p>For more details of the dataset, challenge, BenchBot, and how it all fits together, please see our summary video below:</p>\\n<div class=\\\"embedded-block block-embed-service-youtube\\\"><iframe type=\\\"text/html\\\" src=\\\"//www.youtube.com/embed/jQPkV29KFvI\\\" frameborder=\\\"0\\\" width=\\\"640\\\" height=\\\"390\\\" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe></div>\\n\",\"name\":\"Semantic Scene Understanding (challenge)\",\"type\":\"dataset\",\"url\":\"https://cloudstor.aarnet.edu.au/plus/s/gRg5N85PZYRcI2c/download\",\"size\":\"7.5GB\",\"src\":\"/content/benchbot/benchbot-challenge.md\",\"id\":\"benchbot-challenge\",\"image_position\":\"center\",\"image\":\"/_next/static/images/challenge_envs-1bb1e48b62de2cdd9e3540368bf44c0f.png\"}],\"feature\":1,\"src\":\"/content/benchbot/collection.md\",\"image_position\":\"100% center\",\"image\":\"/_next/static/gifs/0f460afe63fb093a8b44efcd5c652cf8.jpg\"},{\"content\":\"<p>The Human Cues for Robot Navigation ARC Discovery Project (DP140103216) investigated how a robot can navigate using the same navigation cues humans use when navigating built environments. Types of navigation cues targeted include labels, directional signs, signboards, maps &amp; floor plans, navigational gestures, and spoken directions &amp; descriptions. The main contribution from this work is the abstract map, a navigational tool that allows a robot to employ symbolic spatial information in its navigation of unseen spaces.</p>\\n\",\"name\":\"Human Cues for Robot Navigation\",\"type\":\"collection\",\"url\":\"https://btalb.github.io/abstract_map\",\"code\":[{\"content\":\"<p align=center><strong>~ Please see the <a href=\\\"https://btalb.github.io/abstract_map/\\\">abstract map site</a> for further details about the research publication ~</strong></p>\\n<h1>The Abstract Map - using symbols to navigate</h1>\\n<p><img src=\\\"/_next/static/images/abstract_map_in_action-261a2f7eea1f79411b48203e72995f14.png\\\" alt=\\\"The abstract map in action\\\"></p>\\n<p>This repository provides the implementation of the abstract map used in our <a href=\\\"https://doi.org/10.1109/TCDS.2020.2993855\\\">IEEE TCDS journal</a>. The implementation, done in Python, includes the following features:</p>\\n<ul>\\n<li>a novel dynamics-based malleable spatial model for imagining unseen spaces from symbols (which includes simulated springs, friction, repulsive forces, &amp; collision models)</li>\\n<li>a visualiser &amp; text-based commentator for introspection of your navigation system (both shown in videos on the <a href=\\\"https://btalb.github.io/abstract_map/\\\">repository website</a>)</li>\\n<li>easy ROS bindings for getting up &amp; running in simulation or on a real robot</li>\\n<li>tag readers &amp; interpreters for extracting symbolic spatial information from <a href=\\\"http://wiki.ros.org/apriltag_ros\\\">AprilTags</a></li>\\n<li>configuration files for the zoo experiments performed on GP-S11 of QUT's Gardens Point campus (see <a href=\\\"https://doi.org/10.1109/TCDS.2020.2993855\\\">the paper</a> for further details)</li>\\n<li>serialisation methods for passing an entire abstract map state between machines, or saving to file</li>\\n</ul>\\n<p>Please see our other related repositories for further resources, and related parts of the abstract map studies:</p>\\n<ul>\\n<li><strong><a href=https://github.com/btalb/abstract_map_simulator>abstract_map_simulator</a>:</strong> all of the resources needed to run a full 2D simulation of the zoo experiments performed on GP-S11 of our Gardens Point campus at QUT</li>\\n<li><strong><a href=https://github.com/btalb/abstract_map_app>abstract_map_app</a>:</strong> mobile Android application used by human participants to complete navigation tasks as part of the zoo experiments (the app used the on-board camera to scan tags &amp; present the mapped symbolic spatial information in real time)</li>\\n</ul>\\n<h2>Getting up &amp; running with the abstract map</h2>\\n<p><em>Note: if you wish to run this in simulation (significantly easier than on a real robot platform), you will also need the <a href=https://github.com/btalb/abstract_map_simulator>abstract_map_simulator</a> package</em></p>\\n<h3>Setting up your environment</h3>\\n<p>Clone the repo &amp; install all Python dependencies:</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">git clone https://github.com/btalb/abstract_map\\npip install -r abstract_map/requirements.txt\\n</code></pre>\\n<p>Add the new package to your ROS workspace at <code class=\\\"language-none\\\">&lt;ROS_WS&gt;/</code> by linking in the cloned repository:</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">ln -s &lt;LOCATION_REPO_WAS_CLONED_ABOVE&gt; &lt;ROS_WS&gt;/src/\\n</code></pre>\\n<p>Install all of the listed ROS dependencies, and build the package:</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">cd &lt;ROS_WS&gt;/src/\\nrosdep install abstract_map\\ncd &lt;ROS_WS&gt;\\ncatkin_make\\n</code></pre>\\n<h3>Running the Zoo experiments</h3>\\n<p>Start the experiment (this will try &amp; launch the 2D simulation back-end by default, so make sure you have that installed if you are using it):</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">roslaunch abstract_map experiment.launch\\n</code></pre>\\n<p><em>(please see <a href=https://github.com/btalb/abstract_map_simulator/issues/1>this issue</a> for details if you get the spam of TF based errors... which probably shouldn't even be errors... )</em></p>\\n<p>In another terminal, start the hierarchy publisher to give the abstract map the contextual symbolic spatial information to begin with:</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">rosrun abstract_map hierarchy_publisher\\n</code></pre>\\n<p>This will use the hierarchy available in <code class=\\\"language-none\\\">./experiments/zoo_hierarchy.xml</code> by default. Feel free to make your own if you would like to do different experiments.</p>\\n<p>Start the visualiser in preparation of beginning the experiment (pick either light or dark mode with one of the two commands):</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">rosrun abstract_map visualiser\\n</code></pre>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">rosrun abstract_map visualiser --dark\\n</code></pre>\\n<p><img src=\\\"/_next/static/images/abstract_map_light_vs_dark-ae93c3e7b8419b56719b5d876dd150f4.png\\\" alt=\\\"Visualise the abstract map with dark or light colours\\\"></p>\\n<p>Finally, start the abstract map with a goal, and watch it attempt to complete the navigation task:</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">roslaunch abstract_map abstract_map.launch goal:=Lion\\n</code></pre>\\n<p>If you want to manually drive the robot around and observe how the abstract map evolves over time, you can run the above command without a goal to start in &quot;observe mode&quot;.</p>\\n<h2>Acknowledgements &amp; Citing our work</h2>\\n<p>This work was supported by the Australian Research Council's Discovery Projects Funding Scheme under Project DP140103216. The authors are with the <a href=\\\"https://research.qut.edu.au/qcr/\\\">QUT Centre for Robotics</a>.</p>\\n<p>If you use this software in your research, or for comparisons, please kindly cite our work:</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">@ARTICLE{9091567,  \\n    author={B. {Talbot} and F. {Dayoub} and P. {Corke} and G. {Wyeth}},  \\n    journal={IEEE Transactions on Cognitive and Developmental Systems},   \\n    title={Robot Navigation in Unseen Spaces using an Abstract Map},   \\n    year={2020},  \\n    volume={},  \\n    number={},  \\n    pages={1-1},\\n    keywords={Navigation;Robot sensing systems;Measurement;Linguistics;Visualization;symbol grounding;symbolic spatial information;abstract map;navigation;cognitive robotics;intelligent robots.},\\n    doi={10.1109/TCDS.2020.2993855},\\n    ISSN={2379-8939},\\n    month={},}\\n}\\n</code></pre>\\n\",\"name\":\"Abstract Map (Python)\",\"type\":\"code\",\"url\":\"https://github.com/btalb/abstract_map\",\"src\":\"/content/human_cues/abstract-map.md\",\"id\":\"abstract-map\",\"image_position\":\"center\",\"image\":\"/_next/static/images/abstract_map_in_action-261a2f7eea1f79411b48203e72995f14.png\"},{\"content\":\"<p align=center><strong>~ Please see the <a href=\\\"https://btalb.github.io/abstract_map/\\\">abstract map site</a> for further details about the research publication ~</strong></p>\\n<h1>Using the Abstract Map in a 2D Stage simulation</h1>\\n<p><img src=\\\"/_next/static/images/abstract_map_simulation-8e1275a3c88423d73d8d661443eeefdf.png\\\" alt=\\\"2D Stage simulation with with simulated tags\\\"></p>\\n<p>Package contains everything needed to simulate the zoo experiments performed in our <a href=\\\"https://doi.org/10.1109/TCDS.2020.2993855\\\">IEEE TCDS journal</a>. The package includes:</p>\\n<ul>\\n<li>world &amp; launch files for a stage simulation of the GP-S11 environment on QUT's Gardens Point campus</li>\\n<li>a tool for creating simulated tags in an environment &amp; saving them to file,</li>\\n<li>launch &amp; config files for using the move_base navigation stack with gmapping to explore unseen simulated environments</li>\\n</ul>\\n<h2>Installing the abstract map simulator</h2>\\n<p><em>Note: this is just the simulator; to use the abstract map with the simulator please make sure you use the <a href=https://github.com/btalb/abstract_map>abstract_map</a> package</em></p>\\n<p>Clone the repo &amp; install all Python dependencies:</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">git clone https://github.com/btalb/abstract_map_simulator\\npip install -r abstract_map_simulator/requirements.txt\\n</code></pre>\\n<p>Add the new package to your ROS workspace at <code class=\\\"language-none\\\">&lt;ROS_WS&gt;/</code> by linking in the cloned repository:</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">ln -s &lt;LOCATION_REPO_WAS_CLONED_ABOVE&gt; &lt;ROS_WS&gt;/src/\\n</code></pre>\\n<p>Install all of the listed ROS dependencies, and build the package:</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">cd &lt;ROS_WS&gt;/src/\\nrosdep install abstract_map_simulator\\ncd &lt;ROS_WS&gt;\\ncatkin_make\\n</code></pre>\\n<h2>Acknowledgements &amp; Citing our work</h2>\\n<p>This work was supported by the Australian Research Council's Discovery Projects Funding Scheme under Project DP140103216. The authors are with the <a href=\\\"https://research.qut.edu.au/qcr/\\\">QUT Centre for Robotics</a>.</p>\\n<p>If you use this software in your research, or for comparisons, please kindly cite our work:</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">@ARTICLE{9091567,  \\n    author={B. {Talbot} and F. {Dayoub} and P. {Corke} and G. {Wyeth}},  \\n    journal={IEEE Transactions on Cognitive and Developmental Systems},   \\n    title={Robot Navigation in Unseen Spaces using an Abstract Map},   \\n    year={2020},  \\n    volume={},  \\n    number={},  \\n    pages={1-1},\\n    keywords={Navigation;Robot sensing systems;Measurement;Linguistics;Visualization;symbol grounding;symbolic spatial information;abstract map;navigation;cognitive robotics;intelligent robots.},\\n    doi={10.1109/TCDS.2020.2993855},\\n    ISSN={2379-8939},\\n    month={},}\\n}\\n</code></pre>\\n\",\"name\":\"2D Simulator for Zoo Experiments\",\"type\":\"code\",\"url\":\"https://github.com/btalb/abstract_map_simulator\",\"src\":\"/content/human_cues/abstract-map-simulator.md\",\"id\":\"abstract-map-simulator\",\"image_position\":\"center\",\"image\":\"/_next/static/images/abstract_map_simulation-8e1275a3c88423d73d8d661443eeefdf.png\"},{\"content\":\"<p align=center><strong>~ Please see the <a href=\\\"https://btalb.github.io/abstract_map/\\\">abstract map site</a> for further details about the research publication ~</strong></p>\\n<h1>App for the Human vs Abstract Map Zoo Experiments</h1>\\n<p><video autoplay loop poster=\\\"/_next/static/gifs/1e64d3716d81982074296f38479c3ae2.jpg\\\"><source src=\\\"/_next/static/gifs/1e64d3716d81982074296f38479c3ae2.webm\\\" type=\\\"video/webm\\\"/></video></p>\\n<p>This repository contains the mobile application used by human participants in the zoo experiments described in our <a href=\\\"https://doi.org/10.1109/TCDS.2020.2993855\\\">IEEE TCDS journal</a>. The app, created with Android Studio, includes the following:</p>\\n<ul>\\n<li>opening screen for users to select experiment name &amp; goal location</li>\\n<li>live display of the camera to help users correctly capture a tag</li>\\n<li>instant visual feedback when a tag is detected, with colouring to denote whether symbolic spatial information is not the goal (red), navigation information (orange), or the goal (green)</li>\\n<li>experiment definitions &amp; tag mappings are creatable via the same XML style used in the <a href=https://github.com/btalb/abstract_map>abstract_map</a> package</li>\\n<li>integration with the <a href=https://github.com/AprilRobotics/apriltag>native C AprilTags</a> using the Android NDK</li>\\n</ul>\\n<h2>Developing &amp; producing the app</h2>\\n<p>The project should be directly openable using Android Studio.</p>\\n<p>Please keep in mind that this app was last developed in 2019, and Android Studio often introduces minor breaking changes with new versions. Often you will have to tweak things like Gradle versions / syntax etc. to get a project working with newer versions. Android Studio is very good though with pointing out where it sees errors and offering suggestions for how to resolve them.</p>\\n<p>Once you have the project open, you should be able to compile the app and load it directly onto a device without issues.</p>\\n<h2>Acknowledgements &amp; Citing our work</h2>\\n<p>This work was supported by the Australian Research Council's Discovery Projects Funding Scheme under Project DP140103216. The authors are with the <a href=\\\"https://research.qut.edu.au/qcr/\\\">QUT Centre for Robotics</a>.</p>\\n<p>If you use this software in your research, or for comparisons, please kindly cite our work:</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">@ARTICLE{9091567,  \\n    author={B. {Talbot} and F. {Dayoub} and P. {Corke} and G. {Wyeth}},  \\n    journal={IEEE Transactions on Cognitive and Developmental Systems},   \\n    title={Robot Navigation in Unseen Spaces using an Abstract Map},   \\n    year={2020},  \\n    volume={},  \\n    number={},  \\n    pages={1-1},\\n    keywords={Navigation;Robot sensing systems;Measurement;Linguistics;Visualization;symbol grounding;symbolic spatial information;abstract map;navigation;cognitive robotics;intelligent robots.},\\n    doi={10.1109/TCDS.2020.2993855},\\n    ISSN={2379-8939},\\n    month={},}\\n}\\n</code></pre>\\n\",\"name\":\"Android App for Human Participants\",\"type\":\"code\",\"url\":\"https://github.com/btalb/abstract_map_app\",\"src\":\"/content/human_cues/abstract-map-app.md\",\"id\":\"abstract-map-app\",\"image_position\":\"center\",\"image\":\"/_next/static/gifs/1e64d3716d81982074296f38479c3ae2.jpg\",\"_image\":\"/_next/static/gifs/1e64d3716d81982074296f38479c3ae2.webm\"}],\"feature\":0,\"src\":\"/content/human_cues/human-cues.md\",\"id\":\"human-cues\",\"image_position\":\"center\",\"image\":\"/_next/static/images/abstract_map_in_action-261a2f7eea1f79411b48203e72995f14.png\"},{\"content\":\"<p>Python Robotics is a collection of software packages providing robotics-specific functionality to Python. While leveraging Python's advantages of portability, ubiquity and support, and the capability of the open-source ecosystem for linear algebra (numpy, scipy), graphics (matplotlib, three.js, WebGL), interactive development (jupyter, jupyterlab, mybinder.org), and documentation (sphinx).</p>\\n<p>The collection is built on top of Spatialmath which underpins all of robotics and robotic vision where we need to describe the position, orientation or pose of objects in 2D or 3D spaces. The core of the collection is the the Robotics Toolbox for Python while Swift provides a light-weight browser-based simulation environment.</p>\\n\",\"name\":\"Python Robotics\",\"type\":\"collection\",\"url\":\"https://petercorke.github.io/robotics-toolbox-python/\",\"image\":\"/_next/static/images/RobToolBox_RoundLogoB-9563d226662903b6e404b809e72e3235.png\",\"image_fit\":\"contain\",\"id\":\"python_robotics\",\"code\":[{\"content\":\"<h1>Spatial Maths for Python</h1>\\n<p><a href=\\\"https://badge.fury.io/py/spatialmath-python\\\"><img src=\\\"https://badge.fury.io/py/spatialmath-python.svg\\\" alt=\\\"PyPI version\\\"></a>\\n<img src=\\\"https://img.shields.io/pypi/pyversions/roboticstoolbox-python.svg\\\" alt=\\\"PyPI - Python Version\\\">\\n<a href=\\\"https://opensource.org/licenses/MIT\\\"><img src=\\\"https://img.shields.io/badge/License-MIT-yellow.svg\\\" alt=\\\"License: MIT\\\"></a>\\n<a href=\\\"https://qcr.github.io\\\"><img src=https://github.com/qcr/qcr.github.io/raw/master/misc/badge.svg alt=\\\"QUT Centre for Robotics Open Source\\\"></a></p>\\n<p><a href=https://github.com/petercorke/spatialmath-python/actions?query=workflow%3Abuild><img src=https://github.com/petercorke/spatialmath-python/workflows/build/badge.svg?branch=master alt=\\\"Build Status\\\"></a>\\n<a href=\\\"https://codecov.io/gh/petercorke/spatialmath-python\\\"><img src=\\\"https://codecov.io/gh/petercorke/spatialmath-python/branch/master/graph/badge.svg\\\" alt=\\\"Coverage\\\"></a>\\n<a href=\\\"https://lgtm.com/projects/g/petercorke/spatialmath-python/context:python\\\"><img src=\\\"https://img.shields.io/lgtm/grade/python/g/petercorke/spatialmath-python.svg?logo=lgtm&amp;logoWidth=18\\\" alt=\\\"Language grade: Python\\\"></a>\\n<a href=\\\"https://pypistats.org/packages/spatialmath-python\\\"><img src=\\\"https://img.shields.io/pypi/dw/spatialmath-python\\\" alt=\\\"PyPI - Downloads\\\"></a>\\n<a href=https://GitHub.com/petercorke/spatialmath-python/stargazers/><img src=\\\"https://img.shields.io/github/stars/petercorke/spatialmath-python.svg?style=social&amp;label=Star\\\" alt=\\\"GitHub stars\\\"></a></p>\\n<table style=\\\"border:0px\\\">\\n<tr style=\\\"border:0px\\\">\\n<td style=\\\"border:0px\\\">\\n<img src=https://github.com/petercorke/spatialmath-python/raw/master/docs/figs/CartesianSnakes_LogoW.png width=\\\"200\\\"></td>\\n<td style=\\\"border:0px\\\">\\nA Python implementation of the <a href=\\\"https://github.com/petercorke/spatial-math\\\">Spatial Math Toolbox for MATLAB<sup>&reg;</sup></a>\\n<ul>\\n<li><a href=\\\"https://github.com/petercorke/spatialmath-python\\\">GitHub repository </a></li>\\n<li><a href=\\\"https://petercorke.github.io/spatialmath-python\\\">Documentation</a></li>\\n<li><a href=\\\"https://github.com/petercorke/spatialmath-python/wiki\\\">Examples and details</a></li>\\n<li><a href=\\\"installation#\\\">Installation</a></li>\\n</ul>\\n</td>\\n</tr>\\n</table>\\n<p>Spatial mathematics capability underpins all of robotics and robotic vision where we need to describe the position, orientation or pose of objects in 2D or 3D spaces.</p>\\n<h1>What it does</h1>\\n<p>The package provides classes to represent pose and orientation in 3D and 2D\\nspace:</p>\\n<table>\\n<thead>\\n<tr>\\n<th>Represents</th>\\n<th>in 3D</th>\\n<th>in 2D</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td>pose</td>\\n<td><code class=\\\"language-none\\\">SE3</code> <code class=\\\"language-none\\\">Twist3</code> <code class=\\\"language-none\\\">UnitDualQuaternion</code></td>\\n<td><code class=\\\"language-none\\\">SE2</code> <code class=\\\"language-none\\\">Twist2</code></td>\\n</tr>\\n<tr>\\n<td>orientation</td>\\n<td><code class=\\\"language-none\\\">SO3</code> <code class=\\\"language-none\\\">UnitQuaternion</code></td>\\n<td><code class=\\\"language-none\\\">SO2</code></td>\\n</tr>\\n</tbody>\\n</table>\\n<p>More specifically:</p>\\n<ul>\\n<li><code class=\\\"language-none\\\">SE3</code> matrices belonging to the group SE(3) for position and orientation (pose) in 3-dimensions</li>\\n<li><code class=\\\"language-none\\\">SO3</code> matrices belonging to the group SO(3) for orientation in 3-dimensions</li>\\n<li><code class=\\\"language-none\\\">UnitQuaternion</code> belonging to the group S3 for orientation in 3-dimensions</li>\\n<li><code class=\\\"language-none\\\">Twist3</code> vectors belonging to the group se(3) for pose in 3-dimensions</li>\\n<li><code class=\\\"language-none\\\">UnitDualQuaternion</code> maps to the group SE(3) for position and orientation (pose) in 3-dimensions</li>\\n<li><code class=\\\"language-none\\\">SE2</code> matrices belonging to the group SE(2) for position and orientation (pose) in 2-dimensions</li>\\n<li><code class=\\\"language-none\\\">SO2</code> matrices belonging to the group SO(2) for orientation in 2-dimensions</li>\\n<li><code class=\\\"language-none\\\">Twist2</code> vectors belonging to the group se(2) for pose in 2-dimensions</li>\\n</ul>\\n<p>These classes provide convenience and type safety, as well as methods and overloaded operators to support:</p>\\n<ul>\\n<li>composition, using the <code class=\\\"language-none\\\">*</code> operator</li>\\n<li>point transformation, using the <code class=\\\"language-none\\\">*</code> operator</li>\\n<li>exponent, using the <code class=\\\"language-none\\\">**</code> operator</li>\\n<li>normalization</li>\\n<li>inversion</li>\\n<li>connection to the Lie algebra via matrix exponential and logarithm operations</li>\\n<li>conversion of orientation to/from Euler angles, roll-pitch-yaw angles and angle-axis forms.</li>\\n<li>list operations such as append, insert and get</li>\\n</ul>\\n<p>These are layered over a set of base functions that perform many of the same operations but represent data explicitly in terms of <code class=\\\"language-none\\\">numpy</code> arrays.</p>\\n<p>The class, method and functions names largely mirror those of the MATLAB toolboxes, and the semantics are quite similar.</p>\\n<p><img src=https://github.com/petercorke/spatialmath-python/raw/master/docs/figs/fig1.png alt=\\\"trplot\\\"></p>\\n<p><video autoplay loop poster=\\\"/_next/static/gifs/f53aa66b328813113b38f087b50da80f.jpg\\\"><source src=\\\"/_next/static/gifs/f53aa66b328813113b38f087b50da80f.webm\\\" type=\\\"video/webm\\\"/></video></p>\\n<h1>Installation</h1>\\n<h2>Using pip</h2>\\n<p>Install a snapshot from PyPI</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">pip install spatialmath-python\\n</code></pre>\\n<h2>From GitHub</h2>\\n<p>Install the current code base from GitHub and pip install a link to that cloned copy</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">git clone https://github.com/petercorke/spatialmath-python.git\\ncd spatialmath-python\\npip install -e .\\n</code></pre>\\n<h2>Dependencies</h2>\\n<p><code class=\\\"language-none\\\">numpy</code>, <code class=\\\"language-none\\\">scipy</code>, <code class=\\\"language-none\\\">matplotlib</code>, <code class=\\\"language-none\\\">ffmpeg</code> (if rendering animations as a movie)</p>\\n<h1>Examples</h1>\\n<h2>High-level classes</h2>\\n<p>These classes abstract the low-level numpy arrays into objects that obey the rules associated with the mathematical groups SO(2), SE(2), SO(3), SE(3) as well as twists and quaternions.</p>\\n<p>Using classes ensures type safety, for example it stops us mixing a 2D homogeneous transformation with a 3D rotation matrix -- both of which are 3x3 matrices.  It also ensures that the internal matrix representation is always a valid member of the relevant group.</p>\\n<p>For example, to create an object representing a rotation of 0.3 radians about the x-axis is simply</p>\\n<pre class=\\\"language-python\\\"><code class=\\\"language-python\\\"><span class=\\\"token operator\\\">>></span><span class=\\\"token operator\\\">></span> R1 <span class=\\\"token operator\\\">=</span> SO3<span class=\\\"token punctuation\\\">.</span>Rx<span class=\\\"token punctuation\\\">(</span><span class=\\\"token number\\\">0.3</span><span class=\\\"token punctuation\\\">)</span>\\n<span class=\\\"token operator\\\">>></span><span class=\\\"token operator\\\">></span> R1\\n   <span class=\\\"token number\\\">1</span>         <span class=\\\"token number\\\">0</span>         <span class=\\\"token number\\\">0</span>          \\n   <span class=\\\"token number\\\">0</span>         <span class=\\\"token number\\\">0.955336</span> <span class=\\\"token operator\\\">-</span><span class=\\\"token number\\\">0.29552</span>    \\n   <span class=\\\"token number\\\">0</span>         <span class=\\\"token number\\\">0.29552</span>   <span class=\\\"token number\\\">0.955336</span>         \\n</code></pre>\\n<p>while a rotation of 30 deg about the z-axis is</p>\\n<pre class=\\\"language-python\\\"><code class=\\\"language-python\\\"><span class=\\\"token operator\\\">>></span><span class=\\\"token operator\\\">></span> R2 <span class=\\\"token operator\\\">=</span> SO3<span class=\\\"token punctuation\\\">.</span>Rz<span class=\\\"token punctuation\\\">(</span><span class=\\\"token number\\\">30</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token string\\\">'deg'</span><span class=\\\"token punctuation\\\">)</span>\\n<span class=\\\"token operator\\\">>></span><span class=\\\"token operator\\\">></span> R2\\n   <span class=\\\"token number\\\">0.866025</span> <span class=\\\"token operator\\\">-</span><span class=\\\"token number\\\">0.5</span>       <span class=\\\"token number\\\">0</span>          \\n   <span class=\\\"token number\\\">0.5</span>       <span class=\\\"token number\\\">0.866025</span>  <span class=\\\"token number\\\">0</span>          \\n   <span class=\\\"token number\\\">0</span>         <span class=\\\"token number\\\">0</span>         <span class=\\\"token number\\\">1</span>    \\n</code></pre>\\n<p>and the composition of these two rotations is</p>\\n<pre class=\\\"language-python\\\"><code class=\\\"language-python\\\"><span class=\\\"token operator\\\">>></span><span class=\\\"token operator\\\">></span> R <span class=\\\"token operator\\\">=</span> R1 <span class=\\\"token operator\\\">*</span> R2\\n   <span class=\\\"token number\\\">0.866025</span> <span class=\\\"token operator\\\">-</span><span class=\\\"token number\\\">0.5</span>       <span class=\\\"token number\\\">0</span>          \\n   <span class=\\\"token number\\\">0.433013</span>  <span class=\\\"token number\\\">0.75</span>     <span class=\\\"token operator\\\">-</span><span class=\\\"token number\\\">0.5</span>        \\n   <span class=\\\"token number\\\">0.25</span>      <span class=\\\"token number\\\">0.433013</span>  <span class=\\\"token number\\\">0.866025</span> \\n</code></pre>\\n<p>We can find the corresponding Euler angles (in radians)</p>\\n<pre class=\\\"language-python\\\"><code class=\\\"language-python\\\"><span class=\\\"token operator\\\">>></span> R<span class=\\\"token punctuation\\\">.</span>eul<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span>\\narray<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">[</span><span class=\\\"token operator\\\">-</span><span class=\\\"token number\\\">1.57079633</span><span class=\\\"token punctuation\\\">,</span>  <span class=\\\"token number\\\">0.52359878</span><span class=\\\"token punctuation\\\">,</span>  <span class=\\\"token number\\\">2.0943951</span> <span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span>\\n</code></pre>\\n<p>Frequently in robotics we want a sequence, a trajectory, of rotation matrices or poses. These pose classes inherit capability from the <code class=\\\"language-none\\\">list</code> class</p>\\n<pre class=\\\"language-python\\\"><code class=\\\"language-python\\\"><span class=\\\"token operator\\\">>></span><span class=\\\"token operator\\\">></span> R <span class=\\\"token operator\\\">=</span> SO3<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span>   <span class=\\\"token comment\\\"># the identity</span>\\n<span class=\\\"token operator\\\">>></span><span class=\\\"token operator\\\">></span> R<span class=\\\"token punctuation\\\">.</span>append<span class=\\\"token punctuation\\\">(</span>R1<span class=\\\"token punctuation\\\">)</span>\\n<span class=\\\"token operator\\\">>></span><span class=\\\"token operator\\\">></span> R<span class=\\\"token punctuation\\\">.</span>append<span class=\\\"token punctuation\\\">(</span>R2<span class=\\\"token punctuation\\\">)</span>\\n<span class=\\\"token operator\\\">>></span><span class=\\\"token operator\\\">></span> <span class=\\\"token builtin\\\">len</span><span class=\\\"token punctuation\\\">(</span>R<span class=\\\"token punctuation\\\">)</span>\\n <span class=\\\"token number\\\">3</span>\\n<span class=\\\"token operator\\\">>></span><span class=\\\"token operator\\\">></span> R<span class=\\\"token punctuation\\\">[</span><span class=\\\"token number\\\">1</span><span class=\\\"token punctuation\\\">]</span>\\n   <span class=\\\"token number\\\">1</span>         <span class=\\\"token number\\\">0</span>         <span class=\\\"token number\\\">0</span>          \\n   <span class=\\\"token number\\\">0</span>         <span class=\\\"token number\\\">0.955336</span> <span class=\\\"token operator\\\">-</span><span class=\\\"token number\\\">0.29552</span>    \\n   <span class=\\\"token number\\\">0</span>         <span class=\\\"token number\\\">0.29552</span>   <span class=\\\"token number\\\">0.955336</span>             \\n</code></pre>\\n<p>and this can be used in <code class=\\\"language-none\\\">for</code> loops and list comprehensions.</p>\\n<p>An alternative way of constructing this would be (<code class=\\\"language-none\\\">R1</code>, <code class=\\\"language-none\\\">R2</code> defined above)</p>\\n<pre class=\\\"language-python\\\"><code class=\\\"language-python\\\"><span class=\\\"token operator\\\">>></span><span class=\\\"token operator\\\">></span> R <span class=\\\"token operator\\\">=</span> SO3<span class=\\\"token punctuation\\\">(</span> <span class=\\\"token punctuation\\\">[</span> SO3<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">,</span> R1<span class=\\\"token punctuation\\\">,</span> R2 <span class=\\\"token punctuation\\\">]</span> <span class=\\\"token punctuation\\\">)</span>       \\n<span class=\\\"token operator\\\">>></span><span class=\\\"token operator\\\">></span> <span class=\\\"token builtin\\\">len</span><span class=\\\"token punctuation\\\">(</span>R<span class=\\\"token punctuation\\\">)</span>\\n <span class=\\\"token number\\\">3</span>\\n</code></pre>\\n<p>Many of the constructors such as <code class=\\\"language-none\\\">.Rx</code>, <code class=\\\"language-none\\\">.Ry</code> and <code class=\\\"language-none\\\">.Rz</code> support vectorization</p>\\n<pre class=\\\"language-python\\\"><code class=\\\"language-python\\\"><span class=\\\"token operator\\\">>></span><span class=\\\"token operator\\\">></span> R <span class=\\\"token operator\\\">=</span> SO3<span class=\\\"token punctuation\\\">.</span>Rx<span class=\\\"token punctuation\\\">(</span> np<span class=\\\"token punctuation\\\">.</span>arange<span class=\\\"token punctuation\\\">(</span><span class=\\\"token number\\\">0</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token number\\\">2</span><span class=\\\"token operator\\\">*</span>np<span class=\\\"token punctuation\\\">.</span>pi<span class=\\\"token punctuation\\\">,</span> <span class=\\\"token number\\\">0.2</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">)</span>\\n<span class=\\\"token operator\\\">>></span><span class=\\\"token operator\\\">></span> <span class=\\\"token builtin\\\">len</span><span class=\\\"token punctuation\\\">(</span>R<span class=\\\"token punctuation\\\">)</span>\\n <span class=\\\"token number\\\">32</span>\\n</code></pre>\\n<p>which has created, in a single line, a list of rotation matrices.</p>\\n<p>Vectorization also applies to the operators, for instance</p>\\n<pre class=\\\"language-python\\\"><code class=\\\"language-python\\\"><span class=\\\"token operator\\\">>></span><span class=\\\"token operator\\\">></span> A <span class=\\\"token operator\\\">=</span> R <span class=\\\"token operator\\\">*</span> SO3<span class=\\\"token punctuation\\\">.</span>Ry<span class=\\\"token punctuation\\\">(</span><span class=\\\"token number\\\">0.5</span><span class=\\\"token punctuation\\\">)</span>\\n<span class=\\\"token operator\\\">>></span><span class=\\\"token operator\\\">></span> <span class=\\\"token builtin\\\">len</span><span class=\\\"token punctuation\\\">(</span>R<span class=\\\"token punctuation\\\">)</span>\\n <span class=\\\"token number\\\">32</span>\\n</code></pre>\\n<p>will produce a result where each element is the product of each element of the left-hand side with the right-hand side, ie. <code class=\\\"language-none\\\">R[i] * SO3.Ry(0.5)</code>.</p>\\n<p>Similarly</p>\\n<pre class=\\\"language-python\\\"><code class=\\\"language-python\\\"><span class=\\\"token operator\\\">>></span><span class=\\\"token operator\\\">></span> A <span class=\\\"token operator\\\">=</span> SO3<span class=\\\"token punctuation\\\">.</span>Ry<span class=\\\"token punctuation\\\">(</span><span class=\\\"token number\\\">0.5</span><span class=\\\"token punctuation\\\">)</span> <span class=\\\"token operator\\\">*</span> R \\n<span class=\\\"token operator\\\">>></span><span class=\\\"token operator\\\">></span> <span class=\\\"token builtin\\\">len</span><span class=\\\"token punctuation\\\">(</span>R<span class=\\\"token punctuation\\\">)</span>\\n <span class=\\\"token number\\\">32</span>\\n</code></pre>\\n<p>will produce a result where each element is the product of the left-hand side with each element of the right-hand side , ie. <code class=\\\"language-none\\\">SO3.Ry(0.5) * R[i] </code>.</p>\\n<p>Finally</p>\\n<pre class=\\\"language-python\\\"><code class=\\\"language-python\\\"><span class=\\\"token operator\\\">>></span><span class=\\\"token operator\\\">></span> A <span class=\\\"token operator\\\">=</span> R <span class=\\\"token operator\\\">*</span> R \\n<span class=\\\"token operator\\\">>></span><span class=\\\"token operator\\\">></span> <span class=\\\"token builtin\\\">len</span><span class=\\\"token punctuation\\\">(</span>R<span class=\\\"token punctuation\\\">)</span>\\n <span class=\\\"token number\\\">32</span>\\n</code></pre>\\n<p>will produce a result where each element is the product of each element of the left-hand side with each element of the right-hand side , ie. <code class=\\\"language-none\\\">R[i] * R[i] </code>.</p>\\n<p>The underlying representation of these classes is a numpy matrix, but the class ensures that the structure of that matrix is valid for the particular group represented: SO(2), SE(2), SO(3), SE(3).  Any operation that is not valid for the group will return a matrix rather than a pose class, for example</p>\\n<pre class=\\\"language-python\\\"><code class=\\\"language-python\\\"><span class=\\\"token operator\\\">>></span><span class=\\\"token operator\\\">></span> SO3<span class=\\\"token punctuation\\\">.</span>Rx<span class=\\\"token punctuation\\\">(</span><span class=\\\"token number\\\">0.3</span><span class=\\\"token punctuation\\\">)</span> <span class=\\\"token operator\\\">*</span> <span class=\\\"token number\\\">2</span>\\narray<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">[</span><span class=\\\"token punctuation\\\">[</span> <span class=\\\"token number\\\">2</span><span class=\\\"token punctuation\\\">.</span>        <span class=\\\"token punctuation\\\">,</span>  <span class=\\\"token number\\\">0</span><span class=\\\"token punctuation\\\">.</span>        <span class=\\\"token punctuation\\\">,</span>  <span class=\\\"token number\\\">0</span><span class=\\\"token punctuation\\\">.</span>        <span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">,</span>\\n       <span class=\\\"token punctuation\\\">[</span> <span class=\\\"token number\\\">0</span><span class=\\\"token punctuation\\\">.</span>        <span class=\\\"token punctuation\\\">,</span>  <span class=\\\"token number\\\">1.91067298</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token operator\\\">-</span><span class=\\\"token number\\\">0.59104041</span><span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">,</span>\\n       <span class=\\\"token punctuation\\\">[</span> <span class=\\\"token number\\\">0</span><span class=\\\"token punctuation\\\">.</span>        <span class=\\\"token punctuation\\\">,</span>  <span class=\\\"token number\\\">0.59104041</span><span class=\\\"token punctuation\\\">,</span>  <span class=\\\"token number\\\">1.91067298</span><span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span>\\n\\n<span class=\\\"token operator\\\">>></span><span class=\\\"token operator\\\">></span> SO3<span class=\\\"token punctuation\\\">.</span>Rx<span class=\\\"token punctuation\\\">(</span><span class=\\\"token number\\\">0.3</span><span class=\\\"token punctuation\\\">)</span> <span class=\\\"token operator\\\">-</span> <span class=\\\"token number\\\">1</span>\\narray<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">[</span><span class=\\\"token punctuation\\\">[</span> <span class=\\\"token number\\\">0</span><span class=\\\"token punctuation\\\">.</span>        <span class=\\\"token punctuation\\\">,</span> <span class=\\\"token operator\\\">-</span><span class=\\\"token number\\\">1</span><span class=\\\"token punctuation\\\">.</span>        <span class=\\\"token punctuation\\\">,</span> <span class=\\\"token operator\\\">-</span><span class=\\\"token number\\\">1</span><span class=\\\"token punctuation\\\">.</span>        <span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">,</span>\\n       <span class=\\\"token punctuation\\\">[</span><span class=\\\"token operator\\\">-</span><span class=\\\"token number\\\">1</span><span class=\\\"token punctuation\\\">.</span>        <span class=\\\"token punctuation\\\">,</span> <span class=\\\"token operator\\\">-</span><span class=\\\"token number\\\">0.04466351</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token operator\\\">-</span><span class=\\\"token number\\\">1.29552021</span><span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">,</span>\\n       <span class=\\\"token punctuation\\\">[</span><span class=\\\"token operator\\\">-</span><span class=\\\"token number\\\">1</span><span class=\\\"token punctuation\\\">.</span>        <span class=\\\"token punctuation\\\">,</span> <span class=\\\"token operator\\\">-</span><span class=\\\"token number\\\">0.70447979</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token operator\\\">-</span><span class=\\\"token number\\\">0.04466351</span><span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span>\\n</code></pre>\\n<p>We can print and plot these objects as well</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">&gt;&gt;&gt; T = SE3(1,2,3) * SE3.Rx(30, 'deg')\\n&gt;&gt;&gt; T.print()\\n   1         0         0         1          \\n   0         0.866025 -0.5       2          \\n   0         0.5       0.866025  3          \\n   0         0         0         1          \\n\\n&gt;&gt;&gt; T.printline()\\nt =        1,        2,        3; rpy/zyx =       30,        0,        0 deg\\n\\n&gt;&gt;&gt; T.plot()\\n</code></pre>\\n<p><img src=https://github.com/petercorke/spatialmath-python/raw/master/docs/figs/fig1.png alt=\\\"trplot\\\"></p>\\n<p><code class=\\\"language-none\\\">printline</code> is a compact single line format for tabular listing, whereas <code class=\\\"language-none\\\">print</code> shows the underlying matrix and for consoles that support it, it is colorised, with rotational elements in red and translational elements in blue.</p>\\n<p>For more detail checkout the shipped Python notebooks:</p>\\n<ul>\\n<li><a href=https://github.com/petercorke/spatialmath-python/blob/master/spatialmath/gentle-introduction.ipynb>gentle introduction</a></li>\\n<li><a href=https://github.com/petercorke/spatialmath-python/blob/master/spatialmath/introduction.ipynb>deeper introduction</a></li>\\n</ul>\\n<p>You can browse it statically through the links above, or clone the toolbox and run them interactively using <a href=\\\"https://jupyter.org\\\">Jupyter</a> or <a href=\\\"https://jupyter.org\\\">JupyterLab</a>.</p>\\n<h2>Low-level spatial math</h2>\\n<p>Import the low-level transform functions</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">&gt;&gt;&gt; import spatialmath.base as tr\\n</code></pre>\\n<p>We can create a 3D rotation matrix</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">&gt;&gt;&gt; tr.rotx(0.3)\\narray([[ 1.        ,  0.        ,  0.        ],\\n       [ 0.        ,  0.95533649, -0.29552021],\\n       [ 0.        ,  0.29552021,  0.95533649]])\\n\\n&gt;&gt;&gt; tr.rotx(30, unit='deg')\\narray([[ 1.       ,  0.       ,  0.       ],\\n       [ 0.       ,  0.8660254, -0.5      ],\\n       [ 0.       ,  0.5      ,  0.8660254]])\\n</code></pre>\\n<p>The results are <code class=\\\"language-none\\\">numpy</code> arrays so to perform matrix multiplication you need to use the <code class=\\\"language-none\\\">@</code> operator, for example</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">rotx(0.3) @ roty(0.2)\\n</code></pre>\\n<p>We also support multiple ways of passing vector information to functions that require it:</p>\\n<ul>\\n<li>as separate positional arguments</li>\\n</ul>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">transl2(1, 2)\\narray([[1., 0., 1.],\\n       [0., 1., 2.],\\n       [0., 0., 1.]])\\n</code></pre>\\n<ul>\\n<li>as a list or a tuple</li>\\n</ul>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">transl2( [1,2] )\\narray([[1., 0., 1.],\\n       [0., 1., 2.],\\n       [0., 0., 1.]])\\n\\ntransl2( (1,2) )\\nOut[444]: \\narray([[1., 0., 1.],\\n       [0., 1., 2.],\\n       [0., 0., 1.]])\\n</code></pre>\\n<ul>\\n<li>or as a <code class=\\\"language-none\\\">numpy</code> array</li>\\n</ul>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">transl2( np.array([1,2]) )\\nOut[445]: \\narray([[1., 0., 1.],\\n       [0., 1., 2.],\\n       [0., 0., 1.]])\\n</code></pre>\\n<p>There is a single module that deals with quaternions, unit or not, and the representation is a <code class=\\\"language-none\\\">numpy</code> array of four elements.  As above, functions can accept the <code class=\\\"language-none\\\">numpy</code> array, a list, dict or <code class=\\\"language-none\\\">numpy</code> row or column vectors.</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">&gt;&gt;&gt; from spatialmath.base.quaternion import *\\n&gt;&gt;&gt; q = qqmul([1,2,3,4], [5,6,7,8])\\n&gt;&gt;&gt; q\\narray([-60,  12,  30,  24])\\n&gt;&gt;&gt; qprint(q)\\n-60.000000 &lt; 12.000000, 30.000000, 24.000000 &gt;\\n&gt;&gt;&gt; qnorm(q)\\n72.24956747275377\\n</code></pre>\\n<h2>Graphics</h2>\\n<p><img src=https://github.com/petercorke/spatialmath-python/raw/master/docs/figs/transforms3d.png alt=\\\"trplot\\\"></p>\\n<p>The functions support various plotting styles</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">trplot( transl(1,2,3), frame='A', rviz=True, width=1, dims=[0, 10, 0, 10, 0, 10])\\ntrplot( transl(3,1, 2), color='red', width=3, frame='B')\\ntrplot( transl(4, 3, 1)@trotx(math.pi/3), color='green', frame='c', dims=[0,4,0,4,0,4])\\n</code></pre>\\n<p>Animation is straightforward</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">tranimate(transl(4, 3, 4)@trotx(2)@troty(-2), frame=' arrow=False, dims=[0, 5], nframes=200)\\n</code></pre>\\n<p>and it can be saved to a file by</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">tranimate(transl(4, 3, 4)@trotx(2)@troty(-2), frame=' arrow=False, dims=[0, 5], nframes=200, movie='out.mp4')\\n</code></pre>\\n<p><video autoplay loop poster=\\\"/_next/static/gifs/f53aa66b328813113b38f087b50da80f.jpg\\\"><source src=\\\"/_next/static/gifs/f53aa66b328813113b38f087b50da80f.webm\\\" type=\\\"video/webm\\\"/></video></p>\\n<p>At the moment we can only save as an MP4, but the following incantation will covert that to an animated GIF for embedding in web pages</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">ffmpeg -i out -r 20 -vf &quot;fps=10,scale=640:-1:flags=lanczos,split[s0][s1];[s0]palettegen[p];[s1][p]paletteuse&quot; out.gif\\n</code></pre>\\n<h2>Symbolic support</h2>\\n<p>Some functions have support for symbolic variables, for example</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">import sympy\\n\\ntheta = sym.symbols('theta')\\nprint(rotx(theta))\\n[[1 0 0]\\n [0 cos(theta) -sin(theta)]\\n [0 sin(theta) cos(theta)]]\\n</code></pre>\\n<p>The resulting <code class=\\\"language-none\\\">numpy</code> array is an array of symbolic objects not numbers – the constants are also symbolic objects.  You can read the elements of the matrix</p>\\n<pre class=\\\"language-none\\\"><code class=\\\"language-none\\\">a = T[0,0]\\n\\na\\nOut[258]: 1\\n\\ntype(a)\\nOut[259]: int\\n\\na = T[1,1]\\na\\nOut[256]: \\ncos(theta)\\ntype(a)\\nOut[255]: cos\\n</code></pre>\\n<p>We see that the symbolic constants are converted back to Python numeric types on read.</p>\\n<p>Similarly when we assign an element or slice of the symbolic matrix to a numeric value, they are converted to symbolic constants on the way in.</p>\\n\",\"name\":\"Spatialmath Python\",\"type\":\"code\",\"url\":\"https://github.com/petercorke/spatialmath-python\",\"image\":\"/_next/static/images/CartesianSnakes_LogoW-292d336acf7d3ffebbf1da8f9f6ccc9d.png\",\"image_fit\":\"contain\",\"src\":\"/content/robotics_toolbox/spatialmath-python.md\",\"id\":\"spatialmath-python\",\"image_position\":\"center\"},{\"content\":\"<h1>Robotics Toolbox for Python</h1>\\n<p><a href=\\\"https://badge.fury.io/py/roboticstoolbox-python\\\"><img src=\\\"https://badge.fury.io/py/roboticstoolbox-python.svg\\\" alt=\\\"PyPI version\\\"></a>\\n<img src=\\\"https://img.shields.io/pypi/pyversions/roboticstoolbox-python.svg\\\" alt=\\\"PyPI - Python Version\\\">\\n<a href=\\\"https://opensource.org/licenses/MIT\\\"><img src=\\\"https://img.shields.io/badge/License-MIT-yellow.svg\\\" alt=\\\"License: MIT\\\"></a>\\n<a href=\\\"https://mybinder.org/v2/gh/petercorke/robotics-toolbox-python/master?filepath=notebooks\\\"><img src=\\\"https://mybinder.org/badge_logo.svg\\\" alt=\\\"Binder\\\"></a>\\n<a href=\\\"https://qcr.github.io\\\"><img src=https://github.com/qcr/qcr.github.io/raw/master/misc/badge.svg alt=\\\"QUT Centre for Robotics Open Source\\\"></a></p>\\n<p><a href=https://github.com/petercorke/robotics-toolbox-python/actions?query=workflow%3Abuild><img src=https://github.com/petercorke/robotics-toolbox-python/workflows/build/badge.svg?branch=master alt=\\\"Build Status\\\"></a>\\n<a href=\\\"https://codecov.io/gh/petercorke/robotics-toolbox-python\\\"><img src=\\\"https://codecov.io/gh/petercorke/robotics-toolbox-python/branch/master/graph/badge.svg\\\" alt=\\\"Coverage\\\"></a>\\n<a href=\\\"https://lgtm.com/projects/g/petercorke/robotics-toolbox-python/context:python\\\"><img src=\\\"https://img.shields.io/lgtm/grade/python/g/petercorke/robotics-toolbox-python.svg?logo=lgtm&amp;logoWidth=18\\\" alt=\\\"Language grade: Python\\\"></a>\\n<a href=\\\"https://pypistats.org/packages/roboticstoolbox-python\\\"><img src=\\\"https://img.shields.io/pypi/dw/roboticstoolbox-python\\\" alt=\\\"PyPI - Downloads\\\"></a></p>\\n<table style=\\\"border:0px\\\">\\n<tr style=\\\"border:0px\\\">\\n<td style=\\\"border:0px\\\">\\n<img src=https://github.com/petercorke/robotics-toolbox-python/raw/master/docs/figs/RobToolBox_RoundLogoB.png width=\\\"200\\\"></td>\\n<td style=\\\"border:0px\\\">\\nA Python implementation of the <a href=\\\"https://github.com/petercorke/robotics-toolbox-matlab\\\">Robotics Toolbox for MATLAB<sup>&reg;</sup></a>\\n<ul>\\n<li><a href=\\\"https://github.com/petercorke/robotics-toolbox-python\\\">GitHub repository </a></li>\\n<li><a href=\\\"https://petercorke.github.io/robotics-toolbox-python\\\">Documentation</a></li>\\n<li><a href=\\\"https://github.com/petercorke/robotics-toolbox-python/wiki\\\">Examples and details</a></li>\\n</ul>\\n</td>\\n</tr>\\n</table>\\n<h2>Synopsis</h2>\\n<p>This toolbox brings robotics-specific functionality to Python, and leverages\\nPython's advantages of portability, ubiquity and support, and the capability of\\nthe open-source ecosystem for linear algebra (numpy, scipy),  graphics\\n(matplotlib, three.js, WebGL), interactive development (jupyter, jupyterlab,\\nmybinder.org), and documentation (sphinx).</p>\\n<p>The Toolbox provides tools for representing the kinematics and dynamics of\\nserial-link manipulators  - you can easily create your own in Denavit-Hartenberg\\nform, import a URDF file, or use over 30 supplied models for well-known\\ncontemporary robots from Franka-Emika, Kinova, Universal Robotics, Rethink as\\nwell as classical robots such as the Puma 560 and the Stanford arm.</p>\\n<p>The toolbox will also support mobile robots with functions for robot motion models\\n(unicycle, bicycle), path planning algorithms (bug, distance transform, D*,\\nPRM), kinodynamic planning (lattice, RRT), localization (EKF, particle filter),\\nmap building (EKF) and simultaneous localization and mapping (EKF).</p>\\n<p>The Toolbox provides:</p>\\n<ul>\\n<li>code that is mature and provides a point of comparison for other\\nimplementations of the same algorithms;</li>\\n<li>routines which are generally written in a straightforward manner which\\nallows for easy understanding, perhaps at the expense of computational\\nefficiency;</li>\\n<li>source code which can be read for learning and teaching;</li>\\n<li>backward compatability with the Robotics Toolbox for MATLAB</li>\\n</ul>\\n<p>The Toolbox leverages the <a href=https://github.com/petercorke/spatialmath-python>Spatial Maths Toolbox for Python</a> to\\nprovide support for data types such as SO(n) and SE(n) matrices, quaternions, twists and spatial vectors.</p>\\n<h2>Code Example</h2>\\n<p>We will load a model of the Franka-Emika Panda robot defined classically using\\nmodified (Craig's convention) Denavit-Hartenberg notation</p>\\n<pre class=\\\"language-python\\\"><code class=\\\"language-python\\\"><span class=\\\"token keyword\\\">import</span> roboticstoolbox <span class=\\\"token keyword\\\">as</span> rtb\\nrobot <span class=\\\"token operator\\\">=</span> rtb<span class=\\\"token punctuation\\\">.</span>models<span class=\\\"token punctuation\\\">.</span>DH<span class=\\\"token punctuation\\\">.</span>Panda<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span>\\n<span class=\\\"token keyword\\\">print</span><span class=\\\"token punctuation\\\">(</span>robot<span class=\\\"token punctuation\\\">)</span>\\n\\n\\t┏━━━━━━━━┳━━━━━━━━┳━━━━━┳━━━━━━━┳━━━━━━━━━┳━━━━━━━━┓\\n\\t┃ aⱼ₋₁   ┃  ⍺ⱼ₋₁  ┃ θⱼ  ┃  dⱼ   ┃   q⁻    ┃   q⁺   ┃\\n\\t┣━━━━━━━━╋━━━━━━━━╋━━━━━╋━━━━━━━╋━━━━━━━━━╋━━━━━━━━┫\\n\\t┃    <span class=\\\"token number\\\">0.0</span> ┃   <span class=\\\"token number\\\">0.0</span>° ┃  q1 ┃ <span class=\\\"token number\\\">0.333</span> ┃ <span class=\\\"token operator\\\">-</span><span class=\\\"token number\\\">166.0</span>° ┃ <span class=\\\"token number\\\">166.0</span>° ┃\\n\\t┃    <span class=\\\"token number\\\">0.0</span> ┃ <span class=\\\"token operator\\\">-</span><span class=\\\"token number\\\">90.0</span>° ┃  q2 ┃   <span class=\\\"token number\\\">0.0</span> ┃ <span class=\\\"token operator\\\">-</span><span class=\\\"token number\\\">101.0</span>° ┃ <span class=\\\"token number\\\">101.0</span>° ┃\\n\\t┃    <span class=\\\"token number\\\">0.0</span> ┃  <span class=\\\"token number\\\">90.0</span>° ┃  q3 ┃ <span class=\\\"token number\\\">0.316</span> ┃ <span class=\\\"token operator\\\">-</span><span class=\\\"token number\\\">166.0</span>° ┃ <span class=\\\"token number\\\">166.0</span>° ┃\\n\\t┃ <span class=\\\"token number\\\">0.0825</span> ┃  <span class=\\\"token number\\\">90.0</span>° ┃  q4 ┃   <span class=\\\"token number\\\">0.0</span> ┃ <span class=\\\"token operator\\\">-</span><span class=\\\"token number\\\">176.0</span>° ┃  <span class=\\\"token operator\\\">-</span><span class=\\\"token number\\\">4.0</span>° ┃\\n\\t┃<span class=\\\"token operator\\\">-</span><span class=\\\"token number\\\">0.0825</span> ┃ <span class=\\\"token operator\\\">-</span><span class=\\\"token number\\\">90.0</span>° ┃  q5 ┃ <span class=\\\"token number\\\">0.384</span> ┃ <span class=\\\"token operator\\\">-</span><span class=\\\"token number\\\">166.0</span>° ┃ <span class=\\\"token number\\\">166.0</span>° ┃\\n\\t┃    <span class=\\\"token number\\\">0.0</span> ┃  <span class=\\\"token number\\\">90.0</span>° ┃  q6 ┃   <span class=\\\"token number\\\">0.0</span> ┃   <span class=\\\"token operator\\\">-</span><span class=\\\"token number\\\">1.0</span>° ┃ <span class=\\\"token number\\\">215.0</span>° ┃\\n\\t┃  <span class=\\\"token number\\\">0.088</span> ┃  <span class=\\\"token number\\\">90.0</span>° ┃  q7 ┃ <span class=\\\"token number\\\">0.107</span> ┃ <span class=\\\"token operator\\\">-</span><span class=\\\"token number\\\">166.0</span>° ┃ <span class=\\\"token number\\\">166.0</span>° ┃\\n\\t┗━━━━━━━━┻━━━━━━━━┻━━━━━┻━━━━━━━┻━━━━━━━━━┻━━━━━━━━┛\\n\\t\\n\\t┌─────┬───────────────────────────────────────┐\\n\\t│tool │ t <span class=\\\"token operator\\\">=</span> <span class=\\\"token number\\\">0</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token number\\\">0</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token number\\\">0.1</span><span class=\\\"token punctuation\\\">;</span> rpy<span class=\\\"token operator\\\">/</span>xyz <span class=\\\"token operator\\\">=</span> <span class=\\\"token operator\\\">-</span><span class=\\\"token number\\\">45</span>°<span class=\\\"token punctuation\\\">,</span> <span class=\\\"token number\\\">0</span>°<span class=\\\"token punctuation\\\">,</span> <span class=\\\"token number\\\">0</span>° │\\n\\t└─────┴───────────────────────────────────────┘\\n\\t\\n\\t┌─────┬─────┬────────┬─────┬───────┬─────┬───────┬──────┐\\n\\t│name │ q0  │ q1     │ q2  │ q3    │ q4  │ q5    │ q6   │\\n\\t├─────┼─────┼────────┼─────┼───────┼─────┼───────┼──────┤\\n\\t│  qz │  <span class=\\\"token number\\\">0</span>° │  <span class=\\\"token number\\\">0</span>°    │  <span class=\\\"token number\\\">0</span>° │  <span class=\\\"token number\\\">0</span>°   │  <span class=\\\"token number\\\">0</span>° │  <span class=\\\"token number\\\">0</span>°   │  <span class=\\\"token number\\\">0</span>°  │\\n\\t│  qr │  <span class=\\\"token number\\\">0</span>° │ <span class=\\\"token operator\\\">-</span><span class=\\\"token number\\\">17.2</span>° │  <span class=\\\"token number\\\">0</span>° │ <span class=\\\"token operator\\\">-</span><span class=\\\"token number\\\">126</span>° │  <span class=\\\"token number\\\">0</span>° │  <span class=\\\"token number\\\">115</span>° │  <span class=\\\"token number\\\">45</span>° │\\n\\t└─────┴─────┴────────┴─────┴───────┴─────┴───────┴──────┘\\n\\nT <span class=\\\"token operator\\\">=</span> robot<span class=\\\"token punctuation\\\">.</span>fkine<span class=\\\"token punctuation\\\">(</span>robot<span class=\\\"token punctuation\\\">.</span>qz<span class=\\\"token punctuation\\\">)</span>  <span class=\\\"token comment\\\"># forward kinematics</span>\\n<span class=\\\"token keyword\\\">print</span><span class=\\\"token punctuation\\\">(</span>T<span class=\\\"token punctuation\\\">)</span>\\n\\n\\t   <span class=\\\"token number\\\">0.707107</span>    <span class=\\\"token number\\\">0.707107</span>    <span class=\\\"token number\\\">0</span>           <span class=\\\"token number\\\">0.088</span>        \\n\\t   <span class=\\\"token number\\\">0.707107</span>   <span class=\\\"token operator\\\">-</span><span class=\\\"token number\\\">0.707107</span>    <span class=\\\"token number\\\">0</span>           <span class=\\\"token number\\\">0</span>            \\n\\t   <span class=\\\"token number\\\">0</span>           <span class=\\\"token number\\\">0</span>          <span class=\\\"token operator\\\">-</span><span class=\\\"token number\\\">1</span>           <span class=\\\"token number\\\">0.823</span>        \\n\\t   <span class=\\\"token number\\\">0</span>           <span class=\\\"token number\\\">0</span>           <span class=\\\"token number\\\">0</span>           <span class=\\\"token number\\\">1</span>          \\n</code></pre>\\n<p>(Python prompts are not shown to make it easy to copy+paste the code, console output is indented)</p>\\n<p>We can solve inverse kinematics very easily.  We first choose an SE(3) pose\\ndefined in terms of position and orientation (end-effector z-axis down (A=-Z) and finger\\norientation parallel to y-axis (O=+Y)).</p>\\n<pre class=\\\"language-python\\\"><code class=\\\"language-python\\\"><span class=\\\"token keyword\\\">from</span> spatialmath <span class=\\\"token keyword\\\">import</span> SE3\\n\\nT <span class=\\\"token operator\\\">=</span> SE3<span class=\\\"token punctuation\\\">(</span><span class=\\\"token number\\\">0.8</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token number\\\">0.2</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token number\\\">0.1</span><span class=\\\"token punctuation\\\">)</span> <span class=\\\"token operator\\\">*</span> SE3<span class=\\\"token punctuation\\\">.</span>OA<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">[</span><span class=\\\"token number\\\">0</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token number\\\">1</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token number\\\">0</span><span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token punctuation\\\">[</span><span class=\\\"token number\\\">0</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token number\\\">0</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token operator\\\">-</span><span class=\\\"token number\\\">1</span><span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span>\\nsol <span class=\\\"token operator\\\">=</span> robot<span class=\\\"token punctuation\\\">.</span>ikine_min<span class=\\\"token punctuation\\\">(</span>T<span class=\\\"token punctuation\\\">)</span>         <span class=\\\"token comment\\\"># solve IK</span>\\n<span class=\\\"token keyword\\\">print</span><span class=\\\"token punctuation\\\">(</span>sol<span class=\\\"token punctuation\\\">.</span>q<span class=\\\"token punctuation\\\">)</span>                     <span class=\\\"token comment\\\"># display joint angles</span>\\n\\n\\t<span class=\\\"token punctuation\\\">[</span><span class=\\\"token operator\\\">-</span><span class=\\\"token number\\\">0.01044</span>    <span class=\\\"token number\\\">7.876</span>    <span class=\\\"token number\\\">1.557</span>    <span class=\\\"token operator\\\">-</span><span class=\\\"token number\\\">6.81</span>    <span class=\\\"token number\\\">1.571</span>    <span class=\\\"token number\\\">4.686</span>   <span class=\\\"token number\\\">0.5169</span><span class=\\\"token punctuation\\\">]</span>\\n\\n<span class=\\\"token keyword\\\">print</span><span class=\\\"token punctuation\\\">(</span>robot<span class=\\\"token punctuation\\\">.</span>fkine<span class=\\\"token punctuation\\\">(</span>sol<span class=\\\"token punctuation\\\">.</span>q<span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">)</span>    <span class=\\\"token comment\\\"># FK shows that desired end-effector pose was achieved</span>\\n\\n\\tOut<span class=\\\"token punctuation\\\">[</span><span class=\\\"token number\\\">35</span><span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">:</span> \\n\\tSE3<span class=\\\"token punctuation\\\">:</span>┏                                           ┓\\n\\t\\t┃<span class=\\\"token operator\\\">-</span><span class=\\\"token number\\\">1</span>         <span class=\\\"token operator\\\">-</span><span class=\\\"token number\\\">4e</span><span class=\\\"token operator\\\">-</span><span class=\\\"token number\\\">08</span>      <span class=\\\"token number\\\">0.000521</span>   <span class=\\\"token number\\\">0.615</span>    ┃\\n\\t\\t┃ <span class=\\\"token number\\\">2.79e-08</span>   <span class=\\\"token number\\\">1</span>          <span class=\\\"token number\\\">0.00013</span>    <span class=\\\"token number\\\">0.154</span>    ┃\\n\\t\\t┃<span class=\\\"token operator\\\">-</span><span class=\\\"token number\\\">0.000521</span>   <span class=\\\"token number\\\">0.00013</span>   <span class=\\\"token operator\\\">-</span><span class=\\\"token number\\\">1</span>          <span class=\\\"token number\\\">0.105</span>    ┃\\n\\t\\t┃ <span class=\\\"token number\\\">0</span>          <span class=\\\"token number\\\">0</span>          <span class=\\\"token number\\\">0</span>          <span class=\\\"token number\\\">1</span>        ┃\\n\\t\\t┗                                           ┛\\n</code></pre>\\n<p>Note that because this robot is redundant we don't have any control over the arm configuration apart from end-effector pose, ie. we can't control the elbow height.</p>\\n<p>We can animate a path from the upright <code class=\\\"language-none\\\">qz</code> configuration to this pickup configuration</p>\\n<pre class=\\\"language-python\\\"><code class=\\\"language-python\\\">qt <span class=\\\"token operator\\\">=</span> rtb<span class=\\\"token punctuation\\\">.</span>trajectory<span class=\\\"token punctuation\\\">.</span>jtraj<span class=\\\"token punctuation\\\">(</span>robot<span class=\\\"token punctuation\\\">.</span>qz<span class=\\\"token punctuation\\\">,</span> q_pickup<span class=\\\"token punctuation\\\">,</span> <span class=\\\"token number\\\">50</span><span class=\\\"token punctuation\\\">)</span>\\nrobot<span class=\\\"token punctuation\\\">.</span>plot<span class=\\\"token punctuation\\\">(</span>qt<span class=\\\"token punctuation\\\">.</span>q<span class=\\\"token punctuation\\\">,</span> movie<span class=\\\"token operator\\\">=</span><span class=\\\"token string\\\">'panda1.gif'</span><span class=\\\"token punctuation\\\">)</span>\\n</code></pre>\\n<p><video autoplay loop poster=\\\"/_next/static/gifs/826a58e84a13c9100ba2527f636dc267.jpg\\\"><source src=\\\"/_next/static/gifs/826a58e84a13c9100ba2527f636dc267.webm\\\" type=\\\"video/webm\\\"/></video></p>\\n<p>which uses the default matplotlib backend.  Grey arrows show the joint axes and the colored frame shows the end-effector pose.</p>\\n<p>Let's now load a URDF model of the same robot. The kinematic representation is no longer\\nbased on Denavit-Hartenberg parameters, it is now a rigid-body tree.</p>\\n<pre class=\\\"language-python\\\"><code class=\\\"language-python\\\">robot <span class=\\\"token operator\\\">=</span> rtb<span class=\\\"token punctuation\\\">.</span>models<span class=\\\"token punctuation\\\">.</span>URDF<span class=\\\"token punctuation\\\">.</span>Panda<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span>  <span class=\\\"token comment\\\"># load URDF version of the Panda</span>\\n<span class=\\\"token keyword\\\">print</span><span class=\\\"token punctuation\\\">(</span>robot<span class=\\\"token punctuation\\\">)</span>    <span class=\\\"token comment\\\"># display the model</span>\\n\\n\\t┌───┬──────────────┬─────────────┬──────────────┬─────────────────────────────────────────────┐\\n\\t│<span class=\\\"token builtin\\\">id</span> │     link     │   parent    │    joint     │                     ETS                     │\\n\\t├───┼──────────────┼─────────────┼──────────────┼─────────────────────────────────────────────┤\\n\\t│ <span class=\\\"token number\\\">0</span> │  panda_link0 │           <span class=\\\"token operator\\\">-</span> │              │                                             │\\n\\t│ <span class=\\\"token number\\\">1</span> │  panda_link1 │ panda_link0 │ panda_joint1 │                          tz<span class=\\\"token punctuation\\\">(</span><span class=\\\"token number\\\">0.333</span><span class=\\\"token punctuation\\\">)</span> <span class=\\\"token operator\\\">*</span> Rz<span class=\\\"token punctuation\\\">(</span>q0<span class=\\\"token punctuation\\\">)</span> │\\n\\t│ <span class=\\\"token number\\\">2</span> │  panda_link2 │ panda_link1 │ panda_joint2 │                           Rx<span class=\\\"token punctuation\\\">(</span><span class=\\\"token operator\\\">-</span><span class=\\\"token number\\\">90</span>°<span class=\\\"token punctuation\\\">)</span> <span class=\\\"token operator\\\">*</span> Rz<span class=\\\"token punctuation\\\">(</span>q1<span class=\\\"token punctuation\\\">)</span> │\\n\\t│ <span class=\\\"token number\\\">3</span> │  panda_link3 │ panda_link2 │ panda_joint3 │               ty<span class=\\\"token punctuation\\\">(</span><span class=\\\"token operator\\\">-</span><span class=\\\"token number\\\">0.316</span><span class=\\\"token punctuation\\\">)</span> <span class=\\\"token operator\\\">*</span> Rx<span class=\\\"token punctuation\\\">(</span><span class=\\\"token number\\\">90</span>°<span class=\\\"token punctuation\\\">)</span> <span class=\\\"token operator\\\">*</span> Rz<span class=\\\"token punctuation\\\">(</span>q2<span class=\\\"token punctuation\\\">)</span> │\\n\\t│ <span class=\\\"token number\\\">4</span> │  panda_link4 │ panda_link3 │ panda_joint4 │               tx<span class=\\\"token punctuation\\\">(</span><span class=\\\"token number\\\">0.0825</span><span class=\\\"token punctuation\\\">)</span> <span class=\\\"token operator\\\">*</span> Rx<span class=\\\"token punctuation\\\">(</span><span class=\\\"token number\\\">90</span>°<span class=\\\"token punctuation\\\">)</span> <span class=\\\"token operator\\\">*</span> Rz<span class=\\\"token punctuation\\\">(</span>q3<span class=\\\"token punctuation\\\">)</span> │\\n\\t│ <span class=\\\"token number\\\">5</span> │  panda_link5 │ panda_link4 │ panda_joint5 │ tx<span class=\\\"token punctuation\\\">(</span><span class=\\\"token operator\\\">-</span><span class=\\\"token number\\\">0.0825</span><span class=\\\"token punctuation\\\">)</span> <span class=\\\"token operator\\\">*</span> ty<span class=\\\"token punctuation\\\">(</span><span class=\\\"token number\\\">0.384</span><span class=\\\"token punctuation\\\">)</span> <span class=\\\"token operator\\\">*</span> Rx<span class=\\\"token punctuation\\\">(</span><span class=\\\"token operator\\\">-</span><span class=\\\"token number\\\">90</span>°<span class=\\\"token punctuation\\\">)</span> <span class=\\\"token operator\\\">*</span> Rz<span class=\\\"token punctuation\\\">(</span>q4<span class=\\\"token punctuation\\\">)</span> │\\n\\t│ <span class=\\\"token number\\\">6</span> │  panda_link6 │ panda_link5 │ panda_joint6 │                            Rx<span class=\\\"token punctuation\\\">(</span><span class=\\\"token number\\\">90</span>°<span class=\\\"token punctuation\\\">)</span> <span class=\\\"token operator\\\">*</span> Rz<span class=\\\"token punctuation\\\">(</span>q5<span class=\\\"token punctuation\\\">)</span> │\\n\\t│ <span class=\\\"token number\\\">7</span> │  panda_link7 │ panda_link6 │ panda_joint7 │                tx<span class=\\\"token punctuation\\\">(</span><span class=\\\"token number\\\">0.088</span><span class=\\\"token punctuation\\\">)</span> <span class=\\\"token operator\\\">*</span> Rx<span class=\\\"token punctuation\\\">(</span><span class=\\\"token number\\\">90</span>°<span class=\\\"token punctuation\\\">)</span> <span class=\\\"token operator\\\">*</span> Rz<span class=\\\"token punctuation\\\">(</span>q6<span class=\\\"token punctuation\\\">)</span> │\\n\\t│ <span class=\\\"token number\\\">8</span> │ @panda_link8 │ panda_link7 │ panda_joint8 │                                   tz<span class=\\\"token punctuation\\\">(</span><span class=\\\"token number\\\">0.107</span><span class=\\\"token punctuation\\\">)</span> │\\n\\t└───┴──────────────┴─────────────┴──────────────┴─────────────────────────────────────────────┘\\n</code></pre>\\n<p>The symbol <code class=\\\"language-none\\\">@</code> indicates the link as an end-effector, a leaf node in the rigid-body\\ntree.</p>\\n<p>We can instantiate our robot inside a browser-based 3d-simulation environment.</p>\\n<pre class=\\\"language-python\\\"><code class=\\\"language-python\\\">env <span class=\\\"token operator\\\">=</span> rtb<span class=\\\"token punctuation\\\">.</span>backends<span class=\\\"token punctuation\\\">.</span>Swift<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span>  <span class=\\\"token comment\\\"># instantiate 3D browser-based visualizer</span>\\nenv<span class=\\\"token punctuation\\\">.</span>launch<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span>                <span class=\\\"token comment\\\"># activate it</span>\\nenv<span class=\\\"token punctuation\\\">.</span>add<span class=\\\"token punctuation\\\">(</span>robot<span class=\\\"token punctuation\\\">)</span>              <span class=\\\"token comment\\\"># add robot to the 3D scene</span>\\n<span class=\\\"token keyword\\\">for</span> qk <span class=\\\"token keyword\\\">in</span> qt<span class=\\\"token punctuation\\\">.</span>q<span class=\\\"token punctuation\\\">:</span>             <span class=\\\"token comment\\\"># for each joint configuration on trajectory</span>\\n      robot<span class=\\\"token punctuation\\\">.</span>q <span class=\\\"token operator\\\">=</span> qk          <span class=\\\"token comment\\\"># update the robot state</span>\\n      env<span class=\\\"token punctuation\\\">.</span>step<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span>            <span class=\\\"token comment\\\"># update visualization</span>\\n</code></pre>\\n<p align=\\\"center\\\">\\n <img src=\\\"/_next/static/gifs/d064326b92f5b2c4e0c25c057731e6a7.gif\\\">\\n</p>\\n<h1>Getting going</h1>\\n<h2>Installing</h2>\\n<p>You will need Python &gt;= 3.6</p>\\n<h3>Using pip</h3>\\n<p>Install a snapshot from PyPI</p>\\n<pre class=\\\"language-shell\\\"><code class=\\\"language-shell\\\">pip3 <span class=\\\"token function\\\">install</span> roboticstoolbox-python\\n</code></pre>\\n<p>Available options are:</p>\\n<ul>\\n<li><code class=\\\"language-none\\\">vpython</code> install <a href=\\\"https://vpython.org\\\">VPython</a> backend</li>\\n<li><code class=\\\"language-none\\\">collision</code> install collision checking with <a href=\\\"https://pybullet.org\\\">pybullet</a></li>\\n</ul>\\n<p>Put the options in a comma separated list like</p>\\n<pre class=\\\"language-shell\\\"><code class=\\\"language-shell\\\">pip3 <span class=\\\"token function\\\">install</span> roboticstoolbox-python<span class=\\\"token punctuation\\\">[</span>optionlist<span class=\\\"token punctuation\\\">]</span>\\n</code></pre>\\n<p><a href=https://github.com/jhavl/swift>Swift</a>, a web-based visualizer, is\\ninstalled as part of Robotics Toolbox.</p>\\n<h3>From GitHub</h3>\\n<p>To install the bleeding-edge version from GitHub</p>\\n<pre class=\\\"language-shell\\\"><code class=\\\"language-shell\\\"><span class=\\\"token function\\\">git</span> clone https://github.com/petercorke/robotics-toolbox-python.git\\n<span class=\\\"token builtin class-name\\\">cd</span> robotics-toolbox-python\\npip3 <span class=\\\"token function\\\">install</span> -e <span class=\\\"token builtin class-name\\\">.</span>\\n</code></pre>\\n<h2>Run some examples</h2>\\n<p>The <a href=https://github.com/petercorke/robotics-toolbox-python/tree/master/notebooks><code class=\\\"language-none\\\">notebooks</code></a> folder contains some tutorial Jupyter notebooks which you can browse on GitHub.</p>\\n<p>Or you can run them, and experiment with them, at <a href=\\\"https://mybinder.org/v2/gh/petercorke/robotics-toolbox-python/master?filepath=notebooks\\\">mybinder.org</a>.</p>\\n<h2>Toolbox Research Applications</h2>\\n<p>The toolbox is incredibly useful for developing and prototyping algorithms for research, thanks to the exhaustive set of well documented and mature robotic functions exposed through clean and painless APIs. Additionally, the ease at which a user can visualize their algorithm supports a rapid prototyping paradigm.</p>\\n<h3>Publication List</h3>\\n<p>J. Haviland and P. Corke, &quot;<strong>NEO: A Novel Expeditious Optimisation Algorithm for Reactive Motion Control of Manipulators</strong>,&quot; in <em>IEEE Robotics and Automation Letters</em>, doi: 10.1109/LRA.2021.3056060. In the video, the robot is controlled using the Robotics toolbox for Python and features a recording from the <a href=https://github.com/jhavl/swift>Swift</a> Simulator.</p>\\n<p>[<a href=\\\"https://arxiv.org/abs/2010.08686\\\">Arxiv Paper</a>] [<a href=\\\"https://ieeexplore.ieee.org/document/9343718\\\">IEEE Xplore</a>] [<a href=\\\"https://jhavl.github.io/neo/\\\">Project Website</a>] [<a href=\\\"https://youtu.be/jSLPJBr8QTY\\\">Video</a>] [<a href=https://github.com/petercorke/robotics-toolbox-python/blob/master/examples/neo.py>Code Example</a>]</p>\\n<p>\\n  <a href=\\\"https://youtu.be/jSLPJBr8QTY\\\">\\n    <img src=https://github.com/petercorke/robotics-toolbox-python/raw/master/docs/figs/neo_youtube.png width=\\\"560\\\">\\n  </a>\\n</p>\\n<p><strong>A Purely-Reactive Manipulability-Maximising Motion Controller</strong>, J. Haviland and P. Corke. In the video, the robot is controlled using the Robotics toolbox for Python.</p>\\n<p>[<a href=\\\"https://arxiv.org/abs/2002.11901\\\">Paper</a>] [<a href=\\\"https://jhavl.github.io/mmc/\\\">Project Website</a>] [<a href=\\\"https://youtu.be/Vu_rcPlaADI\\\">Video</a>] [<a href=https://github.com/petercorke/robotics-toolbox-python/blob/master/examples/mmc.py>Code Example</a>]</p>\\n<p>\\n  <a href=\\\"https://youtu.be/Vu_rcPlaADI\\\">\\n    <img src=https://github.com/petercorke/robotics-toolbox-python/raw/master/docs/figs/mmc_youtube.png width=\\\"560\\\">\\n  </a>\\n</p>\\n<br>\\n\",\"name\":\"Robotics Toolbox Python\",\"type\":\"code\",\"url\":\"https://github.com/petercorke/robotics-toolbox-python\",\"image\":\"/_next/static/images/RobToolBox_RoundLogoB-9563d226662903b6e404b809e72e3235.png\",\"image_fit\":\"contain\",\"src\":\"/content/robotics_toolbox/robotics-toolbox-python.md\",\"id\":\"robotics-toolbox-python\",\"image_position\":\"center\"},{\"content\":\"<h1>Swift</h1>\\n<p><a href=\\\"https://badge.fury.io/py/swift-sim\\\"><img src=\\\"https://badge.fury.io/py/swift-sim.svg\\\" alt=\\\"PyPI version\\\"></a>\\n<a href=\\\"https://img.shields.io/pypi/pyversions/swift-sim\\\"><img src=\\\"https://img.shields.io/pypi/pyversions/swift-sim\\\" alt=\\\"PyPI - Python Version\\\"></a>\\n<a href=\\\"https://opensource.org/licenses/MIT\\\"><img src=\\\"https://img.shields.io/badge/License-MIT-yellow.svg\\\" alt=\\\"License: MIT\\\"></a>\\n<a href=\\\"https://qcr.github.io\\\"><img src=https://github.com/qcr/qcr.github.io/raw/master/misc/badge.svg alt=\\\"QUT Centre for Robotics Open Source\\\"></a></p>\\n<p>Swift is a light-weight browser-based simulator built on top of the <a href=https://github.com/petercorke/robotics-toolbox-python>Robotics Toolbox for Python</a>. This simulator provides robotics-specific functionality for rapid prototyping of algorithms, research, and education. Built using Python and Javascript, Swift is cross-platform (Linux, MacOS, and Windows) while also leveraging the ubiquity and support of these languages.</p>\\n<p>Through the <a href=https://github.com/petercorke/robotics-toolbox-python>Robotics Toolbox for Python</a>, Swift can visualise over 30 supplied robot models: well-known contemporary robots from Franka-Emika, Kinova, Universal Robotics, Rethink as well as classical robots such as the Puma 560 and the Stanford arm. Swift is under development and will support mobile robots in the future.</p>\\n<p>Swift provides:</p>\\n<ul>\\n<li>visualisation of mesh objects (Collada and STL files) and primitive shapes;</li>\\n<li>robot visualisation and simulation;</li>\\n<li>recording and saving a video of the simulation;</li>\\n<li>source code which can be read for learning and teaching;</li>\\n</ul>\\n<h2>Installing</h2>\\n<h3>Using pip</h3>\\n<p>Swift is designed to be controlled through the <a href=https://github.com/petercorke/robotics-toolbox-python>Robotics Toolbox for Python</a>. By installing the toolbox through PyPI, swift is installed as a dependency</p>\\n<pre class=\\\"language-shell\\\"><code class=\\\"language-shell\\\">pip3 <span class=\\\"token function\\\">install</span> roboticstoolbox-python\\n</code></pre>\\n<p>Otherwise, Swift can be install by</p>\\n<pre class=\\\"language-shell\\\"><code class=\\\"language-shell\\\">pip3 <span class=\\\"token function\\\">install</span> swift-sim\\n</code></pre>\\n<h3>From GitHub</h3>\\n<p>To install the latest version from GitHub</p>\\n<pre class=\\\"language-shell\\\"><code class=\\\"language-shell\\\"><span class=\\\"token function\\\">git</span> clone https://github.com/jhavl/swift.git\\n<span class=\\\"token builtin class-name\\\">cd</span> swift\\npip3 <span class=\\\"token function\\\">install</span> -e <span class=\\\"token builtin class-name\\\">.</span>\\n</code></pre>\\n<h2>Code Examples</h2>\\n<h3>Robot Plot</h3>\\n<p>We will load a model of the Franka-Emika Panda robot and plot it. We set the joint angles of the robot into the ready joint configuration qr.</p>\\n<pre class=\\\"language-python\\\"><code class=\\\"language-python\\\"><span class=\\\"token keyword\\\">import</span> roboticstoolbox <span class=\\\"token keyword\\\">as</span> rp\\n\\npanda <span class=\\\"token operator\\\">=</span> rp<span class=\\\"token punctuation\\\">.</span>models<span class=\\\"token punctuation\\\">.</span>Panda<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span>\\npanda<span class=\\\"token punctuation\\\">.</span>plot<span class=\\\"token punctuation\\\">(</span>q<span class=\\\"token operator\\\">=</span>panda<span class=\\\"token punctuation\\\">.</span>qr<span class=\\\"token punctuation\\\">)</span>\\n</code></pre>\\n<p align=\\\"center\\\">\\n <img src=https://github.com/jhavl/swift/blob/master/.github/figures/panda.png>\\n</p>\\n<h3>Resolved-Rate Motion Control</h3>\\n<p>We will load a model of the Franka-Emika Panda robot and make it travel towards a goal pose defined by the variable Tep.</p>\\n<pre class=\\\"language-python\\\"><code class=\\\"language-python\\\"><span class=\\\"token keyword\\\">import</span> roboticstoolbox <span class=\\\"token keyword\\\">as</span> rtb\\n<span class=\\\"token keyword\\\">import</span> spatialmath <span class=\\\"token keyword\\\">as</span> sm\\n<span class=\\\"token keyword\\\">import</span> numpy <span class=\\\"token keyword\\\">as</span> np\\n\\n<span class=\\\"token comment\\\"># Make and instance of the Swift simulator and open it</span>\\nenv <span class=\\\"token operator\\\">=</span> rtb<span class=\\\"token punctuation\\\">.</span>backends<span class=\\\"token punctuation\\\">.</span>Swift<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span>\\nenv<span class=\\\"token punctuation\\\">.</span>launch<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span>\\n\\n<span class=\\\"token comment\\\"># Make a panda model and set its joint angles to the ready joint configuration</span>\\npanda <span class=\\\"token operator\\\">=</span> rtb<span class=\\\"token punctuation\\\">.</span>models<span class=\\\"token punctuation\\\">.</span>Panda<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span>\\npanda<span class=\\\"token punctuation\\\">.</span>q <span class=\\\"token operator\\\">=</span> panda<span class=\\\"token punctuation\\\">.</span>qr\\n\\n<span class=\\\"token comment\\\"># Set a desired and effector pose an an offset from the current end-effector pose</span>\\nTep <span class=\\\"token operator\\\">=</span> panda<span class=\\\"token punctuation\\\">.</span>fkine<span class=\\\"token punctuation\\\">(</span>panda<span class=\\\"token punctuation\\\">.</span>q<span class=\\\"token punctuation\\\">)</span> <span class=\\\"token operator\\\">*</span> sm<span class=\\\"token punctuation\\\">.</span>SE3<span class=\\\"token punctuation\\\">.</span>Tx<span class=\\\"token punctuation\\\">(</span><span class=\\\"token number\\\">0.2</span><span class=\\\"token punctuation\\\">)</span> <span class=\\\"token operator\\\">*</span> sm<span class=\\\"token punctuation\\\">.</span>SE3<span class=\\\"token punctuation\\\">.</span>Ty<span class=\\\"token punctuation\\\">(</span><span class=\\\"token number\\\">0.2</span><span class=\\\"token punctuation\\\">)</span> <span class=\\\"token operator\\\">*</span> sm<span class=\\\"token punctuation\\\">.</span>SE3<span class=\\\"token punctuation\\\">.</span>Tz<span class=\\\"token punctuation\\\">(</span><span class=\\\"token number\\\">0.45</span><span class=\\\"token punctuation\\\">)</span>\\n\\n<span class=\\\"token comment\\\"># Add the robot to the simulator</span>\\nenv<span class=\\\"token punctuation\\\">.</span>add<span class=\\\"token punctuation\\\">(</span>panda<span class=\\\"token punctuation\\\">)</span>\\n\\n<span class=\\\"token comment\\\"># Simulate the robot while it has not arrived at the goal</span>\\narrived <span class=\\\"token operator\\\">=</span> <span class=\\\"token boolean\\\">False</span>\\n<span class=\\\"token keyword\\\">while</span> <span class=\\\"token keyword\\\">not</span> arrived<span class=\\\"token punctuation\\\">:</span>\\n\\n    <span class=\\\"token comment\\\"># Work out the required end-effector velocity to go towards the goal</span>\\n    v<span class=\\\"token punctuation\\\">,</span> arrived <span class=\\\"token operator\\\">=</span> rtb<span class=\\\"token punctuation\\\">.</span>p_servo<span class=\\\"token punctuation\\\">(</span>panda<span class=\\\"token punctuation\\\">.</span>fkine<span class=\\\"token punctuation\\\">(</span>panda<span class=\\\"token punctuation\\\">.</span>q<span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">,</span> Tep<span class=\\\"token punctuation\\\">,</span> <span class=\\\"token number\\\">1</span><span class=\\\"token punctuation\\\">)</span>\\n    \\n    <span class=\\\"token comment\\\"># Set the Panda's joint velocities</span>\\n    panda<span class=\\\"token punctuation\\\">.</span>qd <span class=\\\"token operator\\\">=</span> np<span class=\\\"token punctuation\\\">.</span>linalg<span class=\\\"token punctuation\\\">.</span>pinv<span class=\\\"token punctuation\\\">(</span>panda<span class=\\\"token punctuation\\\">.</span>jacobe<span class=\\\"token punctuation\\\">(</span>panda<span class=\\\"token punctuation\\\">.</span>q<span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">)</span> @ v\\n    \\n    <span class=\\\"token comment\\\"># Step the simulator by 50 milliseconds</span>\\n    env<span class=\\\"token punctuation\\\">.</span>step<span class=\\\"token punctuation\\\">(</span><span class=\\\"token number\\\">0.05</span><span class=\\\"token punctuation\\\">)</span>\\n</code></pre>\\n<p align=\\\"center\\\">\\n <img src=\\\"/_next/static/gifs/0c7102b6a6bab096effb4fed9f4ba2e5.gif\\\">\\n</p>\\n\",\"name\":\"Swift\",\"type\":\"code\",\"url\":\"https://github.com/jhavl/swift\",\"image\":\"/_next/static/images/panda-08fefd194b35f7baa2af3c22759caa53.png\",\"src\":\"/content/robotics_toolbox/swift.md\",\"id\":\"swift\",\"image_position\":\"center\"}],\"feature\":2,\"src\":\"/content/robotics_toolbox/collection.md\",\"image_position\":\"center\"}]"},"__N_SSG":true}