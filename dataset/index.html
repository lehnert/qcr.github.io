<!DOCTYPE html><html><head><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-H0HTWHNLPD"></script><script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
            gtag('config', 'G-H0HTWHNLPD', {
              page_path: window.location.pathname,
            });
          </script><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>QUT Centre for Robotics Open Source</title><meta name="next-head-count" content="3"/><link rel="preload" href="/_next/static/css/ec58676f2add16c92212.css" as="style"/><link rel="stylesheet" href="/_next/static/css/ec58676f2add16c92212.css" data-n-g=""/><link rel="preload" href="/_next/static/css/720c54c06a66d0bc1902.css" as="style"/><link rel="stylesheet" href="/_next/static/css/720c54c06a66d0bc1902.css" data-n-p=""/><noscript data-n-css=""></noscript><link rel="preload" href="/_next/static/chunks/main-c439d75cfca1ce6a0f7f.js" as="script"/><link rel="preload" href="/_next/static/chunks/webpack-50bee04d1dc61f8adf5b.js" as="script"/><link rel="preload" href="/_next/static/chunks/framework.a6402fb70cc88f6f61b0.js" as="script"/><link rel="preload" href="/_next/static/chunks/commons.455c36b53add9c9c2736.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/_app-d07085bfa8b88c39a473.js" as="script"/><link rel="preload" href="/_next/static/chunks/3d04e185781834a6bdd2cdc78a14cbdede4fee55.e5e850c413858c1cae6e.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/%5Blist%5D-3190a030279983f5e879.js" as="script"/></head><body><div id="__next"><div class="site" style="--mdc-theme-on-primary:rgba(255, 255, 255, 1);--mdc-theme-primary:#00407a"><header class="top_bar_bar__3T8Pf mdc-top-app-bar"><div class="top_bar_row__2Br8o mdc-top-app-bar__row"><section class="top_bar_logo-section__-bkhv mdc-top-app-bar__section mdc-top-app-bar__section--align-start"><img class="top_bar_logo__27Lwl" alt="QCR Logo (light)" src="/_next/static/images/qcr_logo_light-3a0967f7c1a32ca7de4713af85481529.png"/></section><section class="top_bar_pages__3emYr mdc-top-app-bar__section mdc-top-app-bar__section--align-end"><button class="mdc-button"><div class="mdc-button__ripple"></div><span class="mdc-button__label">Collections</span></button><button class="mdc-button"><div class="mdc-button__ripple"></div><span class="mdc-button__label">Code</span></button><button class="top_bar_selected-tab__2hCGV mdc-button"><div class="mdc-button__ripple"></div><span class="mdc-button__label">Datasets</span></button></section></div></header><div class="layout_space__3mcnW"></div><div class="layout_main__1OEEk layout_list__2KQH3"><div class="list_cards__1NSVY"><div class="mdc-elevation--z4 mdc-elevation-transition card_card__3y3tW mdc-card"><div class="card_clickable___QgLM mdc-card__primary-action"><img src="/_next/static/images/challenge_envs-1bb1e48b62de2cdd9e3540368bf44c0f.png" class="card_media__1I_sY" style="object-position:center"/><div class="card_footer__2lBtj"><span class="card_extra__1-p0a card_size__nmyRd mdc-typography--body2">7.5GB</span><span class="mdc-typography--body1">Semantic Scene Understanding (challenge)</span></div></div></div><div class="mdc-elevation--z4 mdc-elevation-transition card_card__3y3tW mdc-card"><div class="card_clickable___QgLM mdc-card__primary-action"><img src="/_next/static/images/develop_envs-c77d4d986222aed06900114eb00b4663.png" class="card_media__1I_sY" style="object-position:center"/><div class="card_footer__2lBtj"><span class="card_extra__1-p0a card_size__nmyRd mdc-typography--body2">8.4GB</span><span class="mdc-typography--body1">Semantic Scene Understanding (development)</span></div></div></div></div></div><div class="bottom_bar_bar__B7RGm"><div class="site-bottom-bar bottom_bar_content__2DVtD"><div></div><div></div><div><span class="mdc-typography--body2">CRICOS No. 00213J</span></div></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"listData":"[{\"content\":\"\u003cp\u003eThe Semantic Scene Understanding (challenge) is a set of Unreal Engine environments for use with the \u003ca href=\\\"http://benchbot.org\\\"\u003eBenchBot software stack\u003c/a\u003e in the \u003ca href=\\\"https://evalai.cloudcv.org/web/challenges/challenge-page/625/overview\\\"\u003eACRV Semantic Scene Understanding Challenge\u003c/a\u003e. A collage of the robot starting position for each of the environments is shown below:\u003c/p\u003e\\n\u003cp\u003e\u003cimg src=\\\"/_next/static/images/challenge_envs-1bb1e48b62de2cdd9e3540368bf44c0f.png\\\" alt=\\\"Robot starting positions in environments from the semantic scene understanding (challenge) dataset\\\"\u003e\u003c/p\u003e\\n\u003cp\u003eFeatures of the dataset include:\u003c/p\u003e\\n\u003cul\u003e\\n\u003cli\u003ea total of 15 different environments\u003c/li\u003e\\n\u003cli\u003e3 different places: a luxurious penthouse apartment, an office workspace and a large corporate building\u003c/li\u003e\\n\u003cli\u003eeach place has 5 different variations\u003c/li\u003e\\n\u003cli\u003ebetween variations there are changes in lighting, time of day, starting location, robot trajectory, and object placements\u003c/li\u003e\\n\u003c/ul\u003e\\n\u003cp\u003eFor more details of the dataset, challenge, BenchBot, and how it all fits together, please see our summary video below:\u003c/p\u003e\\n\u003cdiv class=\\\"embedded-block block-embed-service-youtube\\\"\u003e\u003ciframe type=\\\"text/html\\\" src=\\\"//www.youtube.com/embed/jQPkV29KFvI\\\" frameborder=\\\"0\\\" width=\\\"640\\\" height=\\\"390\\\" webkitallowfullscreen mozallowfullscreen allowfullscreen\u003e\u003c/iframe\u003e\u003c/div\u003e\\n\",\"name\":\"Semantic Scene Understanding (challenge)\",\"type\":\"dataset\",\"url\":\"https://cloudstor.aarnet.edu.au/plus/s/gRg5N85PZYRcI2c/download\",\"size\":\"7.5GB\",\"src\":\"/content/benchbot/benchbot-challenge.md\",\"id\":\"benchbot-challenge\",\"image_position\":\"center\",\"image\":\"/_next/static/images/challenge_envs-1bb1e48b62de2cdd9e3540368bf44c0f.png\"},{\"content\":\"\u003cp\u003eThe Semantic Scene Understanding (development) is a set of Unreal Engine environments for use with the \u003ca href=\\\"http://benchbot.org\\\"\u003eBenchBot software stack\u003c/a\u003e in the \u003ca href=\\\"https://evalai.cloudcv.org/web/challenges/challenge-page/625/overview\\\"\u003eACRV Semantic Scene Understanding Challenge\u003c/a\u003e. A collage of the robot starting position for each of the environments is shown below:\u003c/p\u003e\\n\u003cp\u003e\u003cimg src=\\\"/_next/static/images/develop_envs-c77d4d986222aed06900114eb00b4663.png\\\" alt=\\\"Robot starting positions in environments from the semantic scene understanding (development) dataset\\\"\u003e\u003c/p\u003e\\n\u003cp\u003eFeatures of the dataset include:\u003c/p\u003e\\n\u003cul\u003e\\n\u003cli\u003ea total of 10 different environments\u003c/li\u003e\\n\u003cli\u003e2 different places: a small apartment room, and a Scandinavian house\u003c/li\u003e\\n\u003cli\u003eeach place has 5 different variations\u003c/li\u003e\\n\u003cli\u003ebetween variations there are changes in lighting, time of day, starting location, robot trajectory, and object placements\u003c/li\u003e\\n\u003c/ul\u003e\\n\u003cp\u003eFor more details of the dataset, challenge, BenchBot, and how it all fits together, please see our summary video below:\u003c/p\u003e\\n\u003cdiv class=\\\"embedded-block block-embed-service-youtube\\\"\u003e\u003ciframe type=\\\"text/html\\\" src=\\\"//www.youtube.com/embed/jQPkV29KFvI\\\" frameborder=\\\"0\\\" width=\\\"640\\\" height=\\\"390\\\" webkitallowfullscreen mozallowfullscreen allowfullscreen\u003e\u003c/iframe\u003e\u003c/div\u003e\\n\",\"name\":\"Semantic Scene Understanding (development)\",\"type\":\"dataset\",\"url\":\"https://cloudstor.aarnet.edu.au/plus/s/1MNBnLZan8X95qb/download\",\"size\":\"8.4GB\",\"src\":\"/content/benchbot/benchbot-develop.md\",\"id\":\"benchbot-develop\",\"image_position\":\"center\",\"image\":\"/_next/static/images/develop_envs-c77d4d986222aed06900114eb00b4663.png\"}]"},"__N_SSG":true},"page":"/[list]","query":{"list":"dataset"},"buildId":"1nuS-y2A2y9fnoeaTjLIs","nextExport":false,"isFallback":false,"gsp":true}</script><script nomodule="" src="/_next/static/chunks/polyfills-ff94e68042added27a93.js"></script><script src="/_next/static/chunks/main-c439d75cfca1ce6a0f7f.js" async=""></script><script src="/_next/static/chunks/webpack-50bee04d1dc61f8adf5b.js" async=""></script><script src="/_next/static/chunks/framework.a6402fb70cc88f6f61b0.js" async=""></script><script src="/_next/static/chunks/commons.455c36b53add9c9c2736.js" async=""></script><script src="/_next/static/chunks/pages/_app-d07085bfa8b88c39a473.js" async=""></script><script src="/_next/static/chunks/3d04e185781834a6bdd2cdc78a14cbdede4fee55.e5e850c413858c1cae6e.js" async=""></script><script src="/_next/static/chunks/pages/%5Blist%5D-3190a030279983f5e879.js" async=""></script><script src="/_next/static/1nuS-y2A2y9fnoeaTjLIs/_buildManifest.js" async=""></script><script src="/_next/static/1nuS-y2A2y9fnoeaTjLIs/_ssgManifest.js" async=""></script></body></html>